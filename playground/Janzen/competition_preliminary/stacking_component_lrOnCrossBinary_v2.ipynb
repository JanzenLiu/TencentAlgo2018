{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../code/pipeline/')\n",
    "sys.path.append('../../../code/utils/')\n",
    "sys.path.append('../../../code/')\n",
    "import data_pipeline as dp\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import eval_utils as eu\n",
    "import io_utils as iu\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# Data Preparation\n",
    "# ================\n",
    "# defined feature pairs to load cross product transformation\n",
    "# pairs = [(\"aid\", \"age\"), (\"aid\", \"education\"), (\"aid\", \"consumptionAbility\"), (\"aid\", \"LBS\")]\n",
    "pairs = [('productId', 'LBS'),\n",
    "         ('advertiserId', 'interest1'),\n",
    "         ('aid', 'interest2'),\n",
    "         ('creativeSize', 'interest2'), \n",
    "         ('campaignId', 'interest4'),  # whether to keep it? \n",
    "         ('aid', 'interest5'),  \n",
    "         ('productType', 'kw1'),  # 'kw1' looks very overfitting prone, to be decide whether to keep it\n",
    "         ('productType', 'kw2'),\n",
    "         ('productType', 'kw3'),\n",
    "         ('productType', 'topic1'),\n",
    "         ('aid', 'topic2'),\n",
    "         ('productType', 'topic2'),\n",
    "         # ('productType', 'topic3'),  # might help in predicting negative samples\n",
    "         # ('productType', 'appIdInstall'),  # might help in predicting negative samples\n",
    "         # ('productType', 'appIdAction'),  # might help in predicting negative samples\n",
    "         ('aid', 'ct'),\n",
    "         ('aid', 'os')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test\")\n",
    "y = df_train[\"label\"].values.copy()\n",
    "y = (y + 1) / 2  # 1/-1 to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5  # 3? 5? Don't know which one will be better\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=2018)  # for reproducibility\n",
    "split_indices = [(train_index, valid_index) for train_index, valid_index in skf.split(df_train, y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what should be customizable:\n",
    "# 1. model building\n",
    "# 2. model fitting\n",
    "# 3. model predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:22] Finish loading 'LBS' x 'productId'. △M: +122.77MB. △T: 0.2 seconds.\n",
      "[14:51:58] Finish fitting LR (fold 1/5). △M: -13.11MB. △T: 1.6 minutes.\n",
      "[14:53:29] Finish fitting LR (fold 2/5). △M: +26.98MB. △T: 1.5 minutes.\n",
      "[14:54:59] Finish fitting LR (fold 3/5). △M: +128.0KB. △T: 1.5 minutes.\n",
      "[14:56:29] Finish fitting LR (fold 4/5). △M: +26.85MB. △T: 1.5 minutes.\n",
      "[14:58:00] Finish fitting LR (fold 5/5). △M: +0B. △T: 1.5 minutes.\n",
      "AUC: 0.535413(+/-0.00135)\n",
      "[14:58:03] Finish loading 'interest1' x 'advertiserId'. △M: +713.91MB. △T: 1.6 seconds.\n",
      "[15:17:44] Finish fitting LR (fold 1/5). △M: +128.0KB. △T: 19.6 minutes.\n",
      "[15:38:33] Finish fitting LR (fold 2/5). △M: -107.41MB. △T: 20.7 minutes.\n",
      "[15:57:04] Finish fitting LR (fold 3/5). △M: +128.0KB. △T: 18.4 minutes.\n",
      "[16:10:14] Finish fitting LR (fold 4/5). △M: -26.85MB. △T: 13.1 minutes.\n",
      "[16:24:28] Finish fitting LR (fold 5/5). △M: +128.0KB. △T: 14.1 minutes.\n",
      "AUC: 0.595944(+/-0.000632)\n",
      "[16:24:30] Finish loading 'interest2' x 'aid'. △M: +210.34MB. △T: 0.5 seconds.\n",
      "[00:36:57] Finish fitting LR (fold 1/5). △M: +510.18MB. △T: 8.2 hours.\n",
      "[00:44:42] Finish fitting LR (fold 2/5). △M: -237.1MB. △T: 7.7 minutes.\n",
      "[00:49:52] Finish fitting LR (fold 3/5). △M: +100.0KB. △T: 5.1 minutes.\n",
      "[00:55:35] Finish fitting LR (fold 4/5). △M: +928.0KB. △T: 5.7 minutes.\n",
      "[01:01:17] Finish fitting LR (fold 5/5). △M: +128.0KB. △T: 5.7 minutes.\n",
      "AUC: 0.656101(+/-0.000822)\n",
      "[01:01:18] Finish loading 'interest2' x 'creativeSize'. △M: +138.93MB. △T: 0.4 seconds.\n",
      "[01:08:53] Finish fitting LR (fold 1/5). △M: +53.83MB. △T: 7.6 minutes.\n",
      "[01:15:10] Finish fitting LR (fold 2/5). △M: -26.85MB. △T: 6.2 minutes.\n",
      "[01:22:53] Finish fitting LR (fold 3/5). △M: -21.12MB. △T: 7.7 minutes.\n",
      "[01:29:10] Finish fitting LR (fold 4/5). △M: +128.0KB. △T: 6.3 minutes.\n",
      "[01:36:09] Finish fitting LR (fold 5/5). △M: +26.98MB. △T: 7.0 minutes.\n",
      "AUC: 0.634668(+/-0.000534)\n",
      "[01:36:10] Finish loading 'interest4' x 'campaignId'. △M: +0B. △T: 0.1 seconds.\n",
      "[01:37:29] Finish fitting LR (fold 1/5). △M: +0B. △T: 1.3 minutes.\n",
      "[01:39:28] Finish fitting LR (fold 2/5). △M: +26.98MB. △T: 2.0 minutes.\n",
      "[01:41:07] Finish fitting LR (fold 3/5). △M: +0B. △T: 1.6 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:45] Finish fitting LR (fold 4/5). △M: +212.0KB. △T: 2.6 minutes.\n",
      "[01:45:10] Finish fitting LR (fold 5/5). △M: +26.85MB. △T: 1.4 minutes.\n",
      "AUC: 0.503497(+/-0.000271)\n",
      "[01:45:12] Finish loading 'interest5' x 'aid'. △M: +801.81MB. △T: 2.0 seconds.\n",
      "[02:00:20] Finish fitting LR (fold 1/5). △M: +26.85MB. △T: 15.1 minutes.\n",
      "[02:16:23] Finish fitting LR (fold 2/5). △M: -26.85MB. △T: 16.0 minutes.\n",
      "[02:31:19] Finish fitting LR (fold 3/5). △M: +0B. △T: 14.9 minutes.\n",
      "[02:47:32] Finish fitting LR (fold 4/5). △M: +128.0KB. △T: 16.1 minutes.\n",
      "[03:03:15] Finish fitting LR (fold 5/5). △M: -26.85MB. △T: 15.6 minutes.\n",
      "AUC: 0.616594(+/-0.000869)\n",
      "[03:03:18] Finish loading 'kw1' x 'productType'. △M: +381.63MB. △T: 1.6 seconds.\n",
      "[03:10:28] Finish fitting LR (fold 1/5). △M: +196.0KB. △T: 7.1 minutes.\n",
      "[03:18:52] Finish fitting LR (fold 2/5). △M: +140.0KB. △T: 8.4 minutes.\n",
      "[03:26:35] Finish fitting LR (fold 3/5). △M: +128.0KB. △T: 7.7 minutes.\n",
      "[03:34:33] Finish fitting LR (fold 4/5). △M: +128.0KB. △T: 7.9 minutes.\n",
      "[03:43:24] Finish fitting LR (fold 5/5). △M: -43.33MB. △T: 8.8 minutes.\n",
      "AUC: 0.557730(+/-0.000875)\n",
      "[03:43:26] Finish loading 'kw2' x 'productType'. △M: +105.7MB. △T: 0.8 seconds.\n",
      "[03:49:37] Finish fitting LR (fold 1/5). △M: +53.7MB. △T: 6.2 minutes.\n",
      "[03:54:57] Finish fitting LR (fold 2/5). △M: -21.4MB. △T: 5.3 minutes.\n",
      "[04:00:45] Finish fitting LR (fold 3/5). △M: +402.9MB. △T: 5.8 minutes.\n",
      "[04:07:14] Finish fitting LR (fold 4/5). △M: -274.08MB. △T: 6.5 minutes.\n",
      "[04:13:11] Finish fitting LR (fold 5/5). △M: -1.5MB. △T: 5.9 minutes.\n",
      "AUC: 0.664312(+/-0.000894)\n",
      "[04:13:12] Finish loading 'kw3' x 'productType'. △M: +16.01MB. △T: 0.2 seconds.\n",
      "[04:15:02] Finish fitting LR (fold 1/5). △M: -4.88MB. △T: 1.8 minutes.\n",
      "[04:17:03] Finish fitting LR (fold 2/5). △M: +128.0KB. △T: 2.0 minutes.\n",
      "[04:18:42] Finish fitting LR (fold 3/5). △M: +128.0KB. △T: 1.6 minutes.\n",
      "[04:20:22] Finish fitting LR (fold 4/5). △M: -51.77MB. △T: 1.7 minutes.\n",
      "[04:22:19] Finish fitting LR (fold 5/5). △M: +128.0KB. △T: 1.9 minutes.\n",
      "AUC: 0.504458(+/-0.000999)\n",
      "[04:22:20] Finish loading 'topic1' x 'productType'. △M: +194.77MB. △T: 0.6 seconds.\n",
      "[04:27:11] Finish fitting LR (fold 1/5). △M: +128.0KB. △T: 4.8 minutes.\n",
      "[04:32:24] Finish fitting LR (fold 2/5). △M: -22.59MB. △T: 5.2 minutes.\n",
      "[04:37:08] Finish fitting LR (fold 3/5). △M: +128.0KB. △T: 4.7 minutes.\n",
      "[04:40:53] Finish fitting LR (fold 4/5). △M: +128.0KB. △T: 3.7 minutes.\n",
      "[04:45:55] Finish fitting LR (fold 5/5). △M: -37.62MB. △T: 5.0 minutes.\n",
      "AUC: 0.549853(+/-0.000626)\n",
      "[04:45:58] Finish loading 'topic2' x 'aid'. △M: +441.81MB. △T: 2.1 seconds.\n",
      "[04:55:45] Finish fitting LR (fold 1/5). △M: +192.0KB. △T: 9.7 minutes.\n",
      "[05:04:21] Finish fitting LR (fold 2/5). △M: -3.3MB. △T: 8.6 minutes.\n",
      "[05:13:06] Finish fitting LR (fold 3/5). △M: -5.95MB. △T: 8.7 minutes.\n",
      "[05:22:11] Finish fitting LR (fold 4/5). △M: -20.9MB. △T: 9.0 minutes.\n",
      "[05:32:07] Finish fitting LR (fold 5/5). △M: +128.0KB. △T: 9.9 minutes.\n",
      "AUC: 0.629488(+/-0.000904)\n",
      "[05:32:10] Finish loading 'topic2' x 'productType'. △M: -30.37MB. △T: 1.3 seconds.\n",
      "[05:39:50] Finish fitting LR (fold 1/5). △M: +172.0KB. △T: 7.6 minutes.\n",
      "[05:43:18] Finish fitting LR (fold 2/5). △M: -46.54MB. △T: 3.4 minutes.\n",
      "[05:48:13] Finish fitting LR (fold 3/5). △M: -7.72MB. △T: 4.9 minutes.\n",
      "[05:52:18] Finish fitting LR (fold 4/5). △M: +26.98MB. △T: 4.0 minutes.\n",
      "[06:00:24] Finish fitting LR (fold 5/5). △M: +0B. △T: 8.1 minutes.\n",
      "AUC: 0.634358(+/-0.00062)\n",
      "[06:00:26] Finish loading 'ct' x 'aid'. △M: +58.41MB. △T: 0.3 seconds.\n",
      "[06:03:53] Finish fitting LR (fold 1/5). △M: +53.7MB. △T: 3.4 minutes.\n",
      "[06:07:19] Finish fitting LR (fold 2/5). △M: -2.45MB. △T: 3.4 minutes.\n",
      "[06:10:31] Finish fitting LR (fold 3/5). △M: -664.0KB. △T: 3.2 minutes.\n",
      "[06:15:03] Finish fitting LR (fold 4/5). △M: +128.0KB. △T: 4.5 minutes.\n",
      "[06:20:25] Finish fitting LR (fold 5/5). △M: -33.3MB. △T: 5.3 minutes.\n",
      "AUC: 0.557264(+/-0.000941)\n",
      "[06:20:27] Finish loading 'os' x 'aid'. △M: +35.83MB. △T: 0.2 seconds.\n",
      "[06:22:29] Finish fitting LR (fold 1/5). △M: -36.41MB. △T: 2.0 minutes.\n",
      "[06:24:52] Finish fitting LR (fold 2/5). △M: +128.0KB. △T: 2.4 minutes.\n",
      "[06:27:15] Finish fitting LR (fold 3/5). △M: -2.01MB. △T: 2.4 minutes.\n",
      "[06:30:01] Finish fitting LR (fold 4/5). △M: +128.0KB. △T: 2.7 minutes.\n",
      "[06:32:05] Finish fitting LR (fold 5/5). △M: -2.01MB. △T: 2.0 minutes.\n",
      "AUC: 0.554914(+/-0.000776)\n"
     ]
    }
   ],
   "source": [
    "df_stack_tv = pd.DataFrame()\n",
    "df_stack_test = pd.DataFrame()\n",
    "df_score = pd.DataFrame(columns=[\"featureName\", \"auc_mean\", \"auc_std\"])\n",
    "\n",
    "for j, (ad_feat_name, user_feat_name) in enumerate(pairs):\n",
    "    ### given a user feature ###\n",
    "    # load matrix as input to model\n",
    "    with pu.profiler(\"loading '{}' x '{}'\".format(user_feat_name, ad_feat_name)):\n",
    "        cross_bin_loader = dp.CrossBinaryDataManager.build_data(ad_feat_name, user_feat_name) \n",
    "        cols, X_tv,  = cross_bin_loader.load(\"train\")\n",
    "        _, X_test = cross_bin_loader.load(\"test1\")\n",
    "\n",
    "    # prepare containers\n",
    "    stack_tv = np.zeros(X_tv.shape[0])\n",
    "    stack_test = np.zeros((X_test.shape[0], n_splits))\n",
    "    scores = np.zeros(n_splits)\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(split_indices):\n",
    "        ### given a splitting ###\n",
    "        # split train/valid sets\n",
    "        X_train, y_train = X_tv[train_index], y[train_index]\n",
    "        X_valid, y_valid = X_tv[valid_index], y[valid_index]\n",
    "\n",
    "        # fit LR\n",
    "        with pu.profiler(\"fitting LR (fold {}/{})\".format(i + 1, n_splits)):\n",
    "            lr = LogisticRegression(solver=\"newton-cg\")  # use default setting: penalty='l2' and C=1\n",
    "            lr.fit(X_train, y_train)\n",
    "\n",
    "        # make prediction for validation set\n",
    "        proba_valid = lr.predict_proba(X_valid)[:, 1]\n",
    "        stack_tv[valid_index] = proba_valid\n",
    "\n",
    "        # make prediction for testing set\n",
    "        proba_test = lr.predict_proba(X_test)[:, 1]\n",
    "        stack_test[:, i] = proba_test\n",
    "\n",
    "        # calculate scores\n",
    "        auc = metrics.roc_auc_score(y_valid, proba_valid)\n",
    "        scores[i] = auc\n",
    "\n",
    "    # update dataframe for stacking\n",
    "    cross_name = \"{}_x_{}\".format(ad_feat_name, user_feat_name)\n",
    "    col_name = \"stackProba_{}\".format(cross_name)\n",
    "    score_row = {\"featureName\": cross_name, \n",
    "                 \"auc_mean\": scores.mean(), \"auc_std\": scores.std()}\n",
    "    df_stack_tv[col_name] = stack_tv\n",
    "    df_stack_test[col_name] = stack_test.mean(axis=1)\n",
    "    df_score.loc[df_score.shape[0]] = score_row\n",
    "    print(\"AUC: {:.6f}(+/-{:.3g})\".format(score_row[\"auc_mean\"], score_row[\"auc_std\"]))\n",
    "    \n",
    "    del X_tv\n",
    "    del X_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Prediction Shape: (8798814, 14)\n",
      "Testing Set Prediction Shape: (2265989, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Prediction Shape: {}\".format(df_stack_tv.shape))\n",
    "print(\"Testing Set Prediction Shape: {}\".format(df_stack_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(config.DATA_DIR)\n",
    "out_folder = os.path.join(config.DATA_DIR, 'stacking/lr')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# remember to format float number or you will find these really hard-disk consumptive\n",
    "# save prediction for training set\n",
    "out_file = 'train.crossBinary_v2.csv'\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "df_stack_tv.to_csv(out_path, float_format=\"%.6f\", index=False)\n",
    "\n",
    "# save prediction for testing set\n",
    "out_file = 'test.crossBinary_v2.csv'\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "df_stack_test.to_csv(out_path, float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save score information\n",
    "out_file = 'score.crossBinary_v2.csv'\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "df_score = df_score[[\"featureName\", \"auc_mean\", \"auc_std\"]]\n",
    "df_score = df_score.sort_values(\"auc_mean\", ascending=False)\n",
    "df_score.to_csv(out_path, float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_pairs = [('productId', 'LBS'),\n",
    "             ('advertiserId', 'interest1'),\n",
    "             ('aid', 'interest2'),\n",
    "             ('creativeSize', 'interest2'), \n",
    "             # ('campaignId', 'interest4'),  # whether to keep it? \n",
    "             ('aid', 'interest5'),  \n",
    "             ('productType', 'kw1'),  # 'kw1' looks very overfitting prone, to be decide whether to keep it\n",
    "             ('productType', 'kw2'),\n",
    "             # ('productType', 'kw3'),\n",
    "             ('productType', 'topic1'),\n",
    "             ('aid', 'topic2'),\n",
    "             ('productType', 'topic2'),\n",
    "             ('aid', 'ct'),\n",
    "             ('aid', 'os')]\n",
    "use_cols = ['stackProba_{}_x_{}'.format(ad_feat_name, user_feat_name) \n",
    "            for ad_feat_name, user_feat_name in use_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:04:52] Finish getting matrix represenation. △M: +0B. △T: 1.1 seconds.\n",
      "[09:04:54] Finish saving matrix to hard disk. △M: -402.57MB. △T: 1.3 seconds.\n"
     ]
    }
   ],
   "source": [
    "out_folder = config.INPUT_DIR\n",
    "out_file = \"train.stacking.lrCrossBinary_v2.pkl\"\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "with pu.profiler(\"getting matrix represenation\"):\n",
    "    X_train = df_stack_tv[use_cols].values.astype(np.float32)\n",
    "    assert X_train.shape[0] == df_train.shape[0]\n",
    "    assert X_train.shape[1] == len(use_pairs)\n",
    "\n",
    "with pu.profiler(\"saving matrix to hard disk\"):\n",
    "    col_names = ['stackProba_LR_{}_x_{}'.format(ad_feat_name, user_feat_name) for \n",
    "                 ad_feat_name, user_feat_name in use_pairs]\n",
    "    du.save_pickle((col_names, X_train), out_path)\n",
    "    del X_train\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:04:59] Finish getting matrix represenation. △M: +164.34MB. △T: 0.5 seconds.\n",
      "[09:05:00] Finish saving matrix to hard disk. △M: +0B. △T: 0.2 seconds.\n"
     ]
    }
   ],
   "source": [
    "out_file = \"test1.stacking.lrCrossBinary_v2.pkl\"\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "\n",
    "with pu.profiler(\"getting matrix represenation\"):\n",
    "    X_test = df_stack_test[use_cols].values.astype(np.float32)\n",
    "    assert X_test.shape[0] == df_test.shape[0]\n",
    "    assert X_test.shape[1] == len(use_pairs)\n",
    "\n",
    "with pu.profiler(\"saving matrix to hard disk\"):\n",
    "    # col_names = ['stackProba_LR_{}'.format(feat_name) for feat_name in use_feats]\n",
    "    du.save_pickle((col_names, X_test), out_path)\n",
    "    del X_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
