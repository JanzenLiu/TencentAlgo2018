{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "import types\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")  # so sao\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All ResNet Things are adapted from https://github.com/raghakot/keras-resnet/blob/master/resnet.py\n",
    "def _bn_relu(inp):\n",
    "    \"\"\"Helper to build a BN -> relu block\"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(inp)\n",
    "    \n",
    "    return Activation(\"relu\")(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "    \n",
    "    def f(inp):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(inp)\n",
    "        return _bn_relu(conv)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    \n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "    \n",
    "    def f(inp):\n",
    "        activation = _bn_relu(inp)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shortcut(inp, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(inp)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = inp\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(inp)\n",
    "\n",
    "    return add([shortcut, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\"\"\"\n",
    "    def f(inp):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            inp = block_function(filters=filters, init_strides=init_strides,\n",
    "                                 is_first_block_of_first_layer=(is_first_layer and i == 0))(inp)\n",
    "        return inp\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(inp):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(inp)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(inp)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(inp, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(inp):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(inp)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(inp)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(inp, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid identifier: {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        input_shape: tuple \n",
    "            The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            \n",
    "        num_outputs: int \n",
    "            The number of outputs at final softmax layer\n",
    "\n",
    "        block_fn: types.FunctionType | {'basic_block', 'bottleneck'}\n",
    "            The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "            The original paper used basic_block for layers < 50\n",
    "\n",
    "        repetitions: int\n",
    "            Number of repetitions of various block units.\n",
    "            At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model: keras.models.Model\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        inp = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(inp)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=dense)\n",
    "        return model\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_id, folder, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        img_id: string\n",
    "        \n",
    "        folder: string\n",
    "        \n",
    "        size: tuple\n",
    "            Target size to resize the original image into.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        img: np.ndarray\n",
    "            Image as numpy array.\n",
    "    \"\"\"\n",
    "    img = image.load_img(os.path.join(folder, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All preparation things are adapted from https://www.kaggle.com/gaborfodor/dog-breed-pretrained-keras-models-lb-0-3\n",
    "INPUT_SIZE = 224\n",
    "SEED = 20180407\n",
    "data_dir = '../data/dog_breed'\n",
    "labels = pd.read_csv(os.path.join(data_dir, 'labels.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n",
    "NUM_CLASSES = labels[\"breed\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image Counts in Directory: 10222\n",
      "Train Image Counts in CSV: 10222\n",
      "Test Image Counts in Directory: 10357\n",
      "Test Image Counts in Sample Submission: 10357\n",
      "Class Counts: 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Image Counts in Directory: {}\".format(len(os.listdir(os.path.join(data_dir, 'Train')))))\n",
    "print(\"Train Image Counts in CSV: {}\".format(labels.shape[0]))\n",
    "print(\"Test Image Counts in Directory: {}\".format(len(os.listdir(os.path.join(data_dir, 'Test')))))\n",
    "print(\"Test Image Counts in Sample Submission: {}\".format(sample_submission.shape[0]))\n",
    "print(\"Class Counts: {}\".format(NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10222it [00:30, 338.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (10222, 224, 224, 3) size: 1,538,697,216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "INPUT_SIZE = 224\n",
    "POOLING = 'avg'\n",
    "train_folder = \"../data/dog_breed/Train\"\n",
    "y_train = labels[\"breed\"].values\n",
    "x_train = np.zeros((labels.shape[0], INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm.tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, train_folder, (INPUT_SIZE, INPUT_SIZE))\n",
    "    # x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = img  # it's x originally\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and validation set\n",
    "np.random.seed(seed=SEED)\n",
    "rnd = np.random.random(len(labels))\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare labels\n",
    "lb = LabelBinarizer()\n",
    "ytr = y_train[train_idx]\n",
    "yv = y_train[valid_idx]\n",
    "ytr_onehot = lb.fit_transform(ytr)\n",
    "yv_onehot = lb.transform(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare inputs\n",
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "del x_train\n",
    "gc.collect()  # clear the memory or your computer will explode lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Class Counts in training set: 120\n",
      "Unique Class Counts in validation set: 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Class Counts in training set: {}\".format(np.unique(ytr).shape[0]))\n",
    "print(\"Unique Class Counts in validation set: {}\".format(np.unique(yv).shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 112, 112, 64)  9472        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 112, 112, 64)  256         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 112, 112, 64)  0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 56, 56, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 56, 56, 64)    36928       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 56, 56, 64)    256         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 56, 56, 64)    0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 56, 56, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 56, 56, 64)    0           max_pooling2d_1[0][0]            \n",
      "                                                                   conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 56, 56, 64)    256         add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 56, 56, 64)    0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 56, 56, 64)    36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 56, 56, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 56, 56, 64)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 56, 56, 64)    36928       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 56, 56, 64)    0           add_1[0][0]                      \n",
      "                                                                   conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 56, 56, 64)    256         add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 56, 56, 64)    0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 28, 28, 128)   73856       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 28, 28, 128)   512         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 28, 28, 128)   0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 28, 28, 128)   8320        add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 28, 28, 128)   147584      activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 28, 28, 128)   0           conv2d_8[0][0]                   \n",
      "                                                                   conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 28, 28, 128)   512         add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 28, 28, 128)   0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 28, 28, 128)   147584      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 28, 28, 128)   512         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 28, 28, 128)   0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 28, 28, 128)   147584      activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 28, 28, 128)   0           add_3[0][0]                      \n",
      "                                                                   conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 28, 28, 128)   512         add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 28, 28, 128)   0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 14, 14, 256)   295168      activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 14, 14, 256)   1024        conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 14, 14, 256)   0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 14, 14, 256)   33024       add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 14, 14, 256)   590080      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 14, 14, 256)   0           conv2d_13[0][0]                  \n",
      "                                                                   conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 14, 14, 256)   1024        add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 14, 14, 256)   0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 14, 14, 256)   590080      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 14, 14, 256)   1024        conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 14, 14, 256)   0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 14, 14, 256)   590080      activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 14, 14, 256)   0           add_5[0][0]                      \n",
      "                                                                   conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 14, 14, 256)   1024        add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 14, 14, 256)   0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 7, 7, 512)     1180160     activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 7, 7, 512)     2048        conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 7, 7, 512)     0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 7, 7, 512)     131584      add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 7, 7, 512)     2359808     activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 7, 7, 512)     0           conv2d_18[0][0]                  \n",
      "                                                                   conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 7, 7, 512)     2048        add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 7, 7, 512)     0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 7, 7, 512)     2359808     activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 7, 7, 512)     2048        conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 7, 7, 512)     0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 7, 7, 512)     2359808     activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 7, 7, 512)     0           add_7[0][0]                      \n",
      "                                                                   conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 7, 7, 512)     2048        add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 7, 7, 512)     0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 1, 1, 512)     0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 120)           61560       flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 11,248,888\n",
      "Trainable params: 11,241,080\n",
      "Non-trainable params: 7,808\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res18 = ResnetBuilder.build_resnet_18((3, INPUT_SIZE, INPUT_SIZE), NUM_CLASSES)\n",
    "res18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8162 samples, validate on 2060 samples\n",
      "Epoch 1/1\n",
      "8162/8162 [==============================] - 2258s - loss: 0.7546 - acc: 0.9917 - val_loss: 0.7185 - val_acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56e974c080>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res18.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['acc'])\n",
    "res18.fit(Xtr, ytr_onehot,  # This is fucking slow!!!\n",
    "          epochs=1,\n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          validation_data=(Xv, yv_onehot))\n",
    "#         callbacks=[ks.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
