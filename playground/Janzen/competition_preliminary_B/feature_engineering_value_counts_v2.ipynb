{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../code/utils')\n",
    "sys.path.append('../../../code/pipeline')\n",
    "sys.path.append('../../../code')\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import data_jointer as dj\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(1024)\n",
    "def count_values(string):\n",
    "    if isinstance(string, float):\n",
    "        return 0  # is nan\n",
    "    else:\n",
    "        return len(string.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uj = dj.PandasPandasJointer(\"uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:07:16] Finish counting 'interest1' for each user. △M: +300.49MB. △T: 32.2 seconds.\n",
      "[15:07:39] Finish counting 'interest2' for each user. △M: +181.85MB. △T: 23.7 seconds.\n",
      "[15:07:55] Finish counting 'interest3' for each user. △M: +86.13MB. △T: 15.4 seconds.\n",
      "[15:08:09] Finish counting 'interest4' for each user. △M: +87.13MB. △T: 14.5 seconds.\n",
      "[15:08:51] Finish counting 'interest5' for each user. △M: +90.48MB. △T: 42.1 seconds.\n",
      "[15:09:27] Finish counting 'kw1' for each user. △M: +83.34MB. △T: 35.1 seconds.\n",
      "[15:10:02] Finish counting 'kw2' for each user. △M: +91.5MB. △T: 35.7 seconds.\n",
      "[15:10:19] Finish counting 'kw3' for each user. △M: +81.49MB. △T: 16.2 seconds.\n",
      "[15:10:52] Finish counting 'topic1' for each user. △M: +88.34MB. △T: 33.9 seconds.\n",
      "[15:11:31] Finish counting 'topic2' for each user. △M: +93.06MB. △T: 38.6 seconds.\n",
      "[15:11:50] Finish counting 'topic3' for each user. △M: +79.32MB. △T: 19.0 seconds.\n",
      "[15:12:12] Finish counting 'appIdInstall' for each user. △M: +314.17MB. △T: 22.1 seconds.\n",
      "[15:12:31] Finish counting 'appIdAction' for each user. △M: -66.07MB. △T: 18.8 seconds.\n"
     ]
    }
   ],
   "source": [
    "feats_to_count = ['interest1', 'interest2', 'interest3', 'interest4', 'interest5', \n",
    "                  'kw1', 'kw2', 'kw3', \n",
    "                  'topic1', 'topic2', 'topic3', \n",
    "                  'appIdInstall', 'appIdAction'] \n",
    "df_user = None\n",
    "for feat_name in feats_to_count:\n",
    "    with pu.profiler(\"counting '{}' for each user\".format(feat_name)):\n",
    "        # preparation\n",
    "        count_name = \"valueCount@{}\".format(feat_name)\n",
    "\n",
    "        # load and count values\n",
    "        df_feat = du.load_user_feature(feat_name)\n",
    "        df_feat[count_name] = df_feat[feat_name].apply(count_values)\n",
    "        df_feat.drop(feat_name, axis=1, inplace=True)  # clean data for joining\n",
    "\n",
    "        # join data\n",
    "        if df_user is None:\n",
    "            df_user = df_feat\n",
    "        else:\n",
    "            df_user = uj.join(df_user, df_feat)\n",
    "\n",
    "        # release memory and clean garbage\n",
    "        del df_feat\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_groups = {\n",
    "    'interest': ['interest1', 'interest2', 'interest3', 'interest4', 'interest5'],\n",
    "    'kw': ['kw1', 'kw2', 'kw3'],\n",
    "    'topic': ['topic1', 'topic2', 'topic3'],\n",
    "    'app': ['appIdInstall', 'appIdAction']\n",
    "    \n",
    "}\n",
    "\n",
    "for name, feats in feat_groups.items():\n",
    "    all_count_name = 'allCount@{}'.format(name)\n",
    "    df_user[all_count_name] = 0\n",
    "    for feat in feats:\n",
    "        count_name = \"valueCount@{}\".format(feat)\n",
    "        df_user[all_count_name] += df_user[count_name]\n",
    "        df_user.drop(count_name, axis=1, inplace=True)  # clean data for joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:14:11] Finish saving user count data to .csv file. △M: +48.0KB. △T: 1.2 minutes.\n"
     ]
    }
   ],
   "source": [
    "with pu.profiler(\"saving user count data to .csv file\"):\n",
    "    count_folder = os.path.join(config.DATA_DIR, \"stats\", config.PRELIMINARY_CONTEST_DATA_SUBDIR[1:], \"row_value_counts\")\n",
    "    count_file = \"high_level.csv\"\n",
    "    count_path = os.path.join(count_folder, count_file)\n",
    "    os.makedirs(count_folder, exist_ok=True)\n",
    "\n",
    "    df_user.to_csv(count_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test2\")\n",
    "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "train_size = df_train.shape[0]\n",
    "test_size = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pu.profiler(\"joining user count data\"):\n",
    "    df_all = uj.join(df_all, df_user)\n",
    "    df_all.drop([\"aid\", \"uid\", \"label\"], axis=1, inplace=True)  # clean data for saving\n",
    "    gc.collect()\n",
    "\n",
    "with pu.profiler(\"preparing\"):\n",
    "    out_folder = config.INPUT_DIR\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    col_names = df_all.columns.tolist()\n",
    "    X_all = sparse.csr_matrix(df_all.values)\n",
    "    assert len(col_names) == len(feat_groups)\n",
    "    assert X_all.shape[1] == len(feat_groups)\n",
    "\n",
    "with pu.profiler(\"saving count data for the training set\"):\n",
    "    out_file = \"train.high_level.rowCount.pkl\"\n",
    "    out_path = os.path.join(out_folder, out_file)\n",
    "    X_train = X_all[:train_size, :]\n",
    "    assert X_train.shape[0] == df_train.shape[0]\n",
    "    assert X_train.shape[1] == len(feat_groups)\n",
    "\n",
    "    du.save_pickle((col_names, X_train), out_path)\n",
    "    del X_train\n",
    "    gc.collect()\n",
    "\n",
    "with pu.profiler(\"saving count data for the testing set\"):\n",
    "    out_file = \"test2.high_level.rowCount.pkl\"\n",
    "    out_path = os.path.join(out_folder, out_file)\n",
    "    X_test = X_all[train_size:, :]\n",
    "    assert X_test.shape[0] == df_test.shape[0]\n",
    "    assert X_test.shape[1] == len(feat_groups)\n",
    "    \n",
    "    du.save_pickle((col_names, X_test), out_path)\n",
    "    del X_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
