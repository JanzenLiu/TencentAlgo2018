{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from glove import Glove\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../../code/utils/\")\n",
    "sys.path.append(\"../../../code/analysis/\")\n",
    "sys.path.append('../../../code/pipeline/')\n",
    "sys.path.append('../../../code')\n",
    "import data_pipeline as dp\n",
    "import data_jointer as dj\n",
    "import eval_utils as eu\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_folder = os.path.join(config.DATA_DIR, \"embedding\")\n",
    "\n",
    "def embedding_path(feat_name, pooling=\"avg\", version_no=1, dataset=\"train\"):\n",
    "    emb_folder = os.path.join(embedding_folder, \"[featureName='{}']\".format(feat_name))\n",
    "    emb_file = \"{}.{}_v{}.pkl\".format(dataset, pooling, version_no)\n",
    "    emb_path = os.path.join(emb_folder, emb_file)\n",
    "    return emb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_feats = [\"interest2\", \"kw2\", \"topic2\"]\n",
    "\n",
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test2\")\n",
    "y = df_train[\"label\"].values.copy()\n",
    "y = (y + 1) / 2  # 1/-1 to 1/0\n",
    "\n",
    "n_splits = 2  # 3? 5? Don't know which one will be better\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=2018)  # for reproducibility\n",
    "split_indices = [(train_index, valid_index) for train_index, valid_index in skf.split(df_train, y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:32:15] Finish loading 'interest2' (min pooling). △M: +4.0KB. △T: 1.6 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:40:59] Finish fitting LR (fold 1/2). △M: +16.0MB. △T: 8.7 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:51:26] Finish fitting LR (fold 2/2). △M: -16.0KB. △T: 10.4 minutes.\n",
      "AUC: 0.578048(+/-0.000136)\n",
      "[18:51:34] Finish loading 'kw2' (avg pooling). △M: +2.06GB. △T: 5.9 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:58:15] Finish fitting LR (fold 1/2). △M: -8.0KB. △T: 6.7 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:07:40] Finish fitting LR (fold 2/2). △M: -24.0KB. △T: 9.3 minutes.\n",
      "AUC: 0.634801(+/-2.35e-05)\n",
      "[19:07:48] Finish loading 'kw2' (min pooling). △M: +2.06GB. △T: 5.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:22:52] Finish fitting LR (fold 1/2). △M: -12.0KB. △T: 15.0 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:32:47] Finish fitting LR (fold 2/2). △M: -12.0KB. △T: 9.9 minutes.\n",
      "AUC: 0.619814(+/-6.63e-05)\n",
      "[19:32:55] Finish loading 'topic2' (avg pooling). △M: +2.06GB. △T: 5.2 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:41:43] Finish fitting LR (fold 1/2). △M: -8.0KB. △T: 8.8 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:09] Finish fitting LR (fold 2/2). △M: -24.0KB. △T: 8.4 minutes.\n",
      "AUC: 0.595004(+/-0.000834)\n",
      "[19:50:16] Finish loading 'topic2' (min pooling). △M: +2.06GB. △T: 4.9 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:02:09] Finish fitting LR (fold 1/2). △M: -16.0KB. △T: 11.8 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:11:17] Finish fitting LR (fold 2/2). △M: -24.0KB. △T: 9.1 minutes.\n",
      "AUC: 0.587005(+/-0.000801)\n"
     ]
    }
   ],
   "source": [
    "df_stack_tv = pd.DataFrame()\n",
    "df_stack_test = pd.DataFrame()\n",
    "df_score = pd.DataFrame(columns=[\"featureName\", \"auc_mean\", \"auc_std\"])\n",
    "version_no = 1\n",
    "\n",
    "\n",
    "for feat_name in use_feats:\n",
    "    folder = os.path.join(embedding_folder, \"[featureName='{}']\".format(feat_name))\n",
    "    data_manager = dp.DataManager(folder)\n",
    "    \n",
    "    for pooling in [\"avg\", \"min\"]:\n",
    "        ### given a feature name and a pooling scheme ###\n",
    "        # load matrix as input to model\n",
    "        with pu.profiler(\"loading '{}' ({} pooling)\".format(feat_name, pooling)):\n",
    "            emb_loader = data_manager.build_data(\"{}_v{}\".format(pooling, version_no))\n",
    "            cols, X_tv = emb_loader.load(\"train\")\n",
    "            _, X_test = emb_loader.load(\"test2\")\n",
    "            \n",
    "        # prepare containers\n",
    "        stack_tv = np.zeros(X_tv.shape[0])\n",
    "        stack_test = np.zeros((X_test.shape[0], n_splits))\n",
    "        scores = np.zeros(n_splits)\n",
    "        \n",
    "        for i, (train_index, valid_index) in enumerate(split_indices):\n",
    "            ### given a splitting ###\n",
    "            # split train/valid sets\n",
    "            X_train, y_train = X_tv[train_index], y[train_index]\n",
    "            X_valid, y_valid = X_tv[valid_index], y[valid_index]\n",
    "\n",
    "            # fit LR\n",
    "            with pu.profiler(\"fitting LR (fold {}/{})\".format(i + 1, n_splits)):\n",
    "                lr = LogisticRegression(solver=\"newton-cg\", n_jobs=-1)  # use default setting: penalty='l2' and C=1\n",
    "                lr.fit(X_train, y_train)\n",
    "\n",
    "            # make prediction for validation set\n",
    "            proba_valid = lr.predict_proba(X_valid)[:, 1]\n",
    "            stack_tv[valid_index] = proba_valid\n",
    "\n",
    "            # make prediction for testing set\n",
    "            proba_test = lr.predict_proba(X_test)[:, 1]\n",
    "            stack_test[:, i] = proba_test\n",
    "\n",
    "            # calculate scores\n",
    "            auc = metrics.roc_auc_score(y_valid, proba_valid)\n",
    "            scores[i] = auc\n",
    "            \n",
    "         # update dataframe for stacking\n",
    "        emb_name = \"{}_emb_{}Pooling\".format(feat_name, pooling)\n",
    "        col_name = \"stackProba_{}\".format(emb_name)\n",
    "        score_row = {\"featureName\": emb_name, \n",
    "                     \"auc_mean\": scores.mean(), \n",
    "                     \"auc_std\": scores.std()}\n",
    "        df_stack_tv[col_name] = stack_tv\n",
    "        df_stack_test[col_name] = stack_test.mean(axis=1)\n",
    "        df_score.loc[df_score.shape[0]] = score_row\n",
    "        print(\"AUC: {:.6f}(+/-{:.3g})\".format(score_row[\"auc_mean\"], score_row[\"auc_std\"]))\n",
    "\n",
    "        del X_tv\n",
    "        del X_test\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Prediction Shape: (8798814, 6)\n",
      "Testing Set Prediction Shape: (2265879, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Prediction Shape: {}\".format(df_stack_tv.shape))\n",
    "print(\"Testing Set Prediction Shape: {}\".format(df_stack_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(config.DATA_DIR)\n",
    "out_folder = os.path.join(config.DATA_DIR, 'stacking/lr')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# remember to format float number or you will find these really hard-disk consumptive\n",
    "# save prediction for training set\n",
    "out_file = 'train.embedding.csv'\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "df_stack_tv.to_csv(out_path, float_format=\"%.6f\", index=False)\n",
    "\n",
    "# save prediction for testing set\n",
    "out_file = 'test2.embedding.csv'\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "df_stack_test.to_csv(out_path, float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save score information\n",
    "out_file = 'score.embedding.csv'\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "df_score = df_score[[\"featureName\", \"auc_mean\", \"auc_std\"]]\n",
    "df_score = df_score.sort_values(\"auc_mean\", ascending=False)\n",
    "df_score.to_csv(out_path, float_format=\"%.6f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:15:16] Finish getting matrix represenation. △M: +0B. △T: 0.2 seconds.\n",
      "[20:15:16] Finish saving matrix to hard disk. △M: -201.16MB. △T: 0.6 seconds.\n"
     ]
    }
   ],
   "source": [
    "out_folder = config.INPUT_DIR\n",
    "out_file = \"train.stacking.embedding.pkl\"\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "with pu.profiler(\"getting matrix represenation\"):\n",
    "    X_train = df_stack_tv.values.astype(np.float32)\n",
    "    assert X_train.shape[0] == df_train.shape[0]\n",
    "    assert X_train.shape[1] == len(use_feats) * 2\n",
    "\n",
    "with pu.profiler(\"saving matrix to hard disk\"):\n",
    "    col_names = df_stack_tv.columns.tolist()\n",
    "    du.save_pickle((col_names, X_train), out_path)\n",
    "    del X_train\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:15:20] Finish getting matrix represenation. △M: +103.73MB. △T: 0.2 seconds.\n",
      "[20:15:20] Finish saving matrix to hard disk. △M: +0B. △T: 0.2 seconds.\n"
     ]
    }
   ],
   "source": [
    "out_file = \"test2.stacking.embedding.pkl\"\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "\n",
    "with pu.profiler(\"getting matrix represenation\"):\n",
    "    X_test = df_stack_test.values.astype(np.float32)\n",
    "    assert X_test.shape[0] == df_test.shape[0]\n",
    "    assert X_test.shape[1] == len(use_feats) * 2\n",
    "\n",
    "with pu.profiler(\"saving matrix to hard disk\"):\n",
    "    col_names = df_stack_test.columns.tolist()\n",
    "    du.save_pickle((col_names, X_test), out_path)\n",
    "    del X_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
