{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from time import gmtime, strftime\n",
    "import gc\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../../../code/utils')\n",
    "from perf_utils import get_memory_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../../../data/raw/preliminary_contest_data/'\n",
    "USER_DATA_FILE = 'userFeature.preliminary.data'\n",
    "USER_DATA_PATH = os.path.join(DATA_DIR, USER_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_file_lines(filepath):\n",
    "    f = open(filepath)\n",
    "    for i, l in tqdm(enumerate(f.readlines())):\n",
    "        pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9686953 lines in userFeature.data\n",
      "Memory Usage at this moment: 61.0MB\n"
     ]
    }
   ],
   "source": [
    "# line_counts = count_file_lines(os.path.join(DATA_DIR, USER_DATA_FILE))  # comment this if you don't want to run it again\n",
    "line_counts = 9686953  # uncomment this to save time\n",
    "print(\"{} lines in userFeature.data\".format(line_counts))\n",
    "print(\"Memory Usage at this moment: {}\".format(get_memory_str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 9686953/9686953 [00:31<00:00, 306340.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage at this moment: 4.2GB\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "with open(USER_DATA_PATH) as f:\n",
    "    for i in tqdm(range(line_counts)):\n",
    "        line = f.readline().strip()\n",
    "        lines.append(line)\n",
    "print(\"Memory Usage at this moment: {}\".format(get_memory_str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_names = [\"age\", \"gender\", \"marriageStatus\", \"education\", \"consumptionAbility\", \"LBS\",\n",
    "              \"interest1\", \"interest2\", \"interest3\", \"interest4\", \"interest5\",\n",
    "              \"kw1\", \"kw2\", \"kw3\", \"topic1\", \"topic2\", \"topic3\", \"appIdInstall\",\n",
    "              \"appIdAction\", \"ct\", \"os\", \"carrier\", \"house\"]\n",
    "\n",
    "\n",
    "def fast_count_feature_from_lines(lines):  \n",
    "    # no checking, no uid, so faster\n",
    "    counters = {feat_name: Counter() for feat_name in feat_names}\n",
    "    n_lines = len(lines)\n",
    "    # for line in tqdm(lines):\n",
    "    for line in lines:\n",
    "        for feat in line.split(\"|\")[1:]:\n",
    "            arr = feat.split(\" \")\n",
    "            key = arr[0]\n",
    "            vals = arr[1:]\n",
    "            counters[key] += Counter(vals)\n",
    "    # print(\"[{}] worker's task done.\".format(strftime(\"%H:%M:%S\", gmtime())))\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_list(lst, n_split=4):\n",
    "    n_total = len(lst)\n",
    "    step = int(np.ceil(n_total / n_split))\n",
    "    splits = []\n",
    "    for offset in range(0, n_total, step):\n",
    "        splits.append(lst[offset:offset + step])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_counter_dicts(counter_dict_list):\n",
    "    final_counter_dict = {}\n",
    "    for feat_name in feat_names:\n",
    "        final_counter = Counter()\n",
    "        for counter_dict in counter_dict_list:\n",
    "            final_counter += counter_dict[feat_name]\n",
    "        final_counter_dict[feat_name] = final_counter\n",
    "    return final_counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_count_features(lines, n_procs=None, n_batches=None):\n",
    "    print(\"[{}] Starting counting features.\".format(strftime(\"%H:%M:%S\", gmtime())))\n",
    "    n_procs = mp.cpu_count() if n_procs is None else n_procs\n",
    "    print(1)\n",
    "    n_batches = mp.cpu_count() if n_batches is None else n_batches\n",
    "    print(2)\n",
    "    pool = mp.Pool(processes=n_procs)\n",
    "    print(3)\n",
    "    results = [pool.apply_async(fast_count_feature_from_lines, (batch, )) for batch in split_list(lines, n_procs)]\n",
    "    print(4)\n",
    "    pool.close()\n",
    "    print(5)\n",
    "    pool.join()\n",
    "    print(6)\n",
    "    counters_list = [result.get() for result in results]\n",
    "    print(\"[{}] All workers' tasks done. Combining results...\".format(strftime(\"%H:%M:%S\", gmtime())))\n",
    "    final_counter_dict = merge_counter_dicts(counters_list)\n",
    "    print(\"[{}] Combining Finished. Memory Usage: {}\".format(strftime(\"%H:%M:%S\", gmtime()), get_memory_str()))\n",
    "    return final_counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/500\n",
      "[16:22:14] Starting counting features.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "n_batches = 500\n",
    "line_batches = split_list(lines, n_batches)\n",
    "counter_dicts = []\n",
    "for i, line_batch in enumerate(line_batches):\n",
    "    print(\"Batch {}/{}\".format(i, n_batches))\n",
    "    counter_dicts.append(batch_count_features(line_batch, 4))\n",
    "print(\"Memory Usage at this moment: {}\".format(get_memory_str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[{}] Starting merging results.\".format(strftime(\"%H:%M:%S\", gmtime())))\n",
    "counter_dict = merge_counter_dicts(counter_dicts)\n",
    "print(\"[{}] Merging done.\".format(strftime(\"%H:%M:%S\", gmtime())))\n",
    "print(\"Memory Usage at this moment: {}\".format(get_memory_str()))                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(counter_dicts) > 0:\n",
    "    del counter_dicts[0]\n",
    "del counter_dicts\n",
    "gc.collect()\n",
    "print(\"Memory Usage at this moment: {}\".format(get_memory_str())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counter_to_csv(counter, filepath):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(\"value,counts\\n\")\n",
    "        for k, v in counter.most_common():\n",
    "            f.write(\"{},{}\\n\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_folder = out_folder = '../../../data/counter/preliminary_contest_data/'\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "for feat_name, counter in counter_dict.items():\n",
    "    out_file = \"userFeature.[featureName='{}'].csv\".format(feat_name)\n",
    "    out_path = os.path.join(out_folder, out_file)\n",
    "    counter_to_csv(counter, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_as_pickle(obj, filepath):\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_folder = '../../../data/vocabulary/preliminary_contest_data/'\n",
    "os.makedirs(vocab_folder, exist_ok=True)\n",
    "for feat_name, counter in counter_dict.items():\n",
    "    vocab_file = \"userFeature.[featureName='{}'].pkl\".format(feat_name)\n",
    "    vocab_path = os.path.join(vocab_folder, vocab_file)\n",
    "    save_as_pickle(list(counter.keys()), vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_counter_dict(counter_dict):\n",
    "    final_counter = Counter()\n",
    "    for name, counter in counter_dict.items():\n",
    "        new_counter = Counter({\"{}_{}\".format(name, k): v for k, v in counter.items()})\n",
    "        final_counter += new_counter\n",
    "    return final_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_counter = merge_counter_dict(counter_dict)\n",
    "print(\"Memory Usage at this moment: {}\".format(get_memory_str())) \n",
    "print(\"Cleaning memory...\")\n",
    "for feat_name in feat_names:\n",
    "    del counter_dict[feat_name]\n",
    "del counter_dict\n",
    "gc.collect()\n",
    "print(\"Memory Usage at this moment: {}\".format(get_memory_str())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_folder = '../../../data/counter/preliminary_contest_data/'\n",
    "out_file = \"userFeature.csv\"\n",
    "out_path = os.path.join(out_folder, out_file)\n",
    "counter_to_csv(large_counter, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_folder = '../../../data/vocabulary/preliminary_contest_data/'\n",
    "vocab_file = \"userFeature.pkl\"\n",
    "vocab_path = os.path.join(vocab_folder, vocab_file)\n",
    "save_as_pickle(list(large_counter.keys()), vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total feature value(word) counts: {}\".format(len(large_counter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
