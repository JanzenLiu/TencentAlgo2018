{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../../../data/raw/preliminary_contest_data/'\n",
    "ad_cnt_dir = '../../../data/nlp_count/preliminary_contest_data/byAdFeatureName/'\n",
    "user_cnt_dir = '../../../data/nlp_count/preliminary_contest_data/byUserFeatureName/'\n",
    "user_tfidf_dir = '../../../data/nlp_tfidf/preliminary_contest_data/byUserFeatureName/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(filename, **kw):\n",
    "    return pd.read_csv(os.path.join(data_dir, filename), **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pickle(filepath):\n",
    "    obj = None\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ad_cnt(feat_name):\n",
    "    filename = \"adFeature.[featureName='{}'].pkl\".format(feat_name)\n",
    "    filepath = os.path.join(ad_cnt_dir, filename)\n",
    "    index, matrix = load_pickle(filepath)\n",
    "    \n",
    "    filename = \"aid.pkl\".format(feat_name)\n",
    "    filepath = os.path.join(ad_cnt_dir, filename)\n",
    "    uid = load_pickle(filepath)\n",
    "    \n",
    "    return uid, (index, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_user_cnt(feat_name):\n",
    "    filename = \"userFeature.[featureName='{}'].pkl\".format(feat_name)\n",
    "    filepath = os.path.join(user_cnt_dir, filename)\n",
    "    index, matrix = load_pickle(filepath)\n",
    "    \n",
    "    filename = \"uid.pkl\".format(feat_name)\n",
    "    filepath = os.path.join(user_cnt_dir, filename)\n",
    "    uid = load_pickle(filepath)\n",
    "    \n",
    "    return uid, (index, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_user_tfidf(feat_name):\n",
    "    filename = \"userFeature.[featureName='{}'].pkl\".format(feat_name)\n",
    "    filepath = os.path.join(user_tfidf_dir, filename)\n",
    "    index, idf, matrix = load_pickle(filepath)\n",
    "    \n",
    "    filename = \"uid.pkl\".format(feat_name)\n",
    "    filepath = os.path.join(user_tfidf_dir, filename)\n",
    "    uid = load_pickle(filepath)\n",
    "    \n",
    "    return uid, (index, idf, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = load(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid, (ufeat_index, uvec) = load_user_cnt(\"interest1\")\n",
    "aid, (afeat_index, avec) = load_ad_cnt('aid')\n",
    "uid_to_index = dict(zip(uid, list(range(len(uid)))))  # mapping from uids to distinct indices\n",
    "aid_to_index = dict(zip(aid, list(range(len(aid)))))  # mapping from aids to distinct indices\n",
    "\n",
    "a_index = df_train['aid'].map(aid_to_index).values  # list of indices for matrix joining\n",
    "u_index = df_train['uid'].map(uid_to_index).values  # list of indices for matrix joining\n",
    "\n",
    "X = hstack((avec[a_index,:], uvec[u_index,:])).tocsr()  # joined user and advertise matrix\n",
    "y = (df_train['label'].values + 1) / 2\n",
    "\n",
    "X_train, y_train = X[:6000000], y[:6000000]\n",
    "X_valid, y_valid = X[6000000:], y[6000000:]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train.astype(np.float32), y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid.astype(np.float32), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's auc: 0.551884\tvalid1's auc: 0.551446\n",
      "[2]\ttrain's auc: 0.552501\tvalid1's auc: 0.552079\n",
      "[3]\ttrain's auc: 0.554068\tvalid1's auc: 0.553465\n",
      "[4]\ttrain's auc: 0.554547\tvalid1's auc: 0.553624\n",
      "[5]\ttrain's auc: 0.55593\tvalid1's auc: 0.555189\n",
      "[6]\ttrain's auc: 0.556199\tvalid1's auc: 0.555471\n",
      "[7]\ttrain's auc: 0.556544\tvalid1's auc: 0.555728\n",
      "[8]\ttrain's auc: 0.556614\tvalid1's auc: 0.555803\n",
      "[9]\ttrain's auc: 0.556687\tvalid1's auc: 0.555789\n",
      "[10]\ttrain's auc: 0.557061\tvalid1's auc: 0.556237\n",
      "[11]\ttrain's auc: 0.557105\tvalid1's auc: 0.556319\n",
      "[12]\ttrain's auc: 0.558209\tvalid1's auc: 0.557438\n",
      "[13]\ttrain's auc: 0.558242\tvalid1's auc: 0.55746\n",
      "[14]\ttrain's auc: 0.558856\tvalid1's auc: 0.557981\n",
      "[15]\ttrain's auc: 0.559374\tvalid1's auc: 0.558604\n",
      "[16]\ttrain's auc: 0.559669\tvalid1's auc: 0.558859\n",
      "[17]\ttrain's auc: 0.559779\tvalid1's auc: 0.559009\n",
      "[18]\ttrain's auc: 0.560642\tvalid1's auc: 0.559699\n",
      "[19]\ttrain's auc: 0.561354\tvalid1's auc: 0.560359\n",
      "[20]\ttrain's auc: 0.561735\tvalid1's auc: 0.560718\n",
      "[21]\ttrain's auc: 0.562115\tvalid1's auc: 0.560961\n",
      "[22]\ttrain's auc: 0.56247\tvalid1's auc: 0.561333\n",
      "[23]\ttrain's auc: 0.563242\tvalid1's auc: 0.56221\n",
      "[24]\ttrain's auc: 0.563748\tvalid1's auc: 0.562804\n",
      "[25]\ttrain's auc: 0.564122\tvalid1's auc: 0.563078\n",
      "[26]\ttrain's auc: 0.56433\tvalid1's auc: 0.56327\n",
      "[27]\ttrain's auc: 0.564708\tvalid1's auc: 0.563627\n",
      "[28]\ttrain's auc: 0.56506\tvalid1's auc: 0.563924\n",
      "[29]\ttrain's auc: 0.565171\tvalid1's auc: 0.563961\n",
      "[30]\ttrain's auc: 0.565346\tvalid1's auc: 0.564182\n",
      "[31]\ttrain's auc: 0.565484\tvalid1's auc: 0.56417\n",
      "[32]\ttrain's auc: 0.565808\tvalid1's auc: 0.564551\n",
      "[33]\ttrain's auc: 0.566139\tvalid1's auc: 0.564724\n",
      "[34]\ttrain's auc: 0.566534\tvalid1's auc: 0.565128\n",
      "[35]\ttrain's auc: 0.566979\tvalid1's auc: 0.565527\n",
      "[36]\ttrain's auc: 0.567286\tvalid1's auc: 0.565706\n",
      "[37]\ttrain's auc: 0.567577\tvalid1's auc: 0.566015\n",
      "[38]\ttrain's auc: 0.567727\tvalid1's auc: 0.566085\n",
      "[39]\ttrain's auc: 0.568126\tvalid1's auc: 0.56635\n",
      "[40]\ttrain's auc: 0.568398\tvalid1's auc: 0.566498\n",
      "[41]\ttrain's auc: 0.568795\tvalid1's auc: 0.566871\n",
      "[42]\ttrain's auc: 0.569072\tvalid1's auc: 0.567\n",
      "[43]\ttrain's auc: 0.569914\tvalid1's auc: 0.567737\n",
      "[44]\ttrain's auc: 0.570256\tvalid1's auc: 0.568071\n",
      "[45]\ttrain's auc: 0.570572\tvalid1's auc: 0.56831\n",
      "[46]\ttrain's auc: 0.571314\tvalid1's auc: 0.569016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-524557d27d65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgb_valid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 valid_names=['train', 'valid1'])\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\zs111\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zs111\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1521\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train.astype(np.float32), y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid.astype(np.float32), y_valid)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=[lgb_train, lgb_valid], \n",
    "                valid_names=['train', 'valid1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid, (ufeat_index, uidf, uvec) = load_user_tfidf(\"interest1\")\n",
    "uid_to_index = dict(zip(uid, list(range(len(uid)))))\n",
    "\n",
    "u_index = df_train['uid'].map(uid_to_index).values\n",
    "\n",
    "X = hstack((avec[a_index,:], uvec[u_index,:])).tocsr()\n",
    "\n",
    "X_train = X[:6000000]\n",
    "X_valid = X[6000000:]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train.astype(np.float32), y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid.astype(np.float32), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train.astype(np.float32), y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid.astype(np.float32), y_valid)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=300,\n",
    "                valid_sets=[lgb_train, lgb_valid], \n",
    "                valid_names=['train', 'valid1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(dataframe, test, features_u_want):\n",
    "    \n",
    "    aid, (afeat_index, avec) = load_ad_cnt('aid')\n",
    "    aid_to_index = dict(zip(aid, list(range(len(aid)))))  # mapping from aids to distinct indices\n",
    "    a_index = dataframe['aid'].map(aid_to_index).values  # list of indices for matrix joining\n",
    "    \n",
    "    id_index_vec = []                        \n",
    "    for each in features_u_want:\n",
    "        id_index_vec.append(load_user_cnt(each))           #eid, (efeat_index, evec) = load_user_cnt(\"education\")\n",
    "    print(1)\n",
    "    id2index = []                                        # mapping from uids to distinct indices\n",
    "    for each in id_index_vec:\n",
    "        id2index.append(dict(zip(each[0], list(range(len(each[0]))))))  # eid_to_index = dict(zip(eid, list(range(len(eid)))))\n",
    "    print(2)\n",
    "    # list of indices for matrix joining\n",
    "    \n",
    "    index_mapper = []\n",
    "    for each in id2index:\n",
    "        index_mapper.append(dataframe['uid'].map(each).values)     # e_index = dataframe['uid'].map(eid_to_index).values\n",
    "    print(3)\n",
    "    X = avec[a_index,:]\n",
    "    temp = hstack([id_index_vec[i][1][1][index_mapper[i],:] for i in range((len(id_index_vec)))])\n",
    "    X = hstack([X,temp]).tocsr()\n",
    "    \"\"\"\n",
    "    X = hstack((avec[a_index,:], evec[e_index,:], i1vec[i1_index, :], i2vec[i2_index, :], i3vec[i3_index, :],\n",
    "               i4vec[i4_index, :], i5vec[i5_index, :], k1vec[k1_index, :], k2vec[k2_index, :], k3vec[k3_index, :], \n",
    "               appvec[app_index, :], apivec[api_index, :])).tocsr()  # joined user and advertise matrix\"\"\"\n",
    "    if test==True:\n",
    "        return X\n",
    "    else:\n",
    "        y = (dataframe['label'].values + 1) / 2\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "X, y = get_set(df_train, test = False, features_u_want = ['education','interest1','interest2','interest3','interest4','interest5','kw1','kw2',\n",
    "                                       'kw3', 'appIdAction',  'appIdInstall'])\n",
    "X_train, y_train = X[:6000000], y[:6000000]\n",
    "X_valid, y_valid = X[6000000:], y[6000000:]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train.astype(np.float32), y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid.astype(np.float32), y_valid)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's auc: 0.538001\tvalid1's auc: 0.502577\n",
      "[2]\ttrain's auc: 0.541933\tvalid1's auc: 0.501816\n",
      "[3]\ttrain's auc: 0.545326\tvalid1's auc: 0.501699\n",
      "[4]\ttrain's auc: 0.545784\tvalid1's auc: 0.501627\n",
      "[5]\ttrain's auc: 0.551716\tvalid1's auc: 0.501393\n",
      "[6]\ttrain's auc: 0.556275\tvalid1's auc: 0.501179\n",
      "[7]\ttrain's auc: 0.55499\tvalid1's auc: 0.501474\n",
      "[8]\ttrain's auc: 0.555671\tvalid1's auc: 0.501438\n",
      "[9]\ttrain's auc: 0.560689\tvalid1's auc: 0.501415\n",
      "[10]\ttrain's auc: 0.563348\tvalid1's auc: 0.500891\n",
      "[11]\ttrain's auc: 0.564758\tvalid1's auc: 0.500698\n",
      "[12]\ttrain's auc: 0.564237\tvalid1's auc: 0.500907\n",
      "[13]\ttrain's auc: 0.563782\tvalid1's auc: 0.500833\n",
      "[14]\ttrain's auc: 0.564892\tvalid1's auc: 0.500825\n",
      "[15]\ttrain's auc: 0.564607\tvalid1's auc: 0.500949\n",
      "[16]\ttrain's auc: 0.564372\tvalid1's auc: 0.500875\n",
      "[17]\ttrain's auc: 0.564333\tvalid1's auc: 0.501014\n",
      "[18]\ttrain's auc: 0.565519\tvalid1's auc: 0.500895\n",
      "[19]\ttrain's auc: 0.565102\tvalid1's auc: 0.500953\n",
      "[20]\ttrain's auc: 0.564574\tvalid1's auc: 0.500987\n",
      "[21]\ttrain's auc: 0.5648\tvalid1's auc: 0.500889\n",
      "[22]\ttrain's auc: 0.567407\tvalid1's auc: 0.500946\n",
      "[23]\ttrain's auc: 0.568112\tvalid1's auc: 0.500862\n",
      "[24]\ttrain's auc: 0.568397\tvalid1's auc: 0.500834\n",
      "[25]\ttrain's auc: 0.568116\tvalid1's auc: 0.500987\n",
      "[26]\ttrain's auc: 0.571545\tvalid1's auc: 0.500732\n",
      "[27]\ttrain's auc: 0.570861\tvalid1's auc: 0.500826\n",
      "[28]\ttrain's auc: 0.571951\tvalid1's auc: 0.500734\n",
      "[29]\ttrain's auc: 0.571806\tvalid1's auc: 0.500756\n",
      "[30]\ttrain's auc: 0.572354\tvalid1's auc: 0.500707\n",
      "[31]\ttrain's auc: 0.579768\tvalid1's auc: 0.500487\n",
      "[32]\ttrain's auc: 0.583718\tvalid1's auc: 0.500324\n",
      "[33]\ttrain's auc: 0.600355\tvalid1's auc: 0.502496\n",
      "[34]\ttrain's auc: 0.602052\tvalid1's auc: 0.502396\n",
      "[35]\ttrain's auc: 0.602102\tvalid1's auc: 0.502342\n",
      "[36]\ttrain's auc: 0.602674\tvalid1's auc: 0.502221\n",
      "[37]\ttrain's auc: 0.602331\tvalid1's auc: 0.502289\n",
      "[38]\ttrain's auc: 0.599863\tvalid1's auc: 0.502966\n",
      "[39]\ttrain's auc: 0.600066\tvalid1's auc: 0.503029\n",
      "[40]\ttrain's auc: 0.609093\tvalid1's auc: 0.50493\n",
      "[41]\ttrain's auc: 0.611133\tvalid1's auc: 0.504661\n",
      "[42]\ttrain's auc: 0.612624\tvalid1's auc: 0.504548\n",
      "[43]\ttrain's auc: 0.615625\tvalid1's auc: 0.504349\n",
      "[44]\ttrain's auc: 0.613186\tvalid1's auc: 0.50298\n",
      "[45]\ttrain's auc: 0.61418\tvalid1's auc: 0.502864\n",
      "[46]\ttrain's auc: 0.616585\tvalid1's auc: 0.502662\n",
      "[47]\ttrain's auc: 0.619733\tvalid1's auc: 0.502628\n",
      "[48]\ttrain's auc: 0.619892\tvalid1's auc: 0.502548\n",
      "[49]\ttrain's auc: 0.61997\tvalid1's auc: 0.502492\n",
      "[50]\ttrain's auc: 0.61997\tvalid1's auc: 0.502341\n",
      "[51]\ttrain's auc: 0.622698\tvalid1's auc: 0.502195\n",
      "[52]\ttrain's auc: 0.626234\tvalid1's auc: 0.502052\n",
      "[53]\ttrain's auc: 0.630655\tvalid1's auc: 0.502203\n",
      "[54]\ttrain's auc: 0.630695\tvalid1's auc: 0.502172\n",
      "[55]\ttrain's auc: 0.633541\tvalid1's auc: 0.50251\n",
      "[56]\ttrain's auc: 0.633864\tvalid1's auc: 0.502456\n",
      "[57]\ttrain's auc: 0.634115\tvalid1's auc: 0.502542\n",
      "[58]\ttrain's auc: 0.634482\tvalid1's auc: 0.502303\n",
      "[59]\ttrain's auc: 0.635297\tvalid1's auc: 0.502306\n",
      "[60]\ttrain's auc: 0.635646\tvalid1's auc: 0.502258\n",
      "[61]\ttrain's auc: 0.63587\tvalid1's auc: 0.502236\n",
      "[62]\ttrain's auc: 0.639233\tvalid1's auc: 0.502393\n",
      "[63]\ttrain's auc: 0.639457\tvalid1's auc: 0.502418\n",
      "[64]\ttrain's auc: 0.639457\tvalid1's auc: 0.502418\n",
      "[65]\ttrain's auc: 0.639293\tvalid1's auc: 0.502431\n",
      "[66]\ttrain's auc: 0.639371\tvalid1's auc: 0.502358\n",
      "[67]\ttrain's auc: 0.642092\tvalid1's auc: 0.502947\n",
      "[68]\ttrain's auc: 0.644324\tvalid1's auc: 0.503114\n",
      "[69]\ttrain's auc: 0.644278\tvalid1's auc: 0.503123\n",
      "[70]\ttrain's auc: 0.644209\tvalid1's auc: 0.503196\n",
      "[71]\ttrain's auc: 0.644006\tvalid1's auc: 0.503191\n",
      "[72]\ttrain's auc: 0.64401\tvalid1's auc: 0.503206\n",
      "[73]\ttrain's auc: 0.64401\tvalid1's auc: 0.503205\n",
      "[74]\ttrain's auc: 0.644008\tvalid1's auc: 0.503212\n",
      "[75]\ttrain's auc: 0.646851\tvalid1's auc: 0.503612\n",
      "[76]\ttrain's auc: 0.646847\tvalid1's auc: 0.503522\n",
      "[77]\ttrain's auc: 0.645614\tvalid1's auc: 0.50351\n",
      "[78]\ttrain's auc: 0.6467\tvalid1's auc: 0.503706\n",
      "[79]\ttrain's auc: 0.647597\tvalid1's auc: 0.503582\n",
      "[80]\ttrain's auc: 0.647661\tvalid1's auc: 0.503606\n",
      "[81]\ttrain's auc: 0.64756\tvalid1's auc: 0.50358\n",
      "[82]\ttrain's auc: 0.651144\tvalid1's auc: 0.503287\n",
      "[83]\ttrain's auc: 0.651083\tvalid1's auc: 0.503255\n",
      "[84]\ttrain's auc: 0.651505\tvalid1's auc: 0.503391\n",
      "[85]\ttrain's auc: 0.651434\tvalid1's auc: 0.503348\n",
      "[86]\ttrain's auc: 0.653448\tvalid1's auc: 0.503192\n",
      "[87]\ttrain's auc: 0.653295\tvalid1's auc: 0.503107\n",
      "[88]\ttrain's auc: 0.653307\tvalid1's auc: 0.502953\n",
      "[89]\ttrain's auc: 0.653271\tvalid1's auc: 0.5029\n",
      "[90]\ttrain's auc: 0.653192\tvalid1's auc: 0.502823\n",
      "[91]\ttrain's auc: 0.653237\tvalid1's auc: 0.502803\n",
      "[92]\ttrain's auc: 0.652931\tvalid1's auc: 0.503142\n",
      "[93]\ttrain's auc: 0.652909\tvalid1's auc: 0.503138\n",
      "[94]\ttrain's auc: 0.653536\tvalid1's auc: 0.503131\n",
      "[95]\ttrain's auc: 0.655684\tvalid1's auc: 0.503426\n",
      "[96]\ttrain's auc: 0.656351\tvalid1's auc: 0.503359\n",
      "[97]\ttrain's auc: 0.656464\tvalid1's auc: 0.503365\n",
      "[98]\ttrain's auc: 0.659233\tvalid1's auc: 0.503572\n",
      "[99]\ttrain's auc: 0.661047\tvalid1's auc: 0.503799\n",
      "[100]\ttrain's auc: 0.661172\tvalid1's auc: 0.503813\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train.astype(np.float32), y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid.astype(np.float32), y_valid)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=[lgb_train, lgb_valid], \n",
    "                valid_names=['train', 'valid1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1066 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zs111\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 17.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression   \n",
    "from sklearn import metrics\n",
    "lr = LogisticRegression('l2', solver = 'sag', class_weight = 'balanced', verbose = 1)\n",
    "logisticR = lr.fit(X_train, y_train)\n",
    "lr_pred = logisticR.predict_proba(X_valid)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# save model\n",
    "joblib.dump(logisticR, 'lr.pkl')\n",
    "gbm.save_model('model.txt')\n",
    "# load model\n",
    "# bst = lgb.Booster(model_file='model.txt')\n",
    "# lr_pickle = joblib.load('lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build X_test\n",
    "gc.collect()\n",
    "df_test = load(\"test1.csv\")\n",
    "X = get_set(df_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_predict = logisticR.predict_proba(X)\n",
    "gbm_predict = gbm.predict(X.astype(np.float32))\n",
    "emsembled = 0.7*gbm_predict+0.3*lr_predict[:,1]z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['score'] = [round(each, 8) for each in emsembled]\n",
    "df_test.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2265989, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
