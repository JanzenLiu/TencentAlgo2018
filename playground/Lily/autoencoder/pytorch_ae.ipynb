{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import sys\n",
    "sys.path.append('../../../code/utils/')\n",
    "sys.path.append('../../../code/feature/')\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import gc\n",
    "from scipy.sparse import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "get_device is not implemented for type torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2c3a9dedf296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnon_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_cuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: get_device is not implemented for type torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1,2,3]).to(device)\n",
    "print(t.get_device())\n",
    "non_cuda = torch.FloatTensor([1,2,3])\n",
    "print(non_cuda.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20180429)    # reproducible\n",
    "# Hyper Parameters\n",
    "EPOCH = 100                                       #Haven't figured out, let these just be here\n",
    "BATCH_SIZE = 256\n",
    "LR = 5e-5         # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_to_tensor(csr_matrix, size):\n",
    "    data = csr_matrix.data\n",
    "    indices = csr_matrix.indices\n",
    "    \n",
    "    # http://pytorch.org/docs/stable/sparse.html\n",
    "    i = torch.LongTensor([[0, num] for num in indices], device=device)\n",
    "    v = torch.FloatTensor(data.astype(np.float), device=device)\n",
    "    result_tensor = torch.sparse.FloatTensor(i.t(), v, size, device=device).to_dense()\n",
    "    return result_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you should convert data into formats that torch accepts\n",
    "# Make a dataloader\n",
    "class MyDataset(Data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.label = y\n",
    "\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        # convert self.input[index] to tensor\n",
    "        input_item = self.input[index]\n",
    "        x = csr_to_tensor(input_item, torch.Size([1,self.input.shape[1]]))\n",
    "        \n",
    "        # convert self.label[index] to tensor\n",
    "        y = torch.tensor(self.label[index])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we should probably define the auto-encoder\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 32),\n",
    "        ).to(device)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, input_size),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x.to(device))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 728)\t1\n",
      "  (0, 893)\t1\n",
      "  (0, 908)\t1\n",
      "  (0, 923)\t1\n",
      "  (0, 941)\t1\n",
      "  (0, 985)\t1\n",
      "  (0, 986)\t1\n",
      "  (0, 1004)\t1\n",
      "  (0, 1092)\t1\n",
      "  (0, 1103)\t1\n",
      "  (0, 1114)\t1\n",
      "  (0, 1251)\t1\n",
      "  (0, 28269)\t1\n",
      "  (0, 114175)\t1\n",
      "  (0, 122177)\t1\n",
      "  (0, 177443)\t1\n",
      "  (0, 177584)\t1\n",
      "  (0, 310357)\t1\n",
      "  (0, 322279)\t1\n",
      "  (0, 323861)\t1\n",
      "  (0, 324111)\t1\n",
      "  (0, 324797)\t1\n",
      "  (0, 329213)\t1\n",
      "  (0, 330004)\t1\n",
      "  (0, 342260)\t1\n",
      "  (0, 348133)\t1\n",
      "  (0, 412989)\t1\n",
      "  (0, 419204)\t1\n",
      "  (0, 419206)\t1\n",
      "  (0, 419260)\t1\n",
      "  (0, 419395)\t1\n",
      "  (0, 419567)\t1\n",
      "  (0, 419658)\t1\n",
      "  (0, 419775)\t1\n",
      "  (0, 419790)\t1\n",
      "  (0, 419825)\t1\n",
      "  (0, 419859)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_train = du.load_raw_data(\"train\")\n",
    "gc.collect()\n",
    "\n",
    "# train_X: (8798814, 374251)\n",
    "# train_y: (8798814,)\n",
    "\n",
    "train_X = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/xxx.pkl') # on Server\n",
    "train_y = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/yyy.pkl')\n",
    "#train_X, train_y = du.get_set(df_train, test = False, features_u_want = ['house', 'interest2', 'kw1', 'kw2',  'appIdInstall'], a_features_u_want = ['aid', 'productId'])\n",
    "\n",
    "print(train_X[0]) # eg. (0, 1) is the position of non-zero data whose value is 1\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:43] Finish Setting up autoencoder. △M: +1.48GB. △T: 4.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pu.profiler(\"Setting up autoencoder\"):\n",
    "    autoencoder = AutoEncoder(train_X.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR, weight_decay = 1e-5)\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], samples[256/8798814], loss:0.00593919\n",
      "end time: 14:01:46\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[2816/8798814], loss:0.00531732\n",
      "end time: 14:01:57\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[5376/8798814], loss:0.00492823\n",
      "end time: 14:02:09\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[7936/8798814], loss:0.00466196\n",
      "end time: 14:02:20\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[10496/8798814], loss:0.00445479\n",
      "end time: 14:02:31\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[13056/8798814], loss:0.00426609\n",
      "end time: 14:02:42\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[15616/8798814], loss:0.00410123\n",
      "end time: 14:02:54\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[18176/8798814], loss:0.00394280\n",
      "end time: 14:03:05\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[20736/8798814], loss:0.00379502\n",
      "end time: 14:03:16\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[23296/8798814], loss:0.00364970\n",
      "end time: 14:03:28\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[25856/8798814], loss:0.00353435\n",
      "end time: 14:03:39\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader): # step: batch index; x.shape: [BATCH_SIZE, 1, 374251]; y.shape: [BATCH_SIZE]   \n",
    "        b_x = torch.tensor(x).to(device)                   # batch x\n",
    "        b_y = torch.tensor(x).to(device)\n",
    "        b_label = torch.tensor(y).to(device)               # batch label\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = criterion(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step since gradients are accumulated in the process\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients. \"The function can be called once the gradients are computed using eg. backward()\"\n",
    "\n",
    "        # Currently the training speed is really slow, change the numbers below according to what you need\n",
    "        if step % 10 == 0:\n",
    "            print('epoch [{}/{}], samples[{}/{}], loss:{:.8f}'\n",
    "                  .format(epoch + 1, EPOCH, (step + 1) * BATCH_SIZE, train_X.shape[0], loss.item()))\n",
    "            print('end time: {}'.format(pu.get_time_str()))\n",
    "            print('-' * 80)\n",
    "        if step == 100:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input = train_dataset.input[0]\n",
    "first_data = csr_to_tensor(first_input, torch.Size([1,first_input.shape[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data, _ = autoencoder(first_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1276,  0.1587,  0.0816, -0.0512,  0.1101,  0.0090,  0.1257,\n",
       "         -0.0423, -0.1263, -0.0075, -0.0329, -0.0233, -0.1533, -0.0071,\n",
       "          0.0448,  0.0120, -0.0661,  0.0033, -0.1367,  0.0635,  0.0082,\n",
       "          0.0133, -0.0374,  0.0835,  0.0618,  0.0555, -0.0762, -0.1035,\n",
       "          0.0736,  0.1615,  0.1884, -0.0919]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
