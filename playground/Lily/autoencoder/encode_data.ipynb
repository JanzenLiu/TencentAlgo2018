{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../../code/utils/')\n",
    "import perf_utils as pu\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20180429)    # reproducible\n",
    "# Hyper Parameters                                      #Haven't figured out, let these just be here\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_to_tensor(csr_matrix, size):\n",
    "    data = csr_matrix.data\n",
    "    indices = csr_matrix.indices\n",
    "    \n",
    "    # http://pytorch.org/docs/stable/sparse.html\n",
    "    i = torch.LongTensor([[0, num] for num in indices], device=device)\n",
    "    v = torch.FloatTensor(data.astype(np.float), device=device)\n",
    "    result_tensor = torch.sparse.FloatTensor(i.t(), v, size, device=device).to_dense()\n",
    "    return result_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you should convert data into formats that torch accepts\n",
    "# Make a dataloader\n",
    "class MyDataset(Data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.label = y\n",
    "\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        # convert self.input[index] to tensor\n",
    "        input_item = self.input[index]\n",
    "        x = csr_to_tensor(input_item, torch.Size([1,self.input.shape[1]]))\n",
    "        \n",
    "        # convert self.label[index] to tensor\n",
    "        y = torch.tensor(self.label[index])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 32),\n",
    "        ).to(device)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, input_size),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x.to(device))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = torch.load('./useall_step16000_ae_full_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/xxx.pkl') # on Server\n",
    "train_y = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/yyy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8798814, 419862)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8798814,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_index = 21001\n",
    "new_start_index = completed_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_train_X = train_X[new_start_index*256:,]\n",
    "remaining_train_y = train_y[new_start_index*256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3422302, 419862)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3422302,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_X.shape[0] - (completed_index + 1) * BATCH_SIZE == remaining_train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = MyDataset(remaining_train_X, remaining_train_y)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "del train_X\n",
    "del train_y\n",
    "del remaining_train_X\n",
    "del remaining_train_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = joblib.load('./encoded_data_step{}.pkl'.format(completed_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21002"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from step 21002\n",
      "Step 21002, Current time: 05:06:22\n",
      "Step 21302, Current time: 05:10:15\n",
      "Step 21602, Current time: 05:14:15\n",
      "Step 21902, Current time: 05:18:17\n",
      "Step 22202, Current time: 05:22:16\n",
      "Step 22502, Current time: 05:26:03\n",
      "Step 22802, Current time: 05:29:50\n",
      "Step 23102, Current time: 05:33:35\n",
      "Step 23402, Current time: 05:37:19\n",
      "Step 23702, Current time: 05:41:06\n",
      "Step 24002, Current time: 05:44:52\n",
      "Step 24302, Current time: 05:48:40\n",
      "Step 24602, Current time: 05:52:23\n",
      "Step 24902, Current time: 05:56:07\n",
      "Step 25202, Current time: 05:59:52\n",
      "Step 25502, Current time: 06:03:36\n",
      "Step 25802, Current time: 06:07:23\n",
      "Step 26102, Current time: 06:11:09\n",
      "Step 26402, Current time: 06:14:54\n",
      "Step 26702, Current time: 06:18:41\n",
      "Step 27002, Current time: 06:22:29\n",
      "Step 27302, Current time: 06:26:18\n",
      "Step 27602, Current time: 06:30:02\n",
      "Step 27902, Current time: 06:33:45\n",
      "Step 28202, Current time: 06:37:33\n",
      "Step 28502, Current time: 06:41:19\n",
      "Step 28802, Current time: 06:45:05\n",
      "Step 29102, Current time: 06:48:49\n",
      "Step 29402, Current time: 06:52:36\n",
      "Step 29702, Current time: 06:56:22\n",
      "Step 30002, Current time: 07:00:10\n",
      "Step 30302, Current time: 07:04:01\n",
      "Step 30602, Current time: 07:07:47\n",
      "Step 30902, Current time: 07:11:31\n",
      "Step 31202, Current time: 07:15:13\n",
      "Step 31502, Current time: 07:19:01\n",
      "Step 31802, Current time: 07:22:49\n",
      "Step 32102, Current time: 07:26:37\n",
      "Step 32402, Current time: 07:30:28\n",
      "Step 32702, Current time: 07:34:16\n",
      "Step 33002, Current time: 07:38:04\n",
      "Step 33302, Current time: 07:41:54\n",
      "Step 33602, Current time: 07:45:39\n",
      "Step 33902, Current time: 07:49:25\n",
      "Step 34202, Current time: 07:53:13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./encoded_data.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Start from step {}'.format(new_start_index)) # step starts from 0\n",
    "for step, (x, y) in enumerate(train_loader): # step: batch index; x.shape: [BATCH_SIZE, 1, 374251]; y.shape: [BATCH_SIZE]   \n",
    "    b_x = torch.tensor(x).to(device)                   # batch x\n",
    "    b_label = torch.tensor(y).to(device)               # batch label\n",
    "\n",
    "    encoded, _ = ae(b_x)\n",
    "    results.append(np.asarray(encoded.detach().cpu().numpy(), dtype=np.float32))\n",
    "    if step % 300 == 0:\n",
    "        print('Step {}, Current time: {}'.format(step + new_start_index, pu.get_time_str()))\n",
    "    if step % 3000 == 0:\n",
    "        joblib.dump(results, './encoded_data_step{}.pkl'.format(step + new_start_index))\n",
    "joblib.dump(results, './encoded_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
