{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import sys\n",
    "sys.path.append('../../../code/utils/')\n",
    "sys.path.append('../../../code/feature/')\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import gc\n",
    "from scipy.sparse import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU count: 2\n",
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpu_count = torch.cuda.device_count()\n",
    "print('GPU count:', gpu_count)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20180429)    # reproducible\n",
    "# Hyper Parameters\n",
    "EPOCH = 1                                       #Haven't figured out, let these just be here\n",
    "BATCH_SIZE = 256\n",
    "LR = 5e-5         # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_to_tensor(csr_matrix, size):\n",
    "    data = csr_matrix.data\n",
    "    indices = csr_matrix.indices\n",
    "    \n",
    "    # http://pytorch.org/docs/stable/sparse.html\n",
    "    i = torch.LongTensor([[0, num] for num in indices], device=device)\n",
    "    v = torch.FloatTensor(data.astype(np.float), device=device)\n",
    "    result_tensor = torch.sparse.FloatTensor(i.t(), v, size, device=device).to_dense()\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you should convert data into formats that torch accepts\n",
    "# Make a dataloader\n",
    "class MyDataset(Data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.label = y\n",
    "\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        # convert self.input[index] to tensor\n",
    "        input_item = self.input[index]\n",
    "        x = csr_to_tensor(input_item, torch.Size([1,self.input.shape[1]]))\n",
    "        \n",
    "        # convert self.label[index] to tensor\n",
    "        y = torch.tensor(self.label[index])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we should probably define the auto-encoder\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 32),\n",
    "        ).to(device)\n",
    "        self.encoder = nn.DataParallel(self.encoder)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, input_size),\n",
    "        ).to(device)\n",
    "        self.decoder = nn.DataParallel(self.decoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x.to(device)\n",
    "        print('\\tIn Model: input size', input.size())\n",
    "        encoded = self.encoder(input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 728)\t1\n",
      "  (0, 893)\t1\n",
      "  (0, 908)\t1\n",
      "  (0, 923)\t1\n",
      "  (0, 941)\t1\n",
      "  (0, 985)\t1\n",
      "  (0, 986)\t1\n",
      "  (0, 1004)\t1\n",
      "  (0, 1092)\t1\n",
      "  (0, 1103)\t1\n",
      "  (0, 1114)\t1\n",
      "  (0, 1251)\t1\n",
      "  (0, 28269)\t1\n",
      "  (0, 114175)\t1\n",
      "  (0, 122177)\t1\n",
      "  (0, 177443)\t1\n",
      "  (0, 177584)\t1\n",
      "  (0, 310357)\t1\n",
      "  (0, 322279)\t1\n",
      "  (0, 323861)\t1\n",
      "  (0, 324111)\t1\n",
      "  (0, 324797)\t1\n",
      "  (0, 329213)\t1\n",
      "  (0, 330004)\t1\n",
      "  (0, 342260)\t1\n",
      "  (0, 348133)\t1\n",
      "  (0, 412989)\t1\n",
      "  (0, 419204)\t1\n",
      "  (0, 419206)\t1\n",
      "  (0, 419260)\t1\n",
      "  (0, 419395)\t1\n",
      "  (0, 419567)\t1\n",
      "  (0, 419658)\t1\n",
      "  (0, 419775)\t1\n",
      "  (0, 419790)\t1\n",
      "  (0, 419825)\t1\n",
      "  (0, 419859)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_train = du.load_raw_data(\"train\")\n",
    "gc.collect()\n",
    "\n",
    "# train_X: (8798814, 374251)\n",
    "# train_y: (8798814,)\n",
    "\n",
    "train_X = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/xxx.pkl') # on Server\n",
    "train_y = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/yyy.pkl')\n",
    "#train_X, train_y = du.get_set(df_train, test = False, features_u_want = ['house', 'interest2', 'kw1', 'kw2',  'appIdInstall'], a_features_u_want = ['aid', 'productId'])\n",
    "\n",
    "print(train_X[0]) # eg. (0, 1) is the position of non-zero data whose value is 1\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:03:53] Finish Setting up autoencoder. △M: +0B. △T: 1.1 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pu.profiler(\"Setting up autoencoder\"):\n",
    "    autoencoder = AutoEncoder(train_X.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR, weight_decay = 1e-5)\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): DataParallel(\n",
       "    (module): Sequential(\n",
       "      (0): Linear(in_features=419862, out_features=128, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): DataParallel(\n",
       "    (module): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=128, out_features=419862, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = AutoEncoder(train_X.shape[1])\n",
    "autoencoer = nn.DataParallel(autoencoder)\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_X, train_y)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "epoch [1/1], samples[256/8798814], loss:0.00629466\n",
      "end time: 15:08:26\n",
      "--------------------------------------------------------------------------------\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "epoch [1/1], samples[2816/8798814], loss:0.00628878\n",
      "end time: 15:08:39\n",
      "--------------------------------------------------------------------------------\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "epoch [1/1], samples[5376/8798814], loss:0.00628681\n",
      "end time: 15:08:51\n",
      "--------------------------------------------------------------------------------\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n",
      "Outside: input size torch.Size([256, 1, 419862])\n",
      "\tIn Model: input size torch.Size([256, 1, 419862])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6fb34ad84b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# step: batch index; x.shape: [BATCH_SIZE, 1, 374251]; y.shape: [BATCH_SIZE]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mb_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# batch x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mb_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# batch label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader): # step: batch index; x.shape: [BATCH_SIZE, 1, 374251]; y.shape: [BATCH_SIZE]   \n",
    "        b_x = torch.tensor(x).to(device)                   # batch x\n",
    "        b_y = torch.tensor(x).to(device)\n",
    "        b_label = torch.tensor(y).to(device)               # batch label\n",
    "        print('Outside: input size', b_x.size())\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = criterion(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step since gradients are accumulated in the process\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients. \"The function can be called once the gradients are computed using eg. backward()\"\n",
    "\n",
    "        # Currently the training speed is really slow, change the numbers below according to what you need\n",
    "        if step % 10 == 0:\n",
    "            print('epoch [{}/{}], samples[{}/{}], loss:{:.8f}'\n",
    "                  .format(epoch + 1, EPOCH, (step + 1) * BATCH_SIZE, train_X.shape[0], loss.item()))\n",
    "            print('end time: {}'.format(pu.get_time_str()))\n",
    "            print('-' * 80)\n",
    "#         if step == 100:\n",
    "#             break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
