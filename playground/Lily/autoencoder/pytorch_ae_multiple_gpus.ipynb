{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import sys\n",
    "sys.path.append('../../../code/utils/')\n",
    "sys.path.append('../../../code/feature/')\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import gc\n",
    "from scipy.sparse import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU count: 2\n",
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpu_count = torch.cuda.device_count()\n",
    "print('GPU count:', gpu_count)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20180429)    # reproducible\n",
    "# Hyper Parameters\n",
    "EPOCH = 1                                       #Haven't figured out, let these just be here\n",
    "BATCH_SIZE = 256\n",
    "LR = 5e-5         # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_to_tensor(csr_matrix, size):\n",
    "    data = csr_matrix.data\n",
    "    indices = csr_matrix.indices\n",
    "    \n",
    "    # http://pytorch.org/docs/stable/sparse.html\n",
    "    i = torch.LongTensor([[0, num] for num in indices], device=device)\n",
    "    v = torch.FloatTensor(data.astype(np.float), device=device)\n",
    "    result_tensor = torch.sparse.FloatTensor(i.t(), v, size, device=device).to_dense()\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you should convert data into formats that torch accepts\n",
    "# Make a dataloader\n",
    "class MyDataset(Data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.label = y\n",
    "\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        # convert self.input[index] to tensor\n",
    "        input_item = self.input[index]\n",
    "        x = csr_to_tensor(input_item, torch.Size([1,self.input.shape[1]]))\n",
    "        \n",
    "        # convert self.label[index] to tensor\n",
    "        y = torch.tensor(self.label[index])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we should probably define the auto-encoder\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 32),\n",
    "        ).to(device)\n",
    "        self.encoder = nn.DataParallel(self.encoder)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, input_size),\n",
    "        ).to(device)\n",
    "        self.decoder = nn.DataParallel(self.decoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x.to(device)\n",
    "        encoded = self.encoder(input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 728)\t1\n",
      "  (0, 893)\t1\n",
      "  (0, 908)\t1\n",
      "  (0, 923)\t1\n",
      "  (0, 941)\t1\n",
      "  (0, 985)\t1\n",
      "  (0, 986)\t1\n",
      "  (0, 1004)\t1\n",
      "  (0, 1092)\t1\n",
      "  (0, 1103)\t1\n",
      "  (0, 1114)\t1\n",
      "  (0, 1251)\t1\n",
      "  (0, 28269)\t1\n",
      "  (0, 114175)\t1\n",
      "  (0, 122177)\t1\n",
      "  (0, 177443)\t1\n",
      "  (0, 177584)\t1\n",
      "  (0, 310357)\t1\n",
      "  (0, 322279)\t1\n",
      "  (0, 323861)\t1\n",
      "  (0, 324111)\t1\n",
      "  (0, 324797)\t1\n",
      "  (0, 329213)\t1\n",
      "  (0, 330004)\t1\n",
      "  (0, 342260)\t1\n",
      "  (0, 348133)\t1\n",
      "  (0, 412989)\t1\n",
      "  (0, 419204)\t1\n",
      "  (0, 419206)\t1\n",
      "  (0, 419260)\t1\n",
      "  (0, 419395)\t1\n",
      "  (0, 419567)\t1\n",
      "  (0, 419658)\t1\n",
      "  (0, 419775)\t1\n",
      "  (0, 419790)\t1\n",
      "  (0, 419825)\t1\n",
      "  (0, 419859)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_train = du.load_raw_data(\"train\")\n",
    "gc.collect()\n",
    "\n",
    "# train_X: (8798814, 374251)\n",
    "# train_y: (8798814,)\n",
    "\n",
    "train_X = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/xxx.pkl') # on Server\n",
    "train_y = joblib.load('../../../../../zhangez698/TencentAlgo2018/playground/Elvin/autoencoder/yyy.pkl')\n",
    "#train_X, train_y = du.get_set(df_train, test = False, features_u_want = ['house', 'interest2', 'kw1', 'kw2',  'appIdInstall'], a_features_u_want = ['aid', 'productId'])\n",
    "\n",
    "print(train_X[0]) # eg. (0, 1) is the position of non-zero data whose value is 1\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:59] Finish Setting up autoencoder. △M: +1.48GB. △T: 4.8 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pu.profiler(\"Setting up autoencoder\"):\n",
    "    autoencoder = AutoEncoder(train_X.shape[1])\n",
    "    autoencoer = nn.DataParallel(autoencoder)\n",
    "    autoencoder.to(device)\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR, weight_decay = 1e-5)\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_X, train_y)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], samples[256/8798814], loss:0.00593919\n",
      "end time: 15:56:06\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[2816/8798814], loss:0.00531732\n",
      "end time: 15:56:19\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[5376/8798814], loss:0.00492823\n",
      "end time: 15:56:31\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[7936/8798814], loss:0.00466196\n",
      "end time: 15:56:43\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[10496/8798814], loss:0.00445479\n",
      "end time: 15:56:56\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[13056/8798814], loss:0.00426609\n",
      "end time: 15:57:08\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[15616/8798814], loss:0.00410123\n",
      "end time: 15:57:21\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[18176/8798814], loss:0.00394280\n",
      "end time: 15:57:33\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[20736/8798814], loss:0.00379502\n",
      "end time: 15:57:46\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[23296/8798814], loss:0.00364970\n",
      "end time: 15:57:58\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[25856/8798814], loss:0.00353435\n",
      "end time: 15:58:10\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[28416/8798814], loss:0.00338907\n",
      "end time: 15:58:23\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[30976/8798814], loss:0.00327485\n",
      "end time: 15:58:35\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[33536/8798814], loss:0.00315346\n",
      "end time: 15:58:48\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[36096/8798814], loss:0.00305178\n",
      "end time: 15:59:00\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[38656/8798814], loss:0.00293246\n",
      "end time: 15:59:13\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[41216/8798814], loss:0.00284919\n",
      "end time: 15:59:25\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[43776/8798814], loss:0.00274974\n",
      "end time: 15:59:37\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[46336/8798814], loss:0.00266033\n",
      "end time: 15:59:50\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[48896/8798814], loss:0.00257309\n",
      "end time: 16:00:02\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[51456/8798814], loss:0.00248436\n",
      "end time: 16:00:15\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[54016/8798814], loss:0.00241938\n",
      "end time: 16:00:27\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[56576/8798814], loss:0.00234059\n",
      "end time: 16:00:40\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[59136/8798814], loss:0.00228349\n",
      "end time: 16:00:52\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[61696/8798814], loss:0.00221884\n",
      "end time: 16:01:05\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[64256/8798814], loss:0.00216484\n",
      "end time: 16:01:17\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[66816/8798814], loss:0.00210280\n",
      "end time: 16:01:30\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[69376/8798814], loss:0.00203937\n",
      "end time: 16:01:42\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[71936/8798814], loss:0.00199641\n",
      "end time: 16:01:54\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[74496/8798814], loss:0.00194950\n",
      "end time: 16:02:07\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[77056/8798814], loss:0.00189987\n",
      "end time: 16:02:19\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[79616/8798814], loss:0.00186150\n",
      "end time: 16:02:32\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[82176/8798814], loss:0.00181537\n",
      "end time: 16:02:44\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[84736/8798814], loss:0.00177114\n",
      "end time: 16:02:57\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[87296/8798814], loss:0.00173741\n",
      "end time: 16:03:09\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[89856/8798814], loss:0.00170807\n",
      "end time: 16:03:22\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[92416/8798814], loss:0.00167291\n",
      "end time: 16:03:34\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[94976/8798814], loss:0.00163004\n",
      "end time: 16:03:47\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[97536/8798814], loss:0.00159586\n",
      "end time: 16:03:59\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[100096/8798814], loss:0.00158082\n",
      "end time: 16:04:12\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[102656/8798814], loss:0.00154533\n",
      "end time: 16:04:24\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[105216/8798814], loss:0.00151294\n",
      "end time: 16:04:37\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[107776/8798814], loss:0.00147372\n",
      "end time: 16:04:49\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[110336/8798814], loss:0.00145417\n",
      "end time: 16:05:02\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[112896/8798814], loss:0.00142535\n",
      "end time: 16:05:14\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[115456/8798814], loss:0.00139819\n",
      "end time: 16:05:27\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[118016/8798814], loss:0.00138138\n",
      "end time: 16:05:39\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[120576/8798814], loss:0.00137342\n",
      "end time: 16:05:52\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[123136/8798814], loss:0.00133244\n",
      "end time: 16:06:04\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[125696/8798814], loss:0.00131317\n",
      "end time: 16:06:17\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[128256/8798814], loss:0.00128612\n",
      "end time: 16:06:29\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[130816/8798814], loss:0.00126671\n",
      "end time: 16:06:42\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[133376/8798814], loss:0.00125140\n",
      "end time: 16:06:54\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[135936/8798814], loss:0.00123002\n",
      "end time: 16:07:07\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], samples[138496/8798814], loss:0.00119879\n",
      "end time: 16:07:19\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[141056/8798814], loss:0.00118655\n",
      "end time: 16:07:32\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[143616/8798814], loss:0.00116409\n",
      "end time: 16:07:44\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[146176/8798814], loss:0.00114781\n",
      "end time: 16:07:57\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[148736/8798814], loss:0.00112310\n",
      "end time: 16:08:09\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[151296/8798814], loss:0.00110775\n",
      "end time: 16:08:22\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[153856/8798814], loss:0.00108825\n",
      "end time: 16:08:34\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[156416/8798814], loss:0.00107425\n",
      "end time: 16:08:47\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[158976/8798814], loss:0.00107005\n",
      "end time: 16:08:59\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[161536/8798814], loss:0.00104041\n",
      "end time: 16:09:12\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[164096/8798814], loss:0.00101982\n",
      "end time: 16:09:24\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[166656/8798814], loss:0.00100527\n",
      "end time: 16:09:37\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[169216/8798814], loss:0.00099631\n",
      "end time: 16:09:50\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[171776/8798814], loss:0.00096837\n",
      "end time: 16:10:02\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[174336/8798814], loss:0.00096427\n",
      "end time: 16:10:15\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[176896/8798814], loss:0.00094699\n",
      "end time: 16:10:27\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[179456/8798814], loss:0.00092143\n",
      "end time: 16:10:40\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[182016/8798814], loss:0.00091911\n",
      "end time: 16:10:52\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[184576/8798814], loss:0.00089359\n",
      "end time: 16:11:05\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[187136/8798814], loss:0.00088150\n",
      "end time: 16:11:17\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[189696/8798814], loss:0.00086347\n",
      "end time: 16:11:30\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[192256/8798814], loss:0.00084755\n",
      "end time: 16:11:42\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[194816/8798814], loss:0.00084748\n",
      "end time: 16:11:55\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[197376/8798814], loss:0.00082933\n",
      "end time: 16:12:07\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[199936/8798814], loss:0.00080882\n",
      "end time: 16:12:20\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[202496/8798814], loss:0.00081012\n",
      "end time: 16:12:32\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[205056/8798814], loss:0.00079225\n",
      "end time: 16:12:45\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[207616/8798814], loss:0.00078666\n",
      "end time: 16:12:57\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[210176/8798814], loss:0.00075685\n",
      "end time: 16:13:10\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[212736/8798814], loss:0.00075102\n",
      "end time: 16:13:22\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[215296/8798814], loss:0.00074143\n",
      "end time: 16:13:35\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[217856/8798814], loss:0.00073284\n",
      "end time: 16:13:47\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[220416/8798814], loss:0.00071210\n",
      "end time: 16:14:00\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[222976/8798814], loss:0.00070651\n",
      "end time: 16:14:13\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[225536/8798814], loss:0.00068536\n",
      "end time: 16:14:25\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[228096/8798814], loss:0.00067960\n",
      "end time: 16:14:38\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[230656/8798814], loss:0.00067963\n",
      "end time: 16:14:50\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[233216/8798814], loss:0.00066754\n",
      "end time: 16:15:03\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[235776/8798814], loss:0.00065468\n",
      "end time: 16:15:15\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[238336/8798814], loss:0.00063620\n",
      "end time: 16:15:28\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[240896/8798814], loss:0.00062967\n",
      "end time: 16:15:40\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[243456/8798814], loss:0.00061726\n",
      "end time: 16:15:53\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[246016/8798814], loss:0.00061391\n",
      "end time: 16:16:05\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[248576/8798814], loss:0.00060792\n",
      "end time: 16:16:18\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[251136/8798814], loss:0.00059729\n",
      "end time: 16:16:31\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[253696/8798814], loss:0.00059204\n",
      "end time: 16:16:43\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[256256/8798814], loss:0.00057439\n",
      "end time: 16:16:56\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[258816/8798814], loss:0.00057443\n",
      "end time: 16:17:08\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[261376/8798814], loss:0.00056251\n",
      "end time: 16:17:21\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[263936/8798814], loss:0.00054559\n",
      "end time: 16:17:34\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[266496/8798814], loss:0.00055230\n",
      "end time: 16:17:46\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[269056/8798814], loss:0.00054413\n",
      "end time: 16:17:59\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[271616/8798814], loss:0.00053185\n",
      "end time: 16:18:12\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[274176/8798814], loss:0.00051636\n",
      "end time: 16:18:24\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], samples[276736/8798814], loss:0.00052438\n",
      "end time: 16:18:37\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[279296/8798814], loss:0.00050361\n",
      "end time: 16:18:49\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[281856/8798814], loss:0.00049404\n",
      "end time: 16:19:02\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[284416/8798814], loss:0.00049019\n",
      "end time: 16:19:14\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[286976/8798814], loss:0.00048515\n",
      "end time: 16:19:27\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[289536/8798814], loss:0.00046965\n",
      "end time: 16:19:39\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[292096/8798814], loss:0.00045893\n",
      "end time: 16:19:52\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[294656/8798814], loss:0.00045473\n",
      "end time: 16:20:04\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[297216/8798814], loss:0.00045146\n",
      "end time: 16:20:17\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[299776/8798814], loss:0.00044739\n",
      "end time: 16:20:30\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[302336/8798814], loss:0.00043838\n",
      "end time: 16:20:42\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[304896/8798814], loss:0.00043709\n",
      "end time: 16:20:55\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[307456/8798814], loss:0.00043833\n",
      "end time: 16:21:07\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[310016/8798814], loss:0.00042449\n",
      "end time: 16:21:20\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[312576/8798814], loss:0.00041520\n",
      "end time: 16:21:32\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[315136/8798814], loss:0.00041653\n",
      "end time: 16:21:45\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[317696/8798814], loss:0.00040874\n",
      "end time: 16:21:57\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[320256/8798814], loss:0.00041683\n",
      "end time: 16:22:10\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[322816/8798814], loss:0.00039765\n",
      "end time: 16:22:22\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[325376/8798814], loss:0.00038876\n",
      "end time: 16:22:35\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[327936/8798814], loss:0.00038165\n",
      "end time: 16:22:48\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[330496/8798814], loss:0.00037763\n",
      "end time: 16:23:00\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[333056/8798814], loss:0.00038070\n",
      "end time: 16:23:13\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[335616/8798814], loss:0.00036667\n",
      "end time: 16:23:25\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[338176/8798814], loss:0.00036393\n",
      "end time: 16:23:38\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[340736/8798814], loss:0.00036336\n",
      "end time: 16:23:51\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[343296/8798814], loss:0.00035052\n",
      "end time: 16:24:04\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[345856/8798814], loss:0.00034153\n",
      "end time: 16:24:16\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[348416/8798814], loss:0.00035947\n",
      "end time: 16:24:29\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[350976/8798814], loss:0.00034147\n",
      "end time: 16:24:41\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[353536/8798814], loss:0.00034317\n",
      "end time: 16:24:54\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[356096/8798814], loss:0.00032522\n",
      "end time: 16:25:06\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[358656/8798814], loss:0.00033095\n",
      "end time: 16:25:19\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[361216/8798814], loss:0.00032842\n",
      "end time: 16:25:31\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[363776/8798814], loss:0.00031226\n",
      "end time: 16:25:44\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[366336/8798814], loss:0.00031610\n",
      "end time: 16:25:57\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[368896/8798814], loss:0.00031757\n",
      "end time: 16:26:10\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[371456/8798814], loss:0.00031135\n",
      "end time: 16:26:22\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[374016/8798814], loss:0.00030229\n",
      "end time: 16:26:35\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[376576/8798814], loss:0.00029533\n",
      "end time: 16:26:47\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[379136/8798814], loss:0.00029697\n",
      "end time: 16:27:00\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[381696/8798814], loss:0.00029905\n",
      "end time: 16:27:13\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[384256/8798814], loss:0.00028721\n",
      "end time: 16:27:25\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[386816/8798814], loss:0.00028760\n",
      "end time: 16:27:38\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[389376/8798814], loss:0.00029185\n",
      "end time: 16:27:51\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[391936/8798814], loss:0.00028588\n",
      "end time: 16:28:03\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[394496/8798814], loss:0.00027891\n",
      "end time: 16:28:16\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[397056/8798814], loss:0.00027198\n",
      "end time: 16:28:28\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[399616/8798814], loss:0.00027157\n",
      "end time: 16:28:41\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[402176/8798814], loss:0.00026197\n",
      "end time: 16:28:54\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[404736/8798814], loss:0.00026710\n",
      "end time: 16:29:06\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[407296/8798814], loss:0.00026665\n",
      "end time: 16:29:19\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[409856/8798814], loss:0.00027432\n",
      "end time: 16:29:31\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[412416/8798814], loss:0.00025831\n",
      "end time: 16:29:44\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], samples[414976/8798814], loss:0.00025692\n",
      "end time: 16:29:57\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[417536/8798814], loss:0.00025403\n",
      "end time: 16:30:09\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[420096/8798814], loss:0.00024745\n",
      "end time: 16:30:22\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[422656/8798814], loss:0.00024419\n",
      "end time: 16:30:34\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[425216/8798814], loss:0.00024380\n",
      "end time: 16:30:47\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[427776/8798814], loss:0.00025545\n",
      "end time: 16:30:59\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[430336/8798814], loss:0.00023607\n",
      "end time: 16:31:12\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[432896/8798814], loss:0.00023806\n",
      "end time: 16:31:25\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[435456/8798814], loss:0.00023552\n",
      "end time: 16:31:37\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[438016/8798814], loss:0.00023375\n",
      "end time: 16:31:50\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[440576/8798814], loss:0.00022942\n",
      "end time: 16:32:02\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[443136/8798814], loss:0.00022947\n",
      "end time: 16:32:15\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[445696/8798814], loss:0.00022878\n",
      "end time: 16:32:27\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[448256/8798814], loss:0.00022569\n",
      "end time: 16:32:40\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[450816/8798814], loss:0.00022663\n",
      "end time: 16:32:53\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[453376/8798814], loss:0.00022306\n",
      "end time: 16:33:05\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[455936/8798814], loss:0.00022488\n",
      "end time: 16:33:18\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[458496/8798814], loss:0.00022506\n",
      "end time: 16:33:30\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[461056/8798814], loss:0.00022380\n",
      "end time: 16:33:43\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[463616/8798814], loss:0.00022928\n",
      "end time: 16:33:55\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[466176/8798814], loss:0.00021213\n",
      "end time: 16:34:08\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[468736/8798814], loss:0.00021715\n",
      "end time: 16:34:21\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[471296/8798814], loss:0.00021756\n",
      "end time: 16:34:33\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[473856/8798814], loss:0.00021392\n",
      "end time: 16:34:46\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[476416/8798814], loss:0.00021771\n",
      "end time: 16:34:58\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[478976/8798814], loss:0.00021189\n",
      "end time: 16:35:11\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[481536/8798814], loss:0.00021298\n",
      "end time: 16:35:24\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[484096/8798814], loss:0.00020094\n",
      "end time: 16:35:36\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[486656/8798814], loss:0.00019927\n",
      "end time: 16:35:49\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[489216/8798814], loss:0.00021070\n",
      "end time: 16:36:01\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[491776/8798814], loss:0.00019931\n",
      "end time: 16:36:14\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[494336/8798814], loss:0.00020982\n",
      "end time: 16:36:27\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[496896/8798814], loss:0.00019900\n",
      "end time: 16:36:40\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[499456/8798814], loss:0.00019395\n",
      "end time: 16:36:52\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[502016/8798814], loss:0.00019983\n",
      "end time: 16:37:05\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[504576/8798814], loss:0.00018839\n",
      "end time: 16:37:17\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[507136/8798814], loss:0.00019419\n",
      "end time: 16:37:30\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[509696/8798814], loss:0.00018845\n",
      "end time: 16:37:43\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[512256/8798814], loss:0.00019338\n",
      "end time: 16:37:55\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[514816/8798814], loss:0.00019302\n",
      "end time: 16:38:08\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[517376/8798814], loss:0.00018526\n",
      "end time: 16:38:21\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[519936/8798814], loss:0.00018854\n",
      "end time: 16:38:33\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[522496/8798814], loss:0.00019073\n",
      "end time: 16:38:46\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[525056/8798814], loss:0.00019544\n",
      "end time: 16:38:59\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[527616/8798814], loss:0.00018631\n",
      "end time: 16:39:11\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[530176/8798814], loss:0.00017913\n",
      "end time: 16:39:24\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[532736/8798814], loss:0.00017955\n",
      "end time: 16:39:37\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[535296/8798814], loss:0.00019171\n",
      "end time: 16:39:49\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[537856/8798814], loss:0.00018672\n",
      "end time: 16:40:02\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[540416/8798814], loss:0.00019045\n",
      "end time: 16:40:15\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[542976/8798814], loss:0.00017821\n",
      "end time: 16:40:28\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[545536/8798814], loss:0.00018004\n",
      "end time: 16:40:40\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[548096/8798814], loss:0.00018244\n",
      "end time: 16:40:53\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[550656/8798814], loss:0.00017039\n",
      "end time: 16:41:06\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], samples[553216/8798814], loss:0.00017294\n",
      "end time: 16:41:18\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[555776/8798814], loss:0.00017630\n",
      "end time: 16:41:31\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[558336/8798814], loss:0.00017533\n",
      "end time: 16:41:44\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[560896/8798814], loss:0.00016589\n",
      "end time: 16:41:56\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[563456/8798814], loss:0.00017846\n",
      "end time: 16:42:09\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[566016/8798814], loss:0.00017395\n",
      "end time: 16:42:21\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[568576/8798814], loss:0.00017466\n",
      "end time: 16:42:34\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[571136/8798814], loss:0.00017836\n",
      "end time: 16:42:47\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[573696/8798814], loss:0.00016246\n",
      "end time: 16:43:00\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[576256/8798814], loss:0.00018078\n",
      "end time: 16:43:12\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[578816/8798814], loss:0.00017051\n",
      "end time: 16:43:25\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[581376/8798814], loss:0.00016702\n",
      "end time: 16:43:38\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[583936/8798814], loss:0.00016972\n",
      "end time: 16:43:50\n",
      "--------------------------------------------------------------------------------\n",
      "epoch [1/1], samples[586496/8798814], loss:0.00017300\n",
      "end time: 16:44:03\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-485e153762b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mb_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# batch label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# mean square error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-40603ec89c60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mparam_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mparam_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         param_copies = [param_copies[i:i + len(params)]\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, *inputs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mnon_differentiables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_requires_grad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mbroadcast_coalesced\u001b[0;34m(tensors, devices, buffer_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader): # step: batch index; x.shape: [BATCH_SIZE, 1, 374251]; y.shape: [BATCH_SIZE]   \n",
    "        b_x = torch.tensor(x).to(device)                   # batch x\n",
    "        b_y = torch.tensor(x).to(device)\n",
    "        b_label = torch.tensor(y).to(device)               # batch label\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = criterion(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step since gradients are accumulated in the process\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients. \"The function can be called once the gradients are computed using eg. backward()\"\n",
    "\n",
    "        # Currently the training speed is really slow, change the numbers below according to what you need\n",
    "        if step % 10 == 0:\n",
    "            print('epoch [{}/{}], samples[{}/{}], loss:{:.8f}'\n",
    "                  .format(epoch + 1, EPOCH, (step + 1) * BATCH_SIZE, train_X.shape[0], loss.item()))\n",
    "            print('end time: {}'.format(pu.get_time_str()))\n",
    "            print('-' * 80)\n",
    "#         if step == 100:\n",
    "#             break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the speed doesn't improve: https://github.com/pytorch/pytorch/issues/3917\n",
    "# uneven gpu util"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
