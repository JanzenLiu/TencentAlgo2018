{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../code/utils')\n",
    "sys.path.append('../code/pipeline')\n",
    "sys.path.append('../code')\n",
    "import data_pipeline as dp\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import data_jointer as dj\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_folder = os.path.join(config.PRELIM_NLP_COUNT_DATA_DIR, \"simple_cross/byUserFeatureName\")\n",
    "\n",
    "\n",
    "def cross_binary_path(ad_feat_name, user_feat_name, prefix=\"train\", create=True):\n",
    "    folder = os.path.join(cross_folder, \"[featureName='{}']\".format(user_feat_name))\n",
    "    file = \"{}.[adFeatureName='{}'].binary.pkl\".format(prefix, ad_feat_name)\n",
    "    path = os.path.join(folder, file)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:39:55] Finish processing 'aid' x 'age'. △M: +84.33MB. △T: 1.0 seconds.\n",
      "[01:40:00] Finish processing 'aid' x 'interest2'. △M: +524.55MB. △T: 5.8 seconds.\n",
      "[01:40:11] Finish processing 'productType' x 'kw2'. △M: +409.42MB. △T: 10.8 seconds.\n"
     ]
    }
   ],
   "source": [
    "pairs = [(\"aid\", \"age\"), ('aid', 'interest2'), ('productType', 'kw2')]\n",
    "out_folder = os.path.join(config.DATA_DIR, \"input_final\")\n",
    "\n",
    "col_names = []\n",
    "matrix = None\n",
    "for ad_feat_name, user_feat_name in pairs:\n",
    "    with pu.profiler(\"processing '{}' x '{}'\".format(ad_feat_name, user_feat_name)):\n",
    "        # =============\n",
    "        # process train\n",
    "        # =============\n",
    "        path = cross_binary_path(ad_feat_name, user_feat_name, \"train\")\n",
    "        new_col_names, new_matrix = du.load_pickle(path, use_joblib=True)\n",
    "        \n",
    "        min_df = 10\n",
    "        col_nnz = new_matrix.getnnz(axis=0)\n",
    "        mask = (col_nnz >= min_df)\n",
    "        new_col_names = list(itertools.compress(new_col_names, mask))\n",
    "        new_matrix = new_matrix[:, mask]\n",
    "        assert len(new_col_names) == new_matrix.shape[1]\n",
    "\n",
    "        col_names += new_col_names\n",
    "        if matrix is None:\n",
    "            matrix = new_matrix\n",
    "        else:\n",
    "            matrix = sparse.hstack((matrix, new_matrix))\n",
    "        \n",
    "        out_file = \"train.cross.wordCount_v2.pkl\"\n",
    "        out_path = os.path.join(out_folder, out_file)\n",
    "        du.save_pickle((col_names, matrix), out_path, use_joblib=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:40:12] Finish processing 'aid' x 'age'. △M: -201.21MB. △T: 0.2 seconds.\n",
      "[01:40:13] Finish processing 'aid' x 'interest2'. △M: +155.15MB. △T: 1.6 seconds.\n",
      "[01:40:16] Finish processing 'productType' x 'kw2'. △M: +97.95MB. △T: 3.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "col_names = []\n",
    "matrix = None\n",
    "for ad_feat_name, user_feat_name in pairs:\n",
    "    with pu.profiler(\"processing '{}' x '{}'\".format(ad_feat_name, user_feat_name)):\n",
    "        # =============\n",
    "        # process train\n",
    "        # =============\n",
    "        path = cross_binary_path(ad_feat_name, user_feat_name, \"test2\")\n",
    "        new_col_names, new_matrix = du.load_pickle(path, use_joblib=True)\n",
    "        \n",
    "        min_df = 10\n",
    "        col_nnz = new_matrix.getnnz(axis=0)\n",
    "        mask = (col_nnz >= min_df)\n",
    "        new_col_names = list(itertools.compress(new_col_names, mask))\n",
    "        new_matrix = new_matrix[:, mask]\n",
    "        assert len(new_col_names) == new_matrix.shape[1]\n",
    "\n",
    "        col_names += new_col_names\n",
    "        if matrix is None:\n",
    "            matrix = new_matrix\n",
    "        else:\n",
    "            matrix = sparse.hstack((matrix, new_matrix))\n",
    "        \n",
    "        out_file = \"test2.cross.wordCount_v2.pkl\"\n",
    "        out_path = os.path.join(out_folder, out_file)\n",
    "        du.save_pickle((col_names, matrix), out_path, use_joblib=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
