{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../code/utils')\n",
    "sys.path.append('../../../code/feature')\n",
    "sys.path.append('../../../code/pipeline')\n",
    "sys.path.append('../../../code')\n",
    "from clickrate import BayesianSmoothedClickrate\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import data_jointer as dj\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickhist_folder = os.path.join(config.DATA_DIR, \"click_history/user_cross\")\n",
    "clickrate_folder = os.path.join(config.DATA_DIR, \"clickrate_bs/user_cross\")\n",
    "\n",
    "\n",
    "def click_history_fold_dir(num_folds, create=True):\n",
    "    folder = \"{}[StratifiedKFold_{}]\".format(clickhist_folder, num_folds)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "def click_history_path(num_folds, fold_index, user_feat_name1, user_feat_name2, user1_val, create=True):\n",
    "    folder = click_history_fold_dir(num_folds, create)\n",
    "    folder = os.path.join(folder, str(fold_index), \"[featureName='{}']\".format(user_feat_name2))\n",
    "    filename = \"[{}='{}'].csv\".format(user_feat_name1, user1_val)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def click_rate_fold_dir(num_folds, create=True):\n",
    "    folder = \"{}[StratifiedKFold_{}]\".format(clickrate_folder, num_folds)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "def click_rate_paths(num_folds, fold_index, user_feat_name1, user_feat_name2, create=True):\n",
    "    folder = click_rate_fold_dir(num_folds, create)\n",
    "    folder = os.path.join(folder, str(fold_index),  \"[featureName='{}']\".format(user_feat_name2))\n",
    "    clickrate_file = \"[featureName='{}'].csv\".format(user_feat_name1)\n",
    "    clickrate_filepath = os.path.join(folder, clickrate_file)\n",
    "    meta_file = \"params[featureName='{}'].csv\".format(user_feat_name1)\n",
    "    meta_filepath = os.path.join(folder, meta_file)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return clickrate_filepath, meta_filepath\n",
    "\n",
    "\n",
    "def load_split_indices(num_folds):\n",
    "    fold_dir = os.path.join(config.DATA_DIR, \"click_history/simple_cross/byUserFeatureName\")\n",
    "    fold_dir = \"{}[StratifiedKFold_{}]\".format(fold_dir, num_folds)\n",
    "    index_file = \"indices.pkl\"\n",
    "    index_path = os.path.join(fold_dir, index_file)\n",
    "    split_indices = du.load_pickle(index_path)\n",
    "    return split_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feat_stats(feat_stats):\n",
    "    feat_stats[\"impression\"] = feat_stats[\"positive\"] + feat_stats[\"negative\"]\n",
    "    feat_stats = feat_stats.rename(columns={\"positive\": \"click\", \"value\":\"user_val\"})\n",
    "    return feat_stats\n",
    "\n",
    "\n",
    "def clean_meta(df_meta):\n",
    "    df_meta[\"ad_val\"] = df_meta[\"ad_val\"].astype(str)  # seems that this line of code is redundant\n",
    "    df_meta = df_meta.sort_values([\"clickrate_expectation\", \"alpha\"], ascending=False)\n",
    "    return df_meta[[\"ad_val\", \"alpha\", \"beta\", \"clickrate_expectation\"]]\n",
    "\n",
    "\n",
    "def clean_clickrate(df_clickrate):\n",
    "    df_clickrate[[\"click\", \"impression\"]] = df_clickrate[[\"click\", \"impression\"]].astype(str)\n",
    "    df_clickrate = df_clickrate.sort_values([\"bs_clickrate\", \"click\"], ascending=False)\n",
    "    return df_clickrate[[\"ad_val\", \"user_val\", \"bs_clickrate\", \"click\", \"impression\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:51:41] Finish loading and joining 'age'. △M: +330.46MB. △T: 11.7 seconds.\n",
      "[16:51:53] Finish loading and joining 'gender'. △M: +67.16MB. △T: 12.1 seconds.\n",
      "[16:52:06] Finish loading and joining 'education'. △M: +67.14MB. △T: 12.9 seconds.\n",
      "[16:52:23] Finish loading and joining 'consumptionAbility'. △M: +67.13MB. △T: 17.0 seconds.\n",
      "[16:52:39] Finish loading and joining 'LBS'. △M: +68.37MB. △T: 16.5 seconds.\n",
      "[16:52:55] Finish loading and joining 'carrier'. △M: +67.14MB. △T: 15.8 seconds.\n",
      "[16:53:11] Finish loading and joining 'house'. △M: +67.13MB. △T: 16.2 seconds.\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "split_indices = load_split_indices(n_splits)\n",
    "\n",
    "pair_dict = {}\n",
    "for i, user_feat1 in enumerate(config.USER_SINGLE_FEAT_NAMES[:-1]):\n",
    "    pair_dict[user_feat1] = config.USER_SINGLE_FEAT_NAMES[i + 1:]\n",
    "    \n",
    "pairs = []\n",
    "for user_feat_name2, user_feat_names1 in pair_dict.items():\n",
    "    for user_feat_name1 in user_feat_names1:\n",
    "        pairs.append((user_feat_name1, user_feat_name2))\n",
    "        \n",
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test2\")\n",
    "train_size = df_train.shape[0]\n",
    "test_size = df_test.shape[0]\n",
    "\n",
    "train = df_train.copy()\n",
    "user_jointer = dj.PandasPandasJointer(\"uid\")\n",
    "for ufeat in config.USER_SINGLE_FEAT_NAMES:\n",
    "    with pu.profiler(\"loading and joining '{}'\".format(ufeat)):\n",
    "        df_feat = du.load_user_feature(ufeat).fillna(\"[nan]\")\n",
    "        train = user_jointer.join(df1=train, df2=df_feat)\n",
    "assert train.isnull().sum().sum() == 0\n",
    "        \n",
    "avals_dict = {afeat: set(train[afeat].unique()) for afeat in config.USER_SINGLE_FEAT_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'carrier' x 'LBS' fold 1/5: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n",
      "'carrier' x 'LBS' fold 2/5: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n",
      "'carrier' x 'LBS' fold 3/5: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n",
      "'carrier' x 'LBS' fold 4/5: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n",
      "'carrier' x 'LBS' fold 5/5: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n",
      "'house' x 'LBS' fold 1/5: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]\n",
      "'house' x 'LBS' fold 2/5: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n",
      "'house' x 'LBS' fold 3/5: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\n",
      "'house' x 'LBS' fold 4/5: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n",
      "'house' x 'LBS' fold 5/5: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n",
      "'education' x 'gender' fold 1/5: 100%|██████████| 8/8 [00:03<00:00,  2.39it/s]\n",
      "'education' x 'gender' fold 2/5: 100%|██████████| 8/8 [00:03<00:00,  2.19it/s]\n",
      "'education' x 'gender' fold 3/5: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n",
      "'education' x 'gender' fold 4/5: 100%|██████████| 8/8 [00:04<00:00,  1.96it/s]\n",
      "'education' x 'gender' fold 5/5: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n",
      "'consumptionAbility' x 'gender' fold 1/5: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "'consumptionAbility' x 'gender' fold 2/5: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
      "'consumptionAbility' x 'gender' fold 3/5: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n",
      "'consumptionAbility' x 'gender' fold 4/5: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]\n",
      "'consumptionAbility' x 'gender' fold 5/5: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]\n",
      "'LBS' x 'gender' fold 1/5:   0%|          | 0/840 [00:00<?, ?it/s]../../../code/feature/clickrate.py:153: RuntimeWarning: invalid value encountered in subtract\n",
      "  numerator_alpha = np.sum(special.digamma(clks + alpha) - special.digamma(alpha))\n",
      "'LBS' x 'gender' fold 1/5:   6%|▋         | 53/840 [00:09<02:17,  5.70it/s]../../../code/feature/clickrate.py:154: RuntimeWarning: invalid value encountered in subtract\n",
      "  numerator_beta = np.sum(special.digamma(imps - clks + beta) - special.digamma(beta))\n",
      "'LBS' x 'gender' fold 1/5:   7%|▋         | 58/840 [00:10<02:17,  5.70it/s]../../../code/feature/clickrate.py:156: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  new_alpha = alpha * (numerator_alpha / denominator)\n",
      "../../../code/feature/clickrate.py:157: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  new_beta = beta * (numerator_beta / denominator)\n",
      "'LBS' x 'gender' fold 1/5: 100%|██████████| 840/840 [02:14<00:00,  6.26it/s]\n",
      "'LBS' x 'gender' fold 2/5: 100%|██████████| 840/840 [02:10<00:00,  6.46it/s]\n",
      "'LBS' x 'gender' fold 3/5: 100%|██████████| 840/840 [02:08<00:00,  6.56it/s]\n",
      "'LBS' x 'gender' fold 4/5: 100%|██████████| 840/840 [02:15<00:00,  6.20it/s]\n",
      "'LBS' x 'gender' fold 5/5: 100%|██████████| 840/840 [02:00<00:00,  6.97it/s]\n",
      "'carrier' x 'gender' fold 1/5: 100%|██████████| 4/4 [00:03<00:00,  1.31it/s]\n",
      "'carrier' x 'gender' fold 2/5: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]\n",
      "'carrier' x 'gender' fold 3/5: 100%|██████████| 4/4 [00:02<00:00,  1.36it/s]\n",
      "'carrier' x 'gender' fold 4/5: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n",
      "'carrier' x 'gender' fold 5/5: 100%|██████████| 4/4 [00:03<00:00,  1.00it/s]\n",
      "'house' x 'gender' fold 1/5: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n",
      "'house' x 'gender' fold 2/5: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n",
      "'house' x 'gender' fold 3/5: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]\n",
      "'house' x 'gender' fold 4/5: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n",
      "'house' x 'gender' fold 5/5: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "'house' x 'carrier' fold 1/5: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "'house' x 'carrier' fold 2/5: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "'house' x 'carrier' fold 3/5: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "'house' x 'carrier' fold 4/5: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "'house' x 'carrier' fold 5/5: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n",
      "'LBS' x 'consumptionAbility' fold 1/5: 100%|██████████| 840/840 [02:04<00:00,  6.75it/s]\n",
      "'LBS' x 'consumptionAbility' fold 2/5: 100%|██████████| 840/840 [01:47<00:00,  7.81it/s]\n",
      "'LBS' x 'consumptionAbility' fold 3/5: 100%|██████████| 840/840 [00:48<00:00, 17.36it/s]\n",
      "'LBS' x 'consumptionAbility' fold 4/5: 100%|██████████| 840/840 [01:05<00:00, 12.90it/s]\n",
      "'LBS' x 'consumptionAbility' fold 5/5: 100%|██████████| 840/840 [01:09<00:00, 12.13it/s]\n",
      "'carrier' x 'consumptionAbility' fold 1/5: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s]\n",
      "'carrier' x 'consumptionAbility' fold 2/5: 100%|██████████| 4/4 [00:01<00:00,  2.66it/s]\n",
      "'carrier' x 'consumptionAbility' fold 3/5: 100%|██████████| 4/4 [00:01<00:00,  2.74it/s]\n",
      "'carrier' x 'consumptionAbility' fold 4/5: 100%|██████████| 4/4 [00:01<00:00,  2.66it/s]\n",
      "'carrier' x 'consumptionAbility' fold 5/5: 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]\n",
      "'house' x 'consumptionAbility' fold 1/5: 100%|██████████| 2/2 [00:00<00:00,  2.70it/s]\n",
      "'house' x 'consumptionAbility' fold 2/5: 100%|██████████| 2/2 [00:00<00:00,  2.62it/s]\n",
      "'house' x 'consumptionAbility' fold 3/5: 100%|██████████| 2/2 [00:00<00:00,  2.64it/s]\n",
      "'house' x 'consumptionAbility' fold 4/5: 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n",
      "'house' x 'consumptionAbility' fold 5/5: 100%|██████████| 2/2 [00:00<00:00,  2.58it/s]\n",
      "'consumptionAbility' x 'education' fold 1/5: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s]\n",
      "'consumptionAbility' x 'education' fold 2/5: 100%|██████████| 3/3 [00:01<00:00,  2.51it/s]\n",
      "'consumptionAbility' x 'education' fold 3/5: 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]\n",
      "'consumptionAbility' x 'education' fold 4/5: 100%|██████████| 3/3 [00:01<00:00,  2.49it/s]\n",
      "'consumptionAbility' x 'education' fold 5/5: 100%|██████████| 3/3 [00:01<00:00,  2.32it/s]\n",
      "'LBS' x 'education' fold 1/5: 100%|██████████| 840/840 [01:21<00:00, 10.28it/s]\n",
      "'LBS' x 'education' fold 2/5: 100%|██████████| 840/840 [01:04<00:00, 13.02it/s]\n",
      "'LBS' x 'education' fold 3/5: 100%|██████████| 840/840 [00:50<00:00, 16.55it/s]\n",
      "'LBS' x 'education' fold 4/5: 100%|██████████| 840/840 [01:20<00:00, 10.39it/s]\n",
      "'LBS' x 'education' fold 5/5: 100%|██████████| 840/840 [00:45<00:00, 18.30it/s]\n",
      "'carrier' x 'education' fold 1/5: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n",
      "'carrier' x 'education' fold 2/5: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n",
      "'carrier' x 'education' fold 3/5: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]\n",
      "'carrier' x 'education' fold 4/5: 100%|██████████| 4/4 [00:04<00:00,  1.10s/it]\n",
      "'carrier' x 'education' fold 5/5: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]\n",
      "'house' x 'education' fold 1/5: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n",
      "'house' x 'education' fold 2/5: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]\n",
      "'house' x 'education' fold 3/5: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n",
      "'house' x 'education' fold 4/5: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]\n",
      "'house' x 'education' fold 5/5: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]\n",
      "'gender' x 'age' fold 1/5: 100%|██████████| 3/3 [00:03<00:00,  1.09s/it]\n",
      "'gender' x 'age' fold 2/5: 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n",
      "'gender' x 'age' fold 3/5: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]\n",
      "'gender' x 'age' fold 4/5: 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n",
      "'gender' x 'age' fold 5/5: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]\n",
      "'education' x 'age' fold 1/5: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n",
      "'education' x 'age' fold 2/5: 100%|██████████| 8/8 [00:08<00:00,  1.05s/it]\n",
      "'education' x 'age' fold 3/5: 100%|██████████| 8/8 [00:08<00:00,  1.03s/it]\n",
      "'education' x 'age' fold 4/5: 100%|██████████| 8/8 [00:09<00:00,  1.14s/it]\n",
      "'education' x 'age' fold 5/5: 100%|██████████| 8/8 [00:09<00:00,  1.16s/it]\n",
      "'consumptionAbility' x 'age' fold 1/5: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]\n",
      "'consumptionAbility' x 'age' fold 2/5: 100%|██████████| 3/3 [00:03<00:00,  1.28s/it]\n",
      "'consumptionAbility' x 'age' fold 3/5: 100%|██████████| 3/3 [00:03<00:00,  1.28s/it]\n",
      "'consumptionAbility' x 'age' fold 4/5: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "'consumptionAbility' x 'age' fold 5/5: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "'LBS' x 'age' fold 1/5: 100%|██████████| 840/840 [02:06<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'LBS' x 'age' fold 2/5: 100%|██████████| 840/840 [02:14<00:00,  6.23it/s]\n",
      "'LBS' x 'age' fold 3/5: 100%|██████████| 840/840 [02:07<00:00,  6.60it/s]\n",
      "'LBS' x 'age' fold 4/5: 100%|██████████| 840/840 [02:10<00:00,  6.42it/s]\n",
      "'LBS' x 'age' fold 5/5: 100%|██████████| 840/840 [01:49<00:00,  7.67it/s]\n",
      "'carrier' x 'age' fold 1/5: 100%|██████████| 4/4 [00:03<00:00,  1.08it/s]\n",
      "'carrier' x 'age' fold 2/5: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n",
      "'carrier' x 'age' fold 3/5: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n",
      "'carrier' x 'age' fold 4/5: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]\n",
      "'carrier' x 'age' fold 5/5: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n",
      "'house' x 'age' fold 1/5: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "'house' x 'age' fold 2/5: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]\n",
      "'house' x 'age' fold 3/5: 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n",
      "'house' x 'age' fold 4/5: 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n",
      "'house' x 'age' fold 5/5: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for ad_feat_name, user_feat_name in pairs:\n",
    "    avals = avals_dict[ad_feat_name]\n",
    "    for split_i in range(n_splits):\n",
    "        df_meta = pd.DataFrame(columns=[\"ad_val\", \"alpha\", \"beta\", \"clickrate_expectation\"])\n",
    "        df_clickrate = pd.DataFrame(columns=[\"ad_val\", \"user_val\", \"bs_clickrate\", \"click\", \"impression\"])\n",
    "        \n",
    "        desc = \"'{}' x '{}' fold {}/{}\".format(ad_feat_name, user_feat_name, split_i + 1, n_splits)\n",
    "        for aval in tqdm.tqdm(list(avals), desc=desc):\n",
    "            in_path = click_history_path(num_folds=n_splits, fold_index=split_i,\n",
    "                                         user_feat_name2=user_feat_name, user_feat_name1=ad_feat_name, \n",
    "                                         user1_val=aval)\n",
    "            feat_stats = pd.read_csv(in_path)\n",
    "            feat_stats = clean_feat_stats(feat_stats)\n",
    "            \n",
    "            imps = feat_stats[\"impression\"].values\n",
    "            clks = feat_stats[\"click\"].values\n",
    "            \n",
    "            max_iter = 10000 if not \"LBS\" in [ad_feat_name, user_feat_name] else 1000\n",
    "            bs = BayesianSmoothedClickrate(use_moment=False, use_fixed_point=True, max_iter=max_iter)\n",
    "            bs.fit(imps, clks, verbose=False)\n",
    "            \n",
    "            feat_stats[\"bs_clickrate\"] = bs.transform(imps, clks)\n",
    "            feat_stats[\"ad_val\"] = aval\n",
    "            df_meta.loc[df_meta.shape[0]] = {\"ad_val\": aval, \"alpha\": bs.alpha, \"beta\": bs.beta, \n",
    "                                             \"clickrate_expectation\": bs.clickrate_expectation}\n",
    "            df_clickrate = df_clickrate.append(feat_stats[[\"ad_val\", \"user_val\", \"bs_clickrate\", \"click\", \"impression\"]])\n",
    "        \n",
    "        clickrate_path, meta_path = click_rate_paths(n_splits, split_i, ad_feat_name, user_feat_name)\n",
    "        df_meta = clean_meta(df_meta)\n",
    "        df_meta.to_csv(meta_path, index=False)\n",
    "        df_clickrate = clean_clickrate(df_clickrate)\n",
    "        df_clickrate.to_csv(clickrate_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
