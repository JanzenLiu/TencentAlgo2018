{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_id, folder, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        img_id: string\n",
    "        \n",
    "        folder: string\n",
    "        \n",
    "        size: tuple\n",
    "            Target size to resize the original image into.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        img: np.ndarray\n",
    "            Image as numpy array.\n",
    "    \"\"\"\n",
    "    img = image.load_img(os.path.join(folder, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All preparation things are adapted from https://www.kaggle.com/gaborfodor/dog-breed-pretrained-keras-models-lb-0-3\n",
    "INPUT_SIZE = 224\n",
    "SEED = 20180407\n",
    "data_dir = '../data/dog_breed'\n",
    "labels = pd.read_csv(os.path.join(data_dir, 'labels.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n",
    "NUM_CLASSES = labels[\"breed\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10222it [01:10, 144.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (10222, 224, 224, 3) size: 1,538,697,216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "INPUT_SIZE = 224\n",
    "POOLING = 'avg'\n",
    "train_folder = \"../data/dog_breed/Train\"\n",
    "y_train = labels[\"breed\"].values\n",
    "x_train = np.zeros((labels.shape[0], INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm.tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, train_folder, (INPUT_SIZE, INPUT_SIZE))\n",
    "    # x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = img  # it's x originally\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and validation set\n",
    "np.random.seed(seed=SEED)\n",
    "rnd = np.random.random(len(labels))\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8\n",
    "\n",
    "# prepare train/test data\n",
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "del x_train\n",
    "gc.collect()  # clear the memory or your computer will explode lol\n",
    "\n",
    "# prepare labels\n",
    "lb = LabelBinarizer()\n",
    "y_onehot = lb.fit_transform(y_train)\n",
    "ytr_onehot = y_onehot[train_idx]\n",
    "yv_onehot = y_onehot[valid_idx]\n",
    "label_idx_dict = {label: idx for idx, label in enumerate(lb.classes_)}\n",
    "idx_label_dict = {idx: label for idx, label in enumerate(lb.classes_)}\n",
    "ycode = np.array([label_idx_dict[label] for label in y_train])\n",
    "ytr = ycode[train_idx]\n",
    "yv = ycode[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8162/8162 [==============================] - 2768s  \n",
      "2060/2060 [==============================] - 690s   \n",
      "Xception train bottleneck features shape: (8162, 2048) size: 16,715,776\n",
      "Xception valid bottleneck features shape: (2060, 2048) size: 4,218,880\n"
     ]
    }
   ],
   "source": [
    "xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\n",
    "print('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Xception LogLoss 5.52039454292717\n",
      "Validation Xception Accuracy 0.04563106796116505\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_x_bf, ytr)\n",
    "valid_probs = logreg.predict_proba(valid_x_bf)\n",
    "valid_preds = logreg.predict(valid_x_bf)\n",
    "print('Validation Xception LogLoss {}'.format(log_loss(yv_onehot, valid_probs)))\n",
    "print('Validation Xception Accuracy {}'.format(accuracy_score(yv, valid_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the validation score sucks so I give up making prediction for test data\n",
    "# test_folder = \"../data/dog_breed/Test\"\n",
    "# x_test = np.zeros((sample_submission.shape[0], INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "# for i, img_id in tqdm.tqdm(enumerate(sample_submission['id'])):\n",
    "#     img = read_img(img_id, test_folder, (INPUT_SIZE, INPUT_SIZE))\n",
    "#     # x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "#     x_test[i] = img  # it's x originally\n",
    "# print('Test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x_bf = xception_bottleneck.predict(x_test, batch_size=32, verbose=1)\n",
    "# test_probs = logreg.predict_proba(test_x_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
