{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../code/utils')\n",
    "sys.path.append('../code/pipeline')\n",
    "sys.path.append('../code')\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import data_jointer as dj\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_dict(dic):\n",
    "    return {v: k for k, v in dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_matrix(indices, max_cols):\n",
    "    # life is short, I use my own implementation\n",
    "    n_rows = len(indices)\n",
    "    indptr = np.arange(n_rows + 1)\n",
    "    indices = np.array(indices)\n",
    "    data = np.ones(len(indices), dtype=np.int8)\n",
    "    matrix = sparse.csr_matrix((data, indices, indptr), shape=(n_rows, max_cols) ,dtype=np.int8)\n",
    "\n",
    "    del indptr\n",
    "    del indices\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def cross_vectorize(df, feat_names, add_prefix=True):\n",
    "    assert len(feat_names) == 2  # only 2 degree crossing is supported now\n",
    "    \n",
    "    # get unique values\n",
    "    feat1_name = feat_names[0]\n",
    "    feat2_name = feat_names[1]\n",
    "    feat1_vals = df[feat1_name].unique()\n",
    "    feat2_vals = df[feat2_name].unique()\n",
    "\n",
    "    # count number of unique values\n",
    "    feat1_nunique = len(feat1_vals)\n",
    "    feat2_nunique = len(feat2_vals)\n",
    "    num_combinations  = feat1_nunique * feat2_nunique\n",
    "\n",
    "    # get index base and offset for unique values\n",
    "    feat1_to_index = dj.list_to_dict(feat1_vals, feat2_nunique)\n",
    "    feat2_to_index = dj.list_to_dict(feat2_vals)\n",
    "\n",
    "    # get indices\n",
    "    indices1 = df[feat1_name].map(feat1_to_index)\n",
    "    indices2 = df[feat2_name].map(feat2_to_index)\n",
    "    indices = indices1 + indices2\n",
    "    assert indices.nunique() >= max(feat1_nunique, feat2_nunique)\n",
    "    assert indices.nunique() <= feat1_nunique * feat2_nunique\n",
    "    \n",
    "    # get column names\n",
    "    index_to_feat1 = inverse_dict(feat1_to_index)\n",
    "    index_to_feat2 = inverse_dict(feat2_to_index)\n",
    "    col_names = []\n",
    "    if not add_prefix:\n",
    "        for i in range(0, num_combinations, feat2_nunique):\n",
    "            feat1_val = index_to_feat1[i]\n",
    "            col_names += [\"{}x{}\".format(feat1_val, index_to_feat2[j]) for j in range(feat2_nunique)]\n",
    "    else:\n",
    "        for i in range(0, num_combinations, feat2_nunique):\n",
    "            feat1_val = index_to_feat1[i]\n",
    "            col_names += [\"{}_{}_x_{}_{}\".format(feat1_name, feat1_val, feat2_name, index_to_feat2[j]) \n",
    "                          for j in range(feat2_nunique)]\n",
    "    \n",
    "    # release memory and collect garbage\n",
    "    del feat1_to_index\n",
    "    del feat2_to_index\n",
    "    del index_to_feat1\n",
    "    del index_to_feat2\n",
    "    del indices1\n",
    "    del indices2\n",
    "    gc.collect()\n",
    "\n",
    "    # construct sparse matrix\n",
    "    matrix = indices_to_matrix(indices, num_combinations)\n",
    "    assert matrix.shape[0] == df.shape[0]\n",
    "    assert matrix.shape[1] == df[feat1_name].nunique() * df[feat2_name].nunique()\n",
    "    return matrix, col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_binary_path(ad_feat_name, user_feat_name, prefix=\"train\", create=True):\n",
    "    folder = os.path.join(out_folder, \"[featureName='{}']\".format(user_feat_name))\n",
    "    file = \"{}.[adFeatureName='{}'].binary.pkl\".format(prefix, ad_feat_name)\n",
    "    path = os.path.join(folder, file)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = os.path.join(config.PRELIM_NLP_COUNT_DATA_DIR, \"simple_cross/byUserFeatureName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test\")\n",
    "df_ad = du.load_raw_data(\"ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 8798814\n",
      "Test Size: 2265989\n",
      "Concatenated Data Shape: (11064803, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = df_train.shape[0]\n",
    "test_size = df_test.shape[0]\n",
    "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
    "print(\"Train Size: {}\".format(train_size))\n",
    "print(\"Test Size: {}\".format(test_size))\n",
    "print(\"Concatenated Data Shape: {}\".format(df_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_one_feat_names = config.USER_SINGLE_FEAT_NAMES\n",
    "ad_feat_names = config.AD_FEAT_NAMES.copy()\n",
    "ad_feat_names.remove(\"creativeSize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:54] Finish loading and joining 'age'. △M: +92.65MB. △T: 10.8 seconds.\n",
      "[14:14:05] Finish loading and joining 'gender'. △M: +84.42MB. △T: 11.0 seconds.\n",
      "[14:14:16] Finish loading and joining 'education'. △M: +84.42MB. △T: 10.9 seconds.\n",
      "[14:14:28] Finish loading and joining 'consumptionAbility'. △M: +84.42MB. △T: 11.3 seconds.\n",
      "[14:14:40] Finish loading and joining 'LBS'. △M: +85.45MB. △T: 12.0 seconds.\n",
      "[14:14:52] Finish loading and joining 'carrier'. △M: +84.42MB. △T: 11.8 seconds.\n",
      "[14:15:03] Finish loading and joining 'house'. △M: +84.42MB. △T: 11.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "aj = dj.PandasPandasJointer(\"aid\")\n",
    "uj = dj.PandasPandasJointer(\"uid\")\n",
    "\n",
    "ad_user = aj.join(df_all, df_ad)  # join ad features\n",
    "for user_feat_name in user_one_feat_names:\n",
    "    with pu.profiler(\"loading and joining '{}'\".format(user_feat_name)):\n",
    "        df_feat = du.load_user_feature(user_feat_name).fillna(\"[nan]\")  # load user feature\n",
    "        ad_user = uj.join(ad_user, df_feat)  # join user feature\n",
    "        \n",
    "        del df_feat\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:08] Finish vectorizing and saving 'age'x'aid' binary. △M: -1.34MB. △T: 4.1 seconds.\n",
      "[14:15:11] Finish vectorizing and saving 'age'x'advertiserId' binary. △M: +200.0KB. △T: 3.7 seconds.\n",
      "[14:15:15] Finish vectorizing and saving 'age'x'campaignId' binary. △M: +4.0KB. △T: 3.6 seconds.\n",
      "[14:15:19] Finish vectorizing and saving 'age'x'creativeId' binary. △M: +0B. △T: 3.6 seconds.\n",
      "[14:15:21] Finish vectorizing and saving 'age'x'adCategoryId' binary. △M: +12.0KB. △T: 2.9 seconds.\n",
      "[14:15:25] Finish vectorizing and saving 'age'x'productId' binary. △M: +4.0KB. △T: 3.4 seconds.\n",
      "[14:15:28] Finish vectorizing and saving 'age'x'productType' binary. △M: +0B. △T: 2.9 seconds.\n",
      "[14:15:32] Finish vectorizing and saving 'gender'x'aid' binary. △M: +4.0KB. △T: 3.8 seconds.\n",
      "[14:15:35] Finish vectorizing and saving 'gender'x'advertiserId' binary. △M: -4.0KB. △T: 3.6 seconds.\n",
      "[14:15:39] Finish vectorizing and saving 'gender'x'campaignId' binary. △M: +8.0KB. △T: 3.6 seconds.\n",
      "[14:15:42] Finish vectorizing and saving 'gender'x'creativeId' binary. △M: +0B. △T: 3.6 seconds.\n",
      "[14:15:45] Finish vectorizing and saving 'gender'x'adCategoryId' binary. △M: +0B. △T: 3.0 seconds.\n",
      "[14:15:49] Finish vectorizing and saving 'gender'x'productId' binary. △M: +0B. △T: 3.6 seconds.\n",
      "[14:15:52] Finish vectorizing and saving 'gender'x'productType' binary. △M: +8.0KB. △T: 2.9 seconds.\n",
      "[14:15:56] Finish vectorizing and saving 'education'x'aid' binary. △M: +0B. △T: 3.9 seconds.\n",
      "[14:15:59] Finish vectorizing and saving 'education'x'advertiserId' binary. △M: +0B. △T: 3.7 seconds.\n",
      "[14:16:03] Finish vectorizing and saving 'education'x'campaignId' binary. △M: +16.0KB. △T: 3.8 seconds.\n",
      "[14:16:07] Finish vectorizing and saving 'education'x'creativeId' binary. △M: +24.0KB. △T: 3.7 seconds.\n",
      "[14:16:10] Finish vectorizing and saving 'education'x'adCategoryId' binary. △M: -40.0KB. △T: 3.1 seconds.\n",
      "[14:16:14] Finish vectorizing and saving 'education'x'productId' binary. △M: +0B. △T: 3.7 seconds.\n",
      "[14:16:17] Finish vectorizing and saving 'education'x'productType' binary. △M: +0B. △T: 3.0 seconds.\n",
      "[14:16:21] Finish vectorizing and saving 'consumptionAbility'x'aid' binary. △M: +16.0KB. △T: 3.9 seconds.\n",
      "[14:16:24] Finish vectorizing and saving 'consumptionAbility'x'advertiserId' binary. △M: -8.0KB. △T: 3.7 seconds.\n",
      "[14:16:28] Finish vectorizing and saving 'consumptionAbility'x'campaignId' binary. △M: +12.0KB. △T: 3.7 seconds.\n",
      "[14:16:32] Finish vectorizing and saving 'consumptionAbility'x'creativeId' binary. △M: +4.0KB. △T: 3.7 seconds.\n",
      "[14:16:35] Finish vectorizing and saving 'consumptionAbility'x'adCategoryId' binary. △M: -16.0KB. △T: 3.0 seconds.\n",
      "[14:16:38] Finish vectorizing and saving 'consumptionAbility'x'productId' binary. △M: +0B. △T: 3.4 seconds.\n",
      "[14:16:41] Finish vectorizing and saving 'consumptionAbility'x'productType' binary. △M: +0B. △T: 2.9 seconds.\n",
      "[14:16:46] Finish vectorizing and saving 'LBS'x'aid' binary. △M: +1.34MB. △T: 4.9 seconds.\n",
      "[14:16:51] Finish vectorizing and saving 'LBS'x'advertiserId' binary. △M: +680.0KB. △T: 4.6 seconds.\n",
      "[14:16:55] Finish vectorizing and saving 'LBS'x'campaignId' binary. △M: +8.0KB. △T: 4.6 seconds.\n",
      "[14:17:00] Finish vectorizing and saving 'LBS'x'creativeId' binary. △M: +0B. △T: 4.8 seconds.\n",
      "[14:17:04] Finish vectorizing and saving 'LBS'x'adCategoryId' binary. △M: -12.35MB. △T: 4.1 seconds.\n",
      "[14:17:09] Finish vectorizing and saving 'LBS'x'productId' binary. △M: +1.55MB. △T: 4.5 seconds.\n",
      "[14:17:12] Finish vectorizing and saving 'LBS'x'productType' binary. △M: +0B. △T: 3.7 seconds.\n",
      "[14:17:16] Finish vectorizing and saving 'carrier'x'aid' binary. △M: -1.97MB. △T: 3.8 seconds.\n",
      "[14:17:20] Finish vectorizing and saving 'carrier'x'advertiserId' binary. △M: -24.0KB. △T: 3.6 seconds.\n",
      "[14:17:23] Finish vectorizing and saving 'carrier'x'campaignId' binary. △M: +24.0KB. △T: 3.7 seconds.\n",
      "[14:17:27] Finish vectorizing and saving 'carrier'x'creativeId' binary. △M: +4.0KB. △T: 3.6 seconds.\n",
      "[14:17:30] Finish vectorizing and saving 'carrier'x'adCategoryId' binary. △M: -28.0KB. △T: 3.0 seconds.\n",
      "[14:17:33] Finish vectorizing and saving 'carrier'x'productId' binary. △M: +0B. △T: 3.5 seconds.\n",
      "[14:17:36] Finish vectorizing and saving 'carrier'x'productType' binary. △M: +0B. △T: 2.9 seconds.\n",
      "[14:17:40] Finish vectorizing and saving 'house'x'aid' binary. △M: +8.0KB. △T: 4.1 seconds.\n",
      "[14:17:44] Finish vectorizing and saving 'house'x'advertiserId' binary. △M: +0B. △T: 3.8 seconds.\n",
      "[14:17:48] Finish vectorizing and saving 'house'x'campaignId' binary. △M: +8.0KB. △T: 3.7 seconds.\n",
      "[14:17:52] Finish vectorizing and saving 'house'x'creativeId' binary. △M: -8.0KB. △T: 3.8 seconds.\n",
      "[14:17:55] Finish vectorizing and saving 'house'x'adCategoryId' binary. △M: +0B. △T: 3.0 seconds.\n",
      "[14:17:58] Finish vectorizing and saving 'house'x'productId' binary. △M: +0B. △T: 3.6 seconds.\n",
      "[14:18:01] Finish vectorizing and saving 'house'x'productType' binary. △M: +0B. △T: 3.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "for user_feat_name in user_one_feat_names:\n",
    "    for ad_feat_name in ad_feat_names:\n",
    "        with pu.profiler(\"vectorizing and saving '{}'x'{}' binary\".format(user_feat_name, ad_feat_name)):\n",
    "            # get matrix and names for matrix columns\n",
    "            matrix, col_names = cross_vectorize(ad_user, [ad_feat_name, user_feat_name])\n",
    "\n",
    "            # save train matrix\n",
    "            out_path = cross_binary_path(ad_feat_name, user_feat_name, prefix=\"train\")\n",
    "            matrix_train = matrix[:train_size, :]\n",
    "            du.save_pickle((col_names, matrix_train), out_path)\n",
    "            del matrix_train\n",
    "            gc.collect()\n",
    "\n",
    "            # save test matrix\n",
    "            out_path = cross_binary_path(ad_feat_name, user_feat_name, prefix=\"test1\")\n",
    "            matrix_test = matrix[train_size:, :]\n",
    "            du.save_pickle((col_names, matrix_test), out_path)\n",
    "            del matrix_test\n",
    "            gc.collect()\n",
    "\n",
    "            # release memory and clean garbage\n",
    "            del matrix\n",
    "            del col_names\n",
    "            gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
