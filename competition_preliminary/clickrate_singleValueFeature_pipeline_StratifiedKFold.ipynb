{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import pickle\n",
    "import copy\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "sys.path.append(\"../code/utils\")\n",
    "sys.path.append(\"../code/feature\")\n",
    "sys.path.append(\"../code/pipeline\")\n",
    "sys.path.append(\"../code\")\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import data_jointer as dj\n",
    "import config\n",
    "from clickrate import BayesianSmoothedClickrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickhist_folder = os.path.join(config.DATA_DIR, \"click_history/single_feature/byFeatureName\")\n",
    "\n",
    "\n",
    "def click_history_fold_dir(num_folds, create=True):\n",
    "    folder = \"{}[StratifiedKFold_{}]\".format(clickhist_folder, num_folds)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "def click_history_path(num_folds, fold_index, feat_name, create=True):\n",
    "    folder = click_history_fold_dir(num_folds, create)\n",
    "    folder = os.path.join(folder, str(fold_index))\n",
    "    filename = \"[featureName='{}'].csv\".format(feat_name)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(df, feat_names):\n",
    "    \"\"\"Get grouped clicks statistics for given feature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame you want to get clicked/unclicked statistics from.\n",
    "\n",
    "    feat_names: list\n",
    "        List containing names of features to consider.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df_group: pd.DataFrame\n",
    "        feat_0 | feat_1 | ... | positive | negative \n",
    "        ———————+————————+—————+——————————+——————————\n",
    "        val_0_0| val_1_0| ... | x        | x        \n",
    "        val_0_0| val_1_0| ... | x        | x        \n",
    "        ...    |        |     |          |          \n",
    "        val_0_i| val_1_j| ... | x        | x        \n",
    "    \"\"\"\n",
    "    # do grouping\n",
    "    if isinstance(feat_names, str):\n",
    "        feat_names = [feat_names]\n",
    "    \n",
    "    group_cols = feat_names + [\"label\"]\n",
    "    df_group = df.groupby(group_cols).size()\n",
    "    df_group = df_group.reset_index()\n",
    "    df_group = df_group.pivot_table(index=feat_names, columns=\"label\", values=0).reset_index()\n",
    "\n",
    "    # renaming and resetting\n",
    "    df_group = df_group.rename(columns={-1: \"negative\",\n",
    "                                        1: \"positive\"})  # rename columns for consistency\n",
    "    df_group.fillna(0, inplace=True)\n",
    "    df_group[[\"positive\", \"negative\"]] = df_group[[\"positive\", \"negative\"]].astype(int)  # reset type\n",
    "    df_group = df_group.rename_axis(None, axis=1)  # remove index name, which is very annoying\n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test\")\n",
    "df_ad = du.load_raw_data(\"ad\")\n",
    "train_size = df_train.shape[0]\n",
    "test_size = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['label'].values\n",
    "# y = (y + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_names = config.USER_FEAT_NAMES\n",
    "user_one_feat_names = config.USER_SINGLE_FEAT_NAMES\n",
    "user_multi_feat_names = config.USER_MULTI_FEAT_NAMES\n",
    "ad_feat_names = config.AD_FEAT_NAMES.copy()\n",
    "ad_feat_names.remove(\"creativeId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:09<00:00,  9.86s/it]\n"
     ]
    }
   ],
   "source": [
    "train = pd.merge(df_train, df_ad, on='aid', how='left')\n",
    "feat_unique_vals = {feat_name: df_ad[feat_name].unique() for feat_name in ad_feat_names}\n",
    "\n",
    "# not applicable for multi-value cases\n",
    "for feat_name in tqdm.tqdm(user_one_feat_names):\n",
    "    df_feat = du.load_user_feature(feat_name).fillna('[nan]')\n",
    "    train = pd.merge(train, df_feat, on=\"uid\", how=\"left\")\n",
    "    feat_unique_vals[feat_name] = df_feat[feat_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train.shape[0] == df_train.shape[0]\n",
    "assert train.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to (test+train) ratio: 0.204793\n",
    "# so we will use 5 fold splitting to calculate corrupted clickrate\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=20180502)  # fix random_state for reproducibility\n",
    "split_indices = [(train_index, valid_index) for train_index, valid_index in skf.split(df_train, y)]\n",
    "\n",
    "# save train/valid indices for each fold\n",
    "fold_dir = click_history_fold_dir(num_folds=n_splits)\n",
    "index_file = \"indices.pkl\"\n",
    "index_path = os.path.join(fold_dir, index_file)\n",
    "du.save_pickle(split_indices, index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:55:56] counting 'aid' fold 1/5 ...\n",
      "[08:55:58] counting 'aid' fold 2/5 ...\n",
      "[08:56:00] counting 'aid' fold 3/5 ...\n",
      "[08:56:02] counting 'aid' fold 4/5 ...\n",
      "[08:56:03] counting 'aid' fold 5/5 ...\n",
      "[08:56:05] counting 'advertiserId' fold 1/5 ...\n",
      "[08:56:07] counting 'advertiserId' fold 2/5 ...\n",
      "[08:56:09] counting 'advertiserId' fold 3/5 ...\n",
      "[08:56:10] counting 'advertiserId' fold 4/5 ...\n",
      "[08:56:12] counting 'advertiserId' fold 5/5 ...\n",
      "[08:56:14] counting 'campaignId' fold 1/5 ...\n",
      "[08:56:16] counting 'campaignId' fold 2/5 ...\n",
      "[08:56:18] counting 'campaignId' fold 3/5 ...\n",
      "[08:56:20] counting 'campaignId' fold 4/5 ...\n",
      "[08:56:21] counting 'campaignId' fold 5/5 ...\n",
      "[08:56:23] counting 'creativeSize' fold 1/5 ...\n",
      "[08:56:25] counting 'creativeSize' fold 2/5 ...\n",
      "[08:56:27] counting 'creativeSize' fold 3/5 ...\n",
      "[08:56:28] counting 'creativeSize' fold 4/5 ...\n",
      "[08:56:30] counting 'creativeSize' fold 5/5 ...\n",
      "[08:56:32] counting 'adCategoryId' fold 1/5 ...\n",
      "[08:56:34] counting 'adCategoryId' fold 2/5 ...\n",
      "[08:56:35] counting 'adCategoryId' fold 3/5 ...\n",
      "[08:56:37] counting 'adCategoryId' fold 4/5 ...\n",
      "[08:56:39] counting 'adCategoryId' fold 5/5 ...\n",
      "[08:56:41] counting 'productId' fold 1/5 ...\n",
      "[08:56:42] counting 'productId' fold 2/5 ...\n",
      "[08:56:44] counting 'productId' fold 3/5 ...\n",
      "[08:56:46] counting 'productId' fold 4/5 ...\n",
      "[08:56:48] counting 'productId' fold 5/5 ...\n",
      "[08:56:49] counting 'productType' fold 1/5 ...\n",
      "[08:56:51] counting 'productType' fold 2/5 ...\n",
      "[08:56:53] counting 'productType' fold 3/5 ...\n",
      "[08:56:54] counting 'productType' fold 4/5 ...\n",
      "[08:56:56] counting 'productType' fold 5/5 ...\n",
      "[08:56:58] counting 'age' fold 1/5 ...\n",
      "[08:57:00] counting 'age' fold 2/5 ...\n",
      "[08:57:02] counting 'age' fold 3/5 ...\n",
      "[08:57:03] counting 'age' fold 4/5 ...\n",
      "[08:57:05] counting 'age' fold 5/5 ...\n",
      "[08:57:07] counting 'gender' fold 1/5 ...\n",
      "[08:57:09] counting 'gender' fold 2/5 ...\n",
      "[08:57:11] counting 'gender' fold 3/5 ...\n",
      "[08:57:13] counting 'gender' fold 4/5 ...\n",
      "[08:57:15] counting 'gender' fold 5/5 ...\n",
      "[08:57:17] counting 'education' fold 1/5 ...\n",
      "[08:57:18] counting 'education' fold 2/5 ...\n",
      "[08:57:20] counting 'education' fold 3/5 ...\n",
      "[08:57:22] counting 'education' fold 4/5 ...\n",
      "[08:57:24] counting 'education' fold 5/5 ...\n",
      "[08:57:26] counting 'consumptionAbility' fold 1/5 ...\n",
      "[08:57:28] counting 'consumptionAbility' fold 2/5 ...\n",
      "[08:57:30] counting 'consumptionAbility' fold 3/5 ...\n",
      "[08:57:31] counting 'consumptionAbility' fold 4/5 ...\n",
      "[08:57:33] counting 'consumptionAbility' fold 5/5 ...\n",
      "[08:57:35] counting 'LBS' fold 1/5 ...\n",
      "[08:57:37] counting 'LBS' fold 2/5 ...\n",
      "[08:57:39] counting 'LBS' fold 3/5 ...\n",
      "[08:57:41] counting 'LBS' fold 4/5 ...\n",
      "[08:57:43] counting 'LBS' fold 5/5 ...\n",
      "[08:57:46] counting 'carrier' fold 1/5 ...\n",
      "[08:57:47] counting 'carrier' fold 2/5 ...\n",
      "[08:57:49] counting 'carrier' fold 3/5 ...\n",
      "[08:57:51] counting 'carrier' fold 4/5 ...\n",
      "[08:57:53] counting 'carrier' fold 5/5 ...\n",
      "[08:57:55] counting 'house' fold 1/5 ...\n",
      "[08:57:57] counting 'house' fold 2/5 ...\n",
      "[08:57:59] counting 'house' fold 3/5 ...\n",
      "[08:58:01] counting 'house' fold 4/5 ...\n",
      "[08:58:03] counting 'house' fold 5/5 ...\n"
     ]
    }
   ],
   "source": [
    "for feat_name in ad_feat_names + user_one_feat_names:\n",
    "    unique_vals = feat_unique_vals[feat_name]\n",
    "    for i, (train_index, valid_index) in enumerate(split_indices):\n",
    "        ### given a fold ###\n",
    "        print(\"[{}] counting '{}' fold {}/{} ...\".format(pu.get_time_str(), \n",
    "                                                         feat_name, \n",
    "                                                         i + 1,\n",
    "                                                         n_splits))\n",
    "        df_group = get_statistics(train.iloc[train_index], feat_name)\n",
    "        \n",
    "        # fill 0 to missed options\n",
    "        vals_present = set(df_group[feat_name].unique())\n",
    "        vals_absent = set(unique_vals).difference(vals_present)\n",
    "        for val in vals_absent:\n",
    "            df_group.loc[df_group.shape[0]] = {feat_name: val, \"positive\": 0, \"negative\": 0}\n",
    "            \n",
    "        # reset column name\n",
    "        df_group.rename(columns={feat_name: \"value\"}, inplace=True)\n",
    "\n",
    "        # save to hard disk\n",
    "        assert df_group.shape[0] == len(unique_vals)\n",
    "        out_path = click_history_path(num_folds=n_splits, fold_index=i, feat_name=feat_name)\n",
    "        df_group.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickrate_folder = os.path.join(config.DATA_DIR, \"clickrate_bs/single_feature/byFeatureName\")\n",
    "\n",
    "\n",
    "def click_rate_fold_dir(num_folds, create=True):\n",
    "    folder = \"{}[StratifiedKFold_{}]\".format(clickrate_folder, num_folds)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "def click_rate_path(num_folds, fold_index, feat_name, create=True):\n",
    "    folder = click_rate_fold_dir(num_folds, create)\n",
    "    folder = os.path.join(folder, str(fold_index))\n",
    "   \n",
    "    ckr_filename = \"[featureName='{}'].csv\".format(feat_name)\n",
    "    ckr_filepath = os.path.join(folder, ckr_filename)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return ckr_filepath\n",
    "\n",
    "\n",
    "def click_rate_meta_path(num_folds, fold_index, create=True):\n",
    "    folder = click_rate_fold_dir(num_folds, create)\n",
    "    folder = os.path.join(folder, str(fold_index))\n",
    "    meta_file = \"params.csv\"\n",
    "    meta_filepath = os.path.join(folder, meta_file)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return meta_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feat_stats(feat_stats):\n",
    "    \"\"\"Preprocess clicks history data just loaded from hard disk.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feat_stats: pd.DataFrame\n",
    "        DataFrame containing grouped clicks history data, with columns:\n",
    "        'value', 'negative', 'positive'.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    feat_stats: pd.DataFrame\n",
    "        DataFrame containing grouped clicks history data, with columns:\n",
    "        'value', 'negative', 'click', 'impression'.\n",
    "    \"\"\"\n",
    "    feat_stats[\"impression\"] = feat_stats[\"positive\"] + feat_stats[\"negative\"]\n",
    "    feat_stats = feat_stats.rename(columns={\"positive\": \"click\"})\n",
    "    return feat_stats\n",
    "\n",
    "\n",
    "def clean_meta(df_meta):\n",
    "    df_meta = df_meta.sort_values([\"clickrate_expectation\", \"alpha\"], ascending=False)\n",
    "    return df_meta[[\"featureName\", \"alpha\", \"beta\", \"clickrate_expectation\"]]\n",
    "\n",
    "\n",
    "def clean_clickrate(df_clickrate):\n",
    "    df_clickrate[[\"click\", \"impression\"]] = df_clickrate[[\"click\", \"impression\"]].astype(int)\n",
    "    df_clickrate = df_clickrate.sort_values([\"bs_clickrate\", \"click\"], ascending=False)\n",
    "    return df_clickrate[[\"value\", \"bs_clickrate\", \"click\", \"impression\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:01:10] processing 'aid' fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:2540: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:01:10] processing 'advertiserId' fold 1/5...\n",
      "[09:01:11] processing 'campaignId' fold 1/5...\n",
      "[09:01:11] processing 'creativeSize' fold 1/5...\n",
      "[09:01:12] processing 'adCategoryId' fold 1/5...\n",
      "[09:01:12] processing 'productId' fold 1/5...\n",
      "[09:01:12] processing 'productType' fold 1/5...\n",
      "[09:01:13] processing 'age' fold 1/5...\n",
      "[09:01:13] processing 'gender' fold 1/5...\n",
      "[09:01:14] processing 'education' fold 1/5...\n",
      "[09:01:14] processing 'consumptionAbility' fold 1/5...\n",
      "[09:01:14] processing 'LBS' fold 1/5...\n",
      "[09:01:17] processing 'carrier' fold 1/5...\n",
      "[09:01:17] processing 'house' fold 1/5...\n",
      "[09:01:18] processing 'aid' fold 2/5...\n",
      "[09:01:18] processing 'advertiserId' fold 2/5...\n",
      "[09:01:19] processing 'campaignId' fold 2/5...\n",
      "[09:01:19] processing 'creativeSize' fold 2/5...\n",
      "[09:01:20] processing 'adCategoryId' fold 2/5...\n",
      "[09:01:20] processing 'productId' fold 2/5...\n",
      "[09:01:21] processing 'productType' fold 2/5...\n",
      "[09:01:21] processing 'age' fold 2/5...\n",
      "[09:01:21] processing 'gender' fold 2/5...\n",
      "[09:01:22] processing 'education' fold 2/5...\n",
      "[09:01:22] processing 'consumptionAbility' fold 2/5...\n",
      "[09:01:23] processing 'LBS' fold 2/5...\n",
      "[09:01:25] processing 'carrier' fold 2/5...\n",
      "[09:01:25] processing 'house' fold 2/5...\n",
      "[09:01:26] processing 'aid' fold 3/5...\n",
      "[09:01:26] processing 'advertiserId' fold 3/5...\n",
      "[09:01:27] processing 'campaignId' fold 3/5...\n",
      "[09:01:27] processing 'creativeSize' fold 3/5...\n",
      "[09:01:28] processing 'adCategoryId' fold 3/5...\n",
      "[09:01:28] processing 'productId' fold 3/5...\n",
      "[09:01:29] processing 'productType' fold 3/5...\n",
      "[09:01:29] processing 'age' fold 3/5...\n",
      "[09:01:29] processing 'gender' fold 3/5...\n",
      "[09:01:30] processing 'education' fold 3/5...\n",
      "[09:01:30] processing 'consumptionAbility' fold 3/5...\n",
      "[09:01:31] processing 'LBS' fold 3/5...\n",
      "[09:01:33] processing 'carrier' fold 3/5...\n",
      "[09:01:33] processing 'house' fold 3/5...\n",
      "[09:01:34] processing 'aid' fold 4/5...\n",
      "[09:01:34] processing 'advertiserId' fold 4/5...\n",
      "[09:01:35] processing 'campaignId' fold 4/5...\n",
      "[09:01:35] processing 'creativeSize' fold 4/5...\n",
      "[09:01:36] processing 'adCategoryId' fold 4/5...\n",
      "[09:01:36] processing 'productId' fold 4/5...\n",
      "[09:01:37] processing 'productType' fold 4/5...\n",
      "[09:01:37] processing 'age' fold 4/5...\n",
      "[09:01:37] processing 'gender' fold 4/5...\n",
      "[09:01:38] processing 'education' fold 4/5...\n",
      "[09:01:38] processing 'consumptionAbility' fold 4/5...\n",
      "[09:01:39] processing 'LBS' fold 4/5...\n",
      "[09:01:41] processing 'carrier' fold 4/5...\n",
      "[09:01:41] processing 'house' fold 4/5...\n",
      "[09:01:42] processing 'aid' fold 5/5...\n",
      "[09:01:42] processing 'advertiserId' fold 5/5...\n",
      "[09:01:43] processing 'campaignId' fold 5/5...\n",
      "[09:01:43] processing 'creativeSize' fold 5/5...\n",
      "[09:01:44] processing 'adCategoryId' fold 5/5...\n",
      "[09:01:44] processing 'productId' fold 5/5...\n",
      "[09:01:45] processing 'productType' fold 5/5...\n",
      "[09:01:45] processing 'age' fold 5/5...\n",
      "[09:01:46] processing 'gender' fold 5/5...\n",
      "[09:01:46] processing 'education' fold 5/5...\n",
      "[09:01:46] processing 'consumptionAbility' fold 5/5...\n",
      "[09:01:47] processing 'LBS' fold 5/5...\n",
      "[09:01:49] processing 'carrier' fold 5/5...\n",
      "[09:01:49] processing 'house' fold 5/5...\n"
     ]
    }
   ],
   "source": [
    "for split_i in range(n_splits):\n",
    "    ### given a fold ###\n",
    "    df_meta = pd.DataFrame(columns=[\"featureName\", \"alpha\", \"beta\", \"clickrate_expectation\"])\n",
    "    \n",
    "    for feat_name in ad_feat_names + user_one_feat_names:\n",
    "        ### given a feature ###\n",
    "        # preparation\n",
    "        print(\"[{}] processing '{}' fold {}/{}...\".format(pu.get_time_str(), feat_name, split_i + 1, n_splits))\n",
    "        df_clickrate = pd.DataFrame(columns=[\"value\", \"bs_clickrate\", \"click\", \"impression\"])\n",
    "        in_path = click_history_path(num_folds=n_splits, fold_index=split_i, feat_name=feat_name)\n",
    "        feat_stats = pd.read_csv(in_path)\n",
    "        feat_stats = clean_feat_stats(feat_stats)\n",
    "\n",
    "        # solve bayesian smoothed click rate\n",
    "        imps = feat_stats[\"impression\"].values\n",
    "        clks = feat_stats[\"click\"].values\n",
    "        bs = BayesianSmoothedClickrate(max_iter=10000)\n",
    "        bs.fit(imps, clks, verbose=False)\n",
    "\n",
    "        # update meta and click rate DataFrame\n",
    "        feat_stats[\"bs_clickrate\"] = bs.transform(imps, clks)\n",
    "        df_meta.loc[df_meta.shape[0]] = {\"featureName\": feat_name, \"alpha\": bs.alpha, \"beta\": bs.beta, \n",
    "                                         \"clickrate_expectation\": bs.clickrate_expectation}\n",
    "        df_ckr= feat_stats[[\"value\", \"bs_clickrate\", \"click\", \"impression\"]]\n",
    "        \n",
    "        # save click rates to hard disk\n",
    "        ckr_path = click_rate_path(n_splits, split_i, feat_name)\n",
    "        df_ckr = clean_clickrate(df_ckr)\n",
    "        df_ckr.to_csv(ckr_path, index=False)\n",
    "    \n",
    "    # save meta info to hard disk\n",
    "    meta_path = click_rate_meta_path(n_splits, split_i)\n",
    "    df_meta = clean_meta(df_meta)\n",
    "    df_meta.to_csv(meta_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_indices(num_folds):\n",
    "    fold_dir = click_history_fold_dir(num_folds=n_splits)\n",
    "    index_file = \"indices.pkl\"\n",
    "    index_path = os.path.join(fold_dir, index_file)\n",
    "    split_indices = du.load_pickle(index_path)\n",
    "    return split_indices\n",
    "\n",
    "\n",
    "def load_clickrate(num_folds, fold_index, feat_name):\n",
    "    in_path = click_rate_path(num_folds, fold_index, feat_name)\n",
    "    df_ckr = pd.read_csv(in_path)\n",
    "    return df_ckr\n",
    "\n",
    "\n",
    "def batch_load_clickrate(num_folds, feat_name):\n",
    "    quick_load = partial(load_clickrate, num_folds=num_folds, feat_name=feat_name)\n",
    "    df_ckr = None\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        df_new = quick_load(fold_index=i)\n",
    "        df_new[\"fold\"] = i\n",
    "        if df_ckr is None:\n",
    "            df_ckr = df_new\n",
    "        else:\n",
    "            df_ckr = pd.concat([df_ckr, df_new], ignore_index=True)\n",
    "        del df_new\n",
    "        gc.collect()\n",
    "        \n",
    "    df_ckr[\"fold\"] = df_ckr[\"fold\"].astype(int)\n",
    "    return df_ckr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_valid_fold_index(df, fold_indices):\n",
    "    df = df.copy()\n",
    "    df[\"fold\"] = -1\n",
    "    for i, (train_index, valid_index) in enumerate(fold_indices):\n",
    "        df.loc[valid_index, \"fold\"] = i\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_splits = 5\n",
    "# split_indices = load_split_indices(mode, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:35] Finish joining click data for 'aid' by fold. △M: -2.2GB. △T: 16.6 seconds.\n",
      "[10:50:53] Finish joining click data for 'campaignId' by fold. △M: +546.48MB. △T: 17.9 seconds.\n",
      "[10:51:09] Finish joining click data for 'age' by fold. △M: +67.13MB. △T: 15.9 seconds.\n",
      "[10:51:25] Finish joining click data for 'consumptionAbility' by fold. △M: +67.13MB. △T: 16.4 seconds.\n",
      "[10:51:42] Finish joining click data for 'education' by fold. △M: +67.13MB. △T: 16.5 seconds.\n",
      "[10:51:59] Finish joining click data for 'LBS' by fold. △M: +67.16MB. △T: 17.6 seconds.\n"
     ]
    }
   ],
   "source": [
    "use_feat_names = [\"aid\", \"campaignId\", \"age\", \"consumptionAbility\", \"education\", \"LBS\"]\n",
    "col_names = []\n",
    "train2 = train.copy()\n",
    "train2 = insert_valid_fold_index(train2, split_indices)\n",
    "\n",
    "for feat_name in use_feat_names:\n",
    "    with pu.profiler(\"joining click data for '{}' by fold\".format(feat_name)):\n",
    "        # preparation\n",
    "        ckr_name = \"bsClickrate@{}\".format(feat_name)\n",
    "        col_names.append(ckr_name)\n",
    "        \n",
    "        # load data and rename columns\n",
    "        df_ckr = batch_load_clickrate(n_splits, feat_name)\n",
    "        df_ckr = df_ckr.rename(columns={\"value\": feat_name, \"bs_clickrate\": ckr_name})\n",
    "        \n",
    "        # unify dtype for joining\n",
    "        df_ckr[feat_name] = df_ckr[feat_name].astype(str)\n",
    "        train2[feat_name] = train2[feat_name].apply(str)\n",
    "    \n",
    "        # join and drop redundant data\n",
    "        train2 = dj.PandasPandasJointer.quick_join(train2, df_ckr, on=[\"fold\", feat_name])\n",
    "        train2.drop([\"impression\", \"click\"], axis=1, inplace=True)\n",
    "        assert train2.isnull().sum().sum() == 0\n",
    "        \n",
    "        # release memory and collect garbage\n",
    "        del df_ckr\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:54:46] Finish getting matrix represenation. △M: +201.39MB. △T: 0.5 seconds.\n",
      "[10:54:46] Finish saving matrix to hard disk. △M: -201.39MB. △T: 0.6 seconds.\n"
     ]
    }
   ],
   "source": [
    "output_folder = config.INPUT_DIR\n",
    "output_file = \"train.raw.clickStats_v1.pkl\"\n",
    "output_path = os.path.join(output_folder, output_file)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "with pu.profiler(\"getting matrix represenation\"):\n",
    "    X_train = train2[col_names].values.astype(np.float32)\n",
    "    assert X_train.shape[0] == df_train.shape[0]\n",
    "    assert X_train.shape[1] == len(use_feat_names)\n",
    "\n",
    "with pu.profiler(\"saving matrix to hard disk\"):\n",
    "    du.save_pickle((col_names, X_train), output_path)\n",
    "    col_names_train = copy.copy(col_names)  # for subsequent checking\n",
    "    del X_train\n",
    "    del train2\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:37<00:00,  5.31s/it]\n"
     ]
    }
   ],
   "source": [
    "test = pd.merge(df_test, df_ad, on='aid', how='left')\n",
    "\n",
    "# not applicable for multi-value cases\n",
    "for feat_name in tqdm.tqdm(user_one_feat_names):\n",
    "    df_feat = du.load_user_feature(feat_name).fillna('[nan]')\n",
    "    test = pd.merge(test, df_feat, on=\"uid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:07:02] Finish joining click data for 'aid' by fold. △M: -257.22MB. △T: 8.9 seconds.\n",
      "[11:07:14] Finish joining click data for 'campaignId' by fold. △M: +140.3MB. △T: 11.7 seconds.\n",
      "[11:07:25] Finish joining click data for 'age' by fold. △M: -121.02MB. △T: 11.2 seconds.\n",
      "[11:07:37] Finish joining click data for 'consumptionAbility' by fold. △M: +69.16MB. △T: 11.6 seconds.\n",
      "[11:07:48] Finish joining click data for 'education' by fold. △M: +34.57MB. △T: 11.8 seconds.\n",
      "[11:08:01] Finish joining click data for 'LBS' by fold. △M: +17.32MB. △T: 12.7 seconds.\n"
     ]
    }
   ],
   "source": [
    "col_names = []\n",
    "\n",
    "for feat_name in use_feat_names:\n",
    "    with pu.profiler(\"joining click data for '{}' by fold\".format(feat_name)):\n",
    "        # preparation\n",
    "        ckr_name = \"bsClickrate@{}\".format(feat_name)\n",
    "        col_names.append(ckr_name)\n",
    "        ckrs = np.zeros((test.shape[0], n_splits))\n",
    "        quick_load = partial(load_clickrate, num_folds=n_splits, feat_name=feat_name)\n",
    "        test[feat_name] = test[feat_name].apply(str)  # unify dtype for joining\n",
    "        \n",
    "        for split_index in range(n_splits):\n",
    "            # load click stats computed from current split\n",
    "            df_ckr = quick_load(fold_index=split_index)\n",
    "            df_ckr = df_ckr.rename(columns={\"value\": feat_name, \"bs_clickrate\": ckr_name})\n",
    "            \n",
    "            # unify dtype for joining\n",
    "            df_ckr[feat_name] = df_ckr[feat_name].astype(str)\n",
    "            \n",
    "            # join data\n",
    "            test = dj.PandasPandasJointer.quick_join(test, df_ckr, on=feat_name)\n",
    "            ckrs[:, split_index] = test[ckr_name]\n",
    "            \n",
    "            # clean up\n",
    "            test.drop([ckr_name, \"impression\", \"click\"], axis=1, inplace=True)\n",
    "            del df_ckr\n",
    "            gc.collect()\n",
    "        \n",
    "        # use average as the final feature\n",
    "        test[ckr_name] = ckrs.mean(axis=1)\n",
    "        assert test.isnull().sum().sum() == 0\n",
    "        \n",
    "        # clean up\n",
    "        del ckrs\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:08:24] Finish getting matrix represenation. △M: +0B. △T: 0.0 seconds.\n",
      "[11:08:24] Finish saving matrix to hard disk. △M: -505.82MB. △T: 0.2 seconds.\n"
     ]
    }
   ],
   "source": [
    "output_file = \"test1.raw.clickStats_v1.pkl\"\n",
    "output_path = os.path.join(output_folder, output_file)\n",
    "\n",
    "with pu.profiler(\"getting matrix represenation\"):\n",
    "    X_test = test[col_names].values.astype(np.float32)\n",
    "    assert X_test.shape[0] == df_test.shape[0]\n",
    "    assert X_test.shape[1] == len(use_feat_names)\n",
    "\n",
    "with pu.profiler(\"saving matrix to hard disk\"):\n",
    "    du.save_pickle((col_names, X_test), output_path)\n",
    "    del X_test\n",
    "    del test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
