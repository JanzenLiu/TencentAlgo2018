{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from fastFM import sgd\n",
    "import lightgbm as lgb\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../code/utils')\n",
    "sys.path.append('../code/pipeline')\n",
    "sys.path.append('../code')\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "import data_jointer as dj\n",
    "import joblib\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test\")\n",
    "df_ad = du.load_raw_data(\"ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 8798814\n",
      "Testing data size: 2265989\n"
     ]
    }
   ],
   "source": [
    "train_size = df_train.shape[0]\n",
    "test_size = df_test.shape[0]\n",
    "print(\"Training data size: {}\".format(train_size))\n",
    "print(\"Testing data size: {}\".format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_one_feat_names = config.USER_SINGLE_FEAT_NAMES\n",
    "user_multi_feat_names = config.USER_MULTI_FEAT_NAMES\n",
    "user_feat_names = config.USER_FEAT_NAMES\n",
    "ad_feat_names = config.AD_FEAT_NAMES\n",
    "ad_feat_names.remove(\"creativeId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing user features...: 100%|██████████| 23/23 [14:49<00:00, 38.66s/it]\n",
      "processing ad features...: 100%|██████████| 7/7 [02:47<00:00, 23.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:24:10] Finish loading and joining user and ad data. △M: +12.5GB. △T: 17.6 minutes.\n",
      "Combined Matrix Shape: (11064803, 419701)\n",
      "Feature Names Count: 419701\n",
      "Memory usage at this moment :13.1GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_jointer = dj.PandasMatrixJointer(\"uid\")\n",
    "ad_jointer = dj.PandasMatrixJointer(\"aid\")\n",
    "X_all = None\n",
    "col_names = []\n",
    "\n",
    "with pu.profiler(\"loading and joining user and ad data\"):\n",
    "    for user_feat_name in tqdm.tqdm(user_feat_names, desc=\"processing user features...\"):\n",
    "        # load matrix\n",
    "        row_uids, (word_to_index, word_idf, tfidf_matrix) = du.load_user_tfidf(user_feat_name)\n",
    "        matrix_all = user_jointer.join(df_all, tfidf_matrix, row_uids)\n",
    "        del tfidf_matrix\n",
    "        gc.collect()\n",
    "        \n",
    "        # concat matrices\n",
    "        if X_all is None:\n",
    "            X_all = matrix_all\n",
    "        else:\n",
    "            X_all = sparse.hstack((X_all, matrix_all))\n",
    "            del matrix_all\n",
    "            gc.collect()\n",
    "            \n",
    "        # define feature names\n",
    "        col_names += [\"{}_{}\".format(user_feat_name, val)\n",
    "                      for val, index in sorted(word_to_index.items(), key=lambda x: x[1])]\n",
    "        \n",
    "    for ad_feat_name in tqdm.tqdm(ad_feat_names, desc=\"processing ad features...\"):\n",
    "        row_aids, (words, cnt_matrix) = du.load_ad_cnt(ad_feat_name)\n",
    "        matrix_all = ad_jointer.join(df_all, cnt_matrix, row_aids)\n",
    "        del cnt_matrix\n",
    "        gc.collect()\n",
    "        \n",
    "        # concat matrices\n",
    "        if X_all is None:\n",
    "            X_all = matrix_all\n",
    "        else:\n",
    "            X_all = sparse.hstack((X_all, matrix_all))\n",
    "            del matrix_all\n",
    "            gc.collect()\n",
    "            \n",
    "        # define feature names\n",
    "        col_names += [\"{}_{}\".format(ad_feat_name, val) for val in words]\n",
    "        \n",
    "print(\"Combined Matrix Shape: {}\".format(X_all.shape))\n",
    "print(\"Feature Names Count: {}\".format(len(col_names)))\n",
    "print(\"Memory usage at this moment :{}\".format(pu.get_memory_str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:27:12] Finish splitting train and test data. △M: -3.28GB. △T: 1.2 minutes.\n",
      "Memory usage at this moment :9.82GB\n"
     ]
    }
   ],
   "source": [
    "with pu.profiler(\"splitting train and test data\"):\n",
    "    X_all = sparse.csr_matrix(X_all, dtype=np.float32)  # COO to CSR\n",
    "    X_tv = X_all[:train_size, :]\n",
    "    X_test = X_all[train_size:, :]\n",
    "    assert X_tv.shape[0] == df_train.shape[0]\n",
    "    assert X_test.shape[0] == df_test.shape[0]\n",
    "    del X_all\n",
    "    gc.collect()\n",
    "    \n",
    "    y = df_train['label'].values\n",
    "    assert X_tv.shape[0] == y.shape[0]\n",
    "    \n",
    "print(\"Memory usage at this moment :{}\".format(pu.get_memory_str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/input/train.raw.tfidf.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_folder = \"../data/input\"\n",
    "save_file = \"train.raw.tfidf.pkl\"\n",
    "save_path = os.path.join(save_folder, save_file)\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "X_tv = X_tv.astype(np.float32)\n",
    "gc.collect()\n",
    "# du.save_pickle((col_names, X_tv), save_path)\n",
    "joblib.dump((col_names, X_tv), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/input/test1.raw.tfidf.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_file = \"test1.raw.tfidf.pkl\"\n",
    "save_path = os.path.join(save_folder, save_file)\n",
    "\n",
    "X_test = X_test.astype(np.float32)\n",
    "gc.collect()\n",
    "# du.save_pickle((col_names, X_test), save_path)\n",
    "joblib.dump((col_names, X_test), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage at this moment :10.13GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory usage at this moment :{}\".format(pu.get_memory_str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
