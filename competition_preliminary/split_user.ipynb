{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager  # for context management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../../data/raw/preliminary_contest_data/'\n",
    "USER_DATA_FILE = 'userFeature.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename, **kw):\n",
    "    engine = kw.pop(\"engine\", \"python\")\n",
    "    return pd.read_csv(os.path.join(DATA_DIR, filename), engine=engine, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def open_files(f_dict):\n",
    "    fs = {k:open(v, \"w\") for k, v in f_dict.items()}\n",
    "    yield fs\n",
    "    for k, f in fs.items():\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileWritter:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.buffer = \"\"\n",
    "    \n",
    "    def write_buffer(self, chars):\n",
    "        self.buffer += chars\n",
    "        \n",
    "    def clear_buffer(self):\n",
    "        self.buffer = \"\"\n",
    "    \n",
    "    def flush(self):\n",
    "        self.f.write(self.buffer)\n",
    "        self.clear_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileWritterGroup:\n",
    "    def __init__(self, f_dict):\n",
    "        self.writters = {k:FileWritter(v) for k, v in f_dict.items()}\n",
    "        self.n_writters = len(f_dict)\n",
    "    \n",
    "    def write_buffer(self, name, chars):\n",
    "        self.writters[name].write_buffer(chars)\n",
    "    \n",
    "    def clear_buffer(self, name):\n",
    "        self.writters[name].clear_buffer()\n",
    "    \n",
    "    def clear_buffers(self):\n",
    "        for name, writter in self.writters.items():\n",
    "            writter.clear_buffer()\n",
    "            \n",
    "    def flush(self):\n",
    "        for name, writter in self.writters.items():\n",
    "            writter.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load(\"train.csv\")\n",
    "df_test = load(\"test1.csv\")\n",
    "df_ad = load(\"adFeature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "aid_to_product = {row[\"aid\"]: row[\"productId\"] for i, row in df_ad.iterrows()}\n",
    "print(len(aid_to_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "df_test_copy = df_test.copy()\n",
    "df_train_copy[\"productId\"] = df_train[\"aid\"].map(aid_to_product)\n",
    "df_test_copy[\"productId\"] = df_test[\"aid\"].map(aid_to_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ids = df_ad[\"productId\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_to_trainidx = df_train_copy.groupby(\"productId\").groups  # dict that maps productId to Index\n",
    "product_to_testidx = df_test_copy.groupby(\"productId\").groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:27<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# ===============\n",
    "# split train.csv\n",
    "# ===============\n",
    "out_folder = '../../../data/split/preliminary_contest_data/byproductId/'\n",
    "os.makedirs(out_folder, exist_ok=True)  # create directory if not existed\n",
    "row_counts = 0  # for debug use\n",
    "for prod_id, idx in tqdm(product_to_trainidx.items()):\n",
    "    df = df_train.loc[idx]\n",
    "    df.to_csv(os.path.join(out_folder, \"train.[productId='{}'].csv\".format(prod_id)), index=False)\n",
    "    row_counts += df.shape[0]\n",
    "assert row_counts == df_train.shape[0]  # for debug use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:06<00:00,  5.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# ===============\n",
    "# split test1.csv\n",
    "# ===============\n",
    "row_counts = 0  # for debug use\n",
    "for prod_id, idx in tqdm(product_to_testidx.items()):\n",
    "    df = df_test.loc[idx]\n",
    "    df.to_csv(os.path.join(out_folder, \"test1.[productId='{}'].csv\".format(prod_id)), index=False)\n",
    "    row_counts += df.shape[0]\n",
    "assert row_counts == df_test.shape[0]  # for debug use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:04<00:00,  7.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# get productId to userIds map\n",
    "# ============================\n",
    "product_to_user = {}  # key: integer, value: set\n",
    "for prod_id in tqdm(prod_ids):\n",
    "    train_idx = product_to_trainidx[prod_id]\n",
    "    test_idx = product_to_testidx[prod_id]\n",
    "    train_uids = df_train.loc[train_idx][\"uid\"].values  # list\n",
    "    test_uids = df_test.loc[test_idx][\"uid\"].values  # list\n",
    "    uids = set(train_uids).union(set(test_uids))  # set\n",
    "    product_to_user[prod_id] = uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 11089/11421 [02:13<00:03, 83.26it/s]"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# split userFeature.data\n",
    "# ======================\n",
    "line_counts = 11420039\n",
    "\n",
    "batch_size = 1000\n",
    "batch_counts = (line_counts - 1) // batch_size + 1\n",
    "product_to_filenames = {prod_id: os.path.join(out_folder, \"userFeature.[productId='{}'].data\".format(prod_id)) \n",
    "                        for prod_id in prod_ids}\n",
    "with open(os.path.join(DATA_DIR, USER_DATA_FILE), \"r\") as user_f:\n",
    "    with open_files(product_to_filenames) as prod_fs:\n",
    "        fwg = FileWritterGroup(prod_fs)\n",
    "        for i in tqdm(range(batch_counts)):\n",
    "            try:\n",
    "                fwg.clear_buffers()\n",
    "                for i in range(batch_size):\n",
    "                    ln = user_f.readline()\n",
    "                    feat = ln[4:16]\n",
    "                    uid = feat.split(\"|\")[0]\n",
    "                    uid = int(uid)\n",
    "                    for prod_id, required_uid_set in product_to_user.items():\n",
    "                        if uid in required_uid_set:\n",
    "                            fwg.write_buffer(prod_id, ln)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            fwg.flush()\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
