{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import pickle\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../code/utils\")\n",
    "sys.path.append(\"../code/feature\")\n",
    "import data_utils as du\n",
    "import perf_utils as pu\n",
    "from clickrate import BayesianSmoothedClickrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = du.load_raw_data(\"train\")\n",
    "df_test = du.load_raw_data(\"test\")\n",
    "df_ad = du.load_raw_data(\"ad\")\n",
    "train_size = df_train.shape[0]\n",
    "test_size = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test/(Train + Test) Ratio: 0.204793\n"
     ]
    }
   ],
   "source": [
    "# test to all: 0.204793\n",
    "# so we will use 5 fold splitting to calculate corrupted clickrate\n",
    "print(\"Test/(Train + Test) Ratio: {:.6f}\".format(test_size / (train_size + test_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['label'].values\n",
    "# y = (y + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('aid', 'age'), ('aid', 'education'), ('aid', 'consumptionAbility'), ('aid', 'LBS')]\n",
    "ufeats_to_join = set([ufeat for afeat, ufeat in pairs])\n",
    "afeats_to_join = set([afeat for afeat, ufeat in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "avals_dict = {afeat: set(df_ad[afeat].unique()) for afeat in afeats_to_join}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:43<00:00, 10.76s/it]\n"
     ]
    }
   ],
   "source": [
    "uvals_dict = {}\n",
    "ad_user = pd.merge(df_train, df_ad, on='aid', how='left')\n",
    "for ufeat in tqdm.tqdm(ufeats_to_join):\n",
    "    df_feat = du.load_user_feature(ufeat).fillna('[nan]')\n",
    "    ad_user = pd.merge(ad_user, df_feat, on=\"uid\", how=\"left\")\n",
    "    uvals_dict[ufeat] = set(df_feat[ufeat].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_df(df, selector):\n",
    "    for col, val in selector.items():\n",
    "        df = df[df[col]==val]\n",
    "    return df.copy()\n",
    "\n",
    "\n",
    "def get_statistics(ad_user, ad_feat_name, user_feat_name):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    ad_user: pd.DataFrame\n",
    "        Joined dataframe containing both the target ad feature and user feature.\n",
    "\n",
    "    ad_feat_name: string\n",
    "        Name of ad feature to consider.\n",
    "        \n",
    "    user_feat_name: string\n",
    "        Name of user feature to consider.\n",
    "    \"\"\"\n",
    "    # do grouping\n",
    "    df_group = ad_user.groupby([ad_feat_name, user_feat_name, \"label\"]).size()\n",
    "    df_group = df_group.reset_index()\n",
    "    df_group = df_group.pivot_table(index=[ad_feat_name, user_feat_name], columns=\"label\", values=0).reset_index()\n",
    "\n",
    "    # renaming and resetting\n",
    "    df_group = df_group.rename(columns={0: \"count\",\n",
    "                                        -1: \"negative\",\n",
    "                                        1: \"positive\",\n",
    "                                        ad_feat_name: \"ad_val\",\n",
    "                                        user_feat_name: \"user_val\"})  # rename columns for consistency\n",
    "    df_group.fillna(0, inplace=True)\n",
    "    df_group[[\"positive\", \"negative\"]] = df_group[[\"positive\", \"negative\"]].astype(int)  # reset type\n",
    "    df_group = df_group.rename_axis(None, axis=1)  # remove index name, which is very annoying\n",
    "    return df_group\n",
    "\n",
    "\n",
    "def select_subgroup(df_group, aval, uvals=None, ad_feat_name=\"ad_val\", user_feat_name=\"user_val\"):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    df_group: pd.DataFrame\n",
    "        A pivoted table storing statistics for all ad feature values.\n",
    "\n",
    "    aval: int | float | string\n",
    "        Ad feature value whose statistics you want to select from `df_group`.\n",
    "\n",
    "    uvals: set\n",
    "        All user feature values presented in the whole dataset.\n",
    "\n",
    "    ad_feat_name: string\n",
    "        Name of current ad feature. If not given, the program will assume you\n",
    "        have renamed the column to 'ad_val'.\n",
    "\n",
    "    user_feat_name: string\n",
    "        Name of current user feature. If not given, the program will assume you\n",
    "        have renamed the column to 'user_val'.\n",
    "    \"\"\"\n",
    "    # select sub-dataframe with given ad feature value\n",
    "    df_selected = select_df(df_group, {ad_feat_name: aval})  # select statistics for given aid\n",
    "\n",
    "    # rename and reset columns\n",
    "    df_selected = df_selected.rename(columns={user_feat_name: \"value\"})  # rename columns\n",
    "    df_selected = df_selected[[\"value\", \"positive\", \"negative\"]]  # selected wanted columns\n",
    "    df_selected = df_selected.reset_index(drop=True)\n",
    "\n",
    "    # handle missing user feature values: append rows with 0 positive and 0 negative\n",
    "    if uvals is not None:\n",
    "        uvals_present = set(df_selected[\"value\"].unique())\n",
    "        uvals_absent = set(uvals).difference(uvals_present)\n",
    "        for uval in uvals_absent:\n",
    "            df_selected.loc[df_selected.shape[0]] = {\"value\": uval, \"positive\": 0, \"negative\": 0}\n",
    "\n",
    "    # handle missing positive and negative: fill with 0\n",
    "    df_selected = df_selected.fillna(0)\n",
    "    df_selected[[\"positive\", \"negative\"]] = df_selected[[\"positive\", \"negative\"]].astype(int)  # reset type\n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickhist_folder = \"../data/click_history/simple_cross/byUserFeatureName\"\n",
    "\n",
    "\n",
    "def click_history_fold_dir(mode, num_folds, create=True):\n",
    "    folder = \"{}[{}_{}]\".format(clickhist_folder, mode, num_folds)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "def click_history_path(mode, num_folds, fold_index, ad_feat_name, user_feat_name, aval, create=True):\n",
    "    folder = click_history_fold_dir(mode, num_folds)\n",
    "    folder = os.path.join(folder, str(fold_index),  \"[featureName='{}']\".format(user_feat_name))\n",
    "    filename = \"[{}='{}'].csv\".format(ad_feat_name, aval)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split k-folds and keep the indices\n",
    "mode = \"StratifiedKFold\"\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=20180502)  # fix random_state for reproducibility\n",
    "split_indices = [(train_index, valid_index) for train_index, valid_index in skf.split(df_train, y)]\n",
    "\n",
    "# save train/valid indices for each fold\n",
    "fold_dir = click_history_fold_dir(mode, num_folds=n_splits)\n",
    "index_file = \"indices.pkl\"\n",
    "index_path = os.path.join(fold_dir, index_file)\n",
    "du.save_pickle(split_indices, index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:00:10] counting 'aid' x 'age' fold 1/5 ...\n",
      "[11:00:17] counting 'aid' x 'age' fold 2/5 ...\n",
      "[11:00:25] counting 'aid' x 'age' fold 3/5 ...\n",
      "[11:00:31] counting 'aid' x 'age' fold 4/5 ...\n",
      "[11:00:39] counting 'aid' x 'age' fold 5/5 ...\n",
      "[11:00:45] counting 'aid' x 'education' fold 1/5 ...\n",
      "[11:00:52] counting 'aid' x 'education' fold 2/5 ...\n",
      "[11:00:59] counting 'aid' x 'education' fold 3/5 ...\n",
      "[11:01:06] counting 'aid' x 'education' fold 4/5 ...\n",
      "[11:01:14] counting 'aid' x 'education' fold 5/5 ...\n",
      "[11:01:21] counting 'aid' x 'consumptionAbility' fold 1/5 ...\n",
      "[11:01:28] counting 'aid' x 'consumptionAbility' fold 2/5 ...\n",
      "[11:01:37] counting 'aid' x 'consumptionAbility' fold 3/5 ...\n",
      "[11:01:42] counting 'aid' x 'consumptionAbility' fold 4/5 ...\n",
      "[11:01:49] counting 'aid' x 'consumptionAbility' fold 5/5 ...\n",
      "[11:01:55] counting 'aid' x 'LBS' fold 1/5 ...\n",
      "[11:06:04] counting 'aid' x 'LBS' fold 2/5 ...\n",
      "[11:10:03] counting 'aid' x 'LBS' fold 3/5 ...\n",
      "[11:14:02] counting 'aid' x 'LBS' fold 4/5 ...\n",
      "[11:18:13] counting 'aid' x 'LBS' fold 5/5 ...\n"
     ]
    }
   ],
   "source": [
    "for ad_feat_name, user_feat_name in pairs:\n",
    "    avals = avals_dict[ad_feat_name]\n",
    "    uvals = uvals_dict[user_feat_name]\n",
    "    for i, (train_index, valid_index) in enumerate(split_indices):\n",
    "        print(\"[{}] counting '{}' x '{}' fold {}/{} ...\".format(pu.get_time_str(), \n",
    "                                                                ad_feat_name, \n",
    "                                                                user_feat_name,\n",
    "                                                                i + 1, \n",
    "                                                                n_splits))\n",
    "        df_group = get_statistics(ad_user.iloc[train_index], ad_feat_name, user_feat_name)\n",
    "        for aval in avals:\n",
    "            out_path = click_history_path(mode=mode, num_folds=n_splits, fold_index=i, \n",
    "                                          user_feat_name=user_feat_name, ad_feat_name=ad_feat_name, aval=aval)\n",
    "            df_subgroup = select_subgroup(df_group, aval, uvals)\n",
    "            assert df_subgroup.shape[0] == len(uvals)\n",
    "            df_subgroup.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickrate_folder = \"../data/clickrate_bs/simple_cross/byUserFeatureName\"\n",
    "\n",
    "\n",
    "def click_rate_fold_dir(mode, num_folds, create=True):\n",
    "    folder = \"{}[{}_{}]\".format(clickrate_folder, mode, num_folds)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "def click_rate_paths(mode, num_folds, fold_index, ad_feat_name, user_feat_name, create=True):\n",
    "    folder = click_rate_fold_dir(mode, num_folds, create)\n",
    "    folder = os.path.join(folder, str(fold_index),  \"[featureName='{}']\".format(user_feat_name))\n",
    "    clickrate_file = \"[adFeatureName='{}'].csv\".format(ad_feat_name)\n",
    "    clickrate_filepath = os.path.join(folder, clickrate_file)\n",
    "    meta_file = \"params[adFeatureName='{}'].csv\".format(ad_feat_name)\n",
    "    meta_filepath = os.path.join(folder, meta_file)\n",
    "    if create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    return clickrate_filepath, meta_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feat_stats(feat_stats):\n",
    "    # feat_stats = feat_stats[feat_stats[\"value\"] != \"all\"]\n",
    "    feat_stats[\"impression\"] = feat_stats[\"positive\"] + feat_stats[\"negative\"]\n",
    "    feat_stats = feat_stats.rename(columns={\"positive\": \"click\", \"value\":\"user_val\"})\n",
    "    return feat_stats\n",
    "\n",
    "\n",
    "def clean_meta(df_meta):\n",
    "    df_meta[\"ad_val\"] = df_meta[\"ad_val\"].astype(int)  # seems that this line of code is redundant\n",
    "    df_meta = df_meta.sort_values([\"clickrate_expectation\", \"alpha\"], ascending=False)\n",
    "    return df_meta[[\"ad_val\", \"alpha\", \"beta\", \"clickrate_expectation\"]]\n",
    "\n",
    "\n",
    "def clean_clickrate(df_clickrate):\n",
    "    df_clickrate[[\"click\", \"impression\"]] = df_clickrate[[\"click\", \"impression\"]].astype(int)\n",
    "    df_clickrate = df_clickrate.sort_values([\"bs_clickrate\", \"click\"], ascending=False)\n",
    "    return df_clickrate[[\"ad_val\", \"user_val\", \"bs_clickrate\", \"click\", \"impression\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'aid' x 'age' fold 1/5: 100%|██████████| 173/173 [01:17<00:00,  2.23it/s]\n",
      "'aid' x 'age' fold 2/5: 100%|██████████| 173/173 [01:19<00:00,  2.18it/s]\n",
      "'aid' x 'age' fold 3/5: 100%|██████████| 173/173 [01:21<00:00,  2.12it/s]\n",
      "'aid' x 'age' fold 4/5: 100%|██████████| 173/173 [01:20<00:00,  2.14it/s]\n",
      "'aid' x 'age' fold 5/5: 100%|██████████| 173/173 [01:23<00:00,  2.08it/s]\n",
      "'aid' x 'education' fold 1/5: 100%|██████████| 173/173 [01:18<00:00,  2.21it/s]\n",
      "'aid' x 'education' fold 2/5: 100%|██████████| 173/173 [01:20<00:00,  2.14it/s]\n",
      "'aid' x 'education' fold 3/5: 100%|██████████| 173/173 [01:18<00:00,  2.21it/s]\n",
      "'aid' x 'education' fold 4/5: 100%|██████████| 173/173 [01:16<00:00,  2.27it/s]\n",
      "'aid' x 'education' fold 5/5: 100%|██████████| 173/173 [01:15<00:00,  2.28it/s]\n",
      "'aid' x 'consumptionAbility' fold 1/5: 100%|██████████| 173/173 [01:14<00:00,  2.31it/s]\n",
      "'aid' x 'consumptionAbility' fold 2/5: 100%|██████████| 173/173 [01:10<00:00,  2.46it/s]\n",
      "'aid' x 'consumptionAbility' fold 3/5: 100%|██████████| 173/173 [01:09<00:00,  2.49it/s]\n",
      "'aid' x 'consumptionAbility' fold 4/5: 100%|██████████| 173/173 [01:09<00:00,  2.48it/s]\n",
      "'aid' x 'consumptionAbility' fold 5/5: 100%|██████████| 173/173 [01:12<00:00,  2.38it/s]\n",
      "'aid' x 'LBS' fold 1/5: 100%|██████████| 173/173 [07:07<00:00,  2.47s/it]\n",
      "'aid' x 'LBS' fold 2/5: 100%|██████████| 173/173 [05:56<00:00,  2.06s/it]\n",
      "'aid' x 'LBS' fold 3/5: 100%|██████████| 173/173 [06:30<00:00,  2.26s/it]\n",
      "'aid' x 'LBS' fold 4/5: 100%|██████████| 173/173 [08:46<00:00,  3.04s/it]\n",
      "'aid' x 'LBS' fold 5/5:  92%|█████████▏| 160/173 [07:47<00:38,  2.92s/it]"
     ]
    }
   ],
   "source": [
    "for ad_feat_name, user_feat_name in pairs:\n",
    "    avals = avals_dict[ad_feat_name]\n",
    "    for split_i in range(n_splits):\n",
    "        df_meta = pd.DataFrame(columns=[\"ad_val\", \"alpha\", \"beta\", \"clickrate_expectation\"])\n",
    "        df_clickrate = pd.DataFrame(columns=[\"ad_val\", \"user_val\", \"bs_clickrate\", \"click\", \"impression\"])\n",
    "        \n",
    "        desc = \"'{}' x '{}' fold {}/{}\".format(ad_feat_name, user_feat_name, split_i + 1, n_splits)\n",
    "        for aval in tqdm.tqdm(list(avals), desc=desc):\n",
    "            in_path = click_history_path(mode=mode, num_folds=n_splits, fold_index=split_i,\n",
    "                                         user_feat_name=user_feat_name, ad_feat_name=ad_feat_name, aval=aval)\n",
    "            feat_stats = pd.read_csv(in_path)\n",
    "            feat_stats = clean_feat_stats(feat_stats)\n",
    "            \n",
    "            imps = feat_stats[\"impression\"].values\n",
    "            clks = feat_stats[\"click\"].values\n",
    "            bs = BayesianSmoothedClickrate(max_iter=10000)\n",
    "            bs.fit(imps, clks, verbose=False)\n",
    "            \n",
    "            feat_stats[\"bs_clickrate\"] = bs.transform(imps, clks)\n",
    "            feat_stats[\"ad_val\"] = aval\n",
    "            df_meta.loc[df_meta.shape[0]] = {\"ad_val\": aval, \"alpha\": bs.alpha, \"beta\": bs.beta, \n",
    "                                             \"clickrate_expectation\": bs.clickrate_expectation}\n",
    "            df_clickrate = df_clickrate.append(feat_stats[[\"ad_val\", \"user_val\", \"bs_clickrate\", \"click\", \"impression\"]])\n",
    "        \n",
    "        clickrate_path, meta_path = click_rate_paths(mode, n_splits, split_i, ad_feat_name, user_feat_name)\n",
    "        df_meta = clean_meta(df_meta)\n",
    "        df_meta.to_csv(meta_path, index=False)\n",
    "        df_clickrate = clean_clickrate(df_clickrate)\n",
    "        df_clickrate.to_csv(clickrate_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
